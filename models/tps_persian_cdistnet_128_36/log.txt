2026-01-05 09:35:49,837 - CDistNet - INFO - model parameter:-------
Trainable: 113.42996 M
2026-01-05 09:35:49,838 - CDistNet - INFO - model struct:-------
DataParallel(
  (module): CDistNet(
    (visual_branch): VIS_Pre(
      (transform): TPS_SpatialTransformerNetwork(
        (LocalizationNetwork): LocalizationNetwork(
          (conv): Sequential(
            (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU(inplace=True)
            (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
            (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (6): ReLU(inplace=True)
            (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
            (8): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (9): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (10): ReLU(inplace=True)
            (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
            (12): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (13): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (14): ReLU(inplace=True)
            (15): AdaptiveAvgPool2d(output_size=1)
          )
          (localization_fc1): Sequential(
            (0): Linear(in_features=512, out_features=256, bias=True)
            (1): ReLU(inplace=True)
          )
          (localization_fc2): Linear(in_features=256, out_features=40, bias=True)
        )
        (GridGenerator): GridGenerator()
      )
      (backbone): ABI_ResNet(
        (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (convbnrelu): ConvBnRelu(
          (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
          (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (layer1): Sequential(
          (0): BasicBlock(
            (conv1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (downsample): Sequential(
              (0): Conv2d(32, 32, kernel_size=(1, 1), stride=(2, 2), bias=False)
              (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (1): BasicBlock(
            (conv1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (2): BasicBlock(
            (conv1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (layer2): Sequential(
          (0): BasicBlock(
            (conv1): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (downsample): Sequential(
              (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (1): BasicBlock(
            (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (2): BasicBlock(
            (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (3): BasicBlock(
            (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (layer3): Sequential(
          (0): BasicBlock(
            (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (downsample): Sequential(
              (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
              (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (1): BasicBlock(
            (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (2): BasicBlock(
            (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (3): BasicBlock(
            (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (4): BasicBlock(
            (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (5): BasicBlock(
            (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (layer4): Sequential(
          (0): BasicBlock(
            (conv1): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (downsample): Sequential(
              (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (1): BasicBlock(
            (conv1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (2): BasicBlock(
            (conv1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (3): BasicBlock(
            (conv1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (4): BasicBlock(
            (conv1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (5): BasicBlock(
            (conv1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (layer5): Sequential(
          (0): BasicBlock(
            (conv1): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (downsample): Sequential(
              (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (1): BasicBlock(
            (conv1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (2): BasicBlock(
            (conv1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
      )
      (positional_encoding): PositionalEncoding(
        (dropout): Dropout(p=0.15, inplace=False)
      )
      (trans_encoder): TransformerEncoder(
        (layers): ModuleList(
          (0-2): 3 x TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
              (conv1): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1))
              (conv2): Conv2d(768, 1536, kernel_size=(1, 1), stride=(1, 1))
              (conv3): Conv2d(768, 2304, kernel_size=(1, 1), stride=(1, 1))
            )
            (conv1): Conv2d(768, 2048, kernel_size=(1, 1), stride=(1, 1))
            (conv2): Conv2d(2048, 768, kernel_size=(1, 1), stride=(1, 1))
            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.15, inplace=False)
            (dropout2): Dropout(p=0.15, inplace=False)
          )
        )
        (pos_encoding): PositionalEncoding(
          (dropout): Dropout(p=0.0, inplace=False)
        )
      )
    )
    (semantic_branch): SEM_Pre(
      (embedding): Embeddings(
        (embedding): Embedding(81, 768, padding_idx=0)
      )
      (positional_encoding): PositionalEncoding(
        (dropout): Dropout(p=0.15, inplace=False)
      )
    )
    (positional_branch): POS_Pre(
      (pos_encoding): PositionalEncoding(
        (dropout): Dropout(p=0.15, inplace=False)
      )
      (linear1): Linear(in_features=768, out_features=768, bias=True)
      (linear2): Linear(in_features=768, out_features=768, bias=True)
      (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    )
    (mdcdp): MDCDP(
      (layers_pos): ModuleList(
        (0-2): 3 x CommonAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): Linear(in_features=768, out_features=768, bias=True)
            (conv1): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1))
            (conv2): Conv2d(768, 1536, kernel_size=(1, 1), stride=(1, 1))
            (conv3): Conv2d(768, 2304, kernel_size=(1, 1), stride=(1, 1))
          )
          (linear1): Linear(in_features=768, out_features=1024, bias=True)
          (dropout): Dropout(p=0.05, inplace=False)
          (linear2): Linear(in_features=1024, out_features=768, bias=True)
          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (dropout2): Dropout(p=0.15, inplace=False)
          (dropout3): Dropout(p=0.15, inplace=False)
        )
      )
      (layers2): ModuleList(
        (0-2): 3 x CommonAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): Linear(in_features=768, out_features=768, bias=True)
            (conv1): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1))
            (conv2): Conv2d(768, 1536, kernel_size=(1, 1), stride=(1, 1))
            (conv3): Conv2d(768, 2304, kernel_size=(1, 1), stride=(1, 1))
          )
          (linear1): Linear(in_features=768, out_features=1024, bias=True)
          (dropout): Dropout(p=0.05, inplace=False)
          (linear2): Linear(in_features=1024, out_features=768, bias=True)
          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (dropout2): Dropout(p=0.15, inplace=False)
          (dropout3): Dropout(p=0.15, inplace=False)
        )
      )
      (layers3): ModuleList(
        (0-2): 3 x CommonAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): Linear(in_features=768, out_features=768, bias=True)
            (conv1): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1))
            (conv2): Conv2d(768, 1536, kernel_size=(1, 1), stride=(1, 1))
            (conv3): Conv2d(768, 2304, kernel_size=(1, 1), stride=(1, 1))
          )
          (linear1): Linear(in_features=768, out_features=1024, bias=True)
          (dropout): Dropout(p=0.05, inplace=False)
          (linear2): Linear(in_features=1024, out_features=768, bias=True)
          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (dropout2): Dropout(p=0.15, inplace=False)
          (dropout3): Dropout(p=0.15, inplace=False)
        )
      )
      (dynamic_shared_fusion): DSF(
        (w_att): Linear(in_features=1024, out_features=512, bias=True)
      )
    )
    (tgt_word_prj): Linear(in_features=768, out_features=81, bias=False)
  )
)
2026-01-05 09:39:06,651 - CDistNet - INFO - model parameter:-------
Trainable: 113.431112 M
2026-01-05 09:39:06,653 - CDistNet - INFO - model struct:-------
DataParallel(
  (module): CDistNet(
    (visual_branch): VIS_Pre(
      (transform): TPS_SpatialTransformerNetwork(
        (LocalizationNetwork): LocalizationNetwork(
          (conv): Sequential(
            (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU(inplace=True)
            (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
            (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (6): ReLU(inplace=True)
            (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
            (8): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (9): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (10): ReLU(inplace=True)
            (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
            (12): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (13): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (14): ReLU(inplace=True)
            (15): AdaptiveAvgPool2d(output_size=1)
          )
          (localization_fc1): Sequential(
            (0): Linear(in_features=512, out_features=256, bias=True)
            (1): ReLU(inplace=True)
          )
          (localization_fc2): Linear(in_features=256, out_features=40, bias=True)
        )
        (GridGenerator): GridGenerator()
      )
      (backbone): ABI_ResNet(
        (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (convbnrelu): ConvBnRelu(
          (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
          (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (layer1): Sequential(
          (0): BasicBlock(
            (conv1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (downsample): Sequential(
              (0): Conv2d(32, 32, kernel_size=(1, 1), stride=(2, 2), bias=False)
              (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (1): BasicBlock(
            (conv1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (2): BasicBlock(
            (conv1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (layer2): Sequential(
          (0): BasicBlock(
            (conv1): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (downsample): Sequential(
              (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (1): BasicBlock(
            (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (2): BasicBlock(
            (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (3): BasicBlock(
            (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (layer3): Sequential(
          (0): BasicBlock(
            (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (downsample): Sequential(
              (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
              (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (1): BasicBlock(
            (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (2): BasicBlock(
            (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (3): BasicBlock(
            (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (4): BasicBlock(
            (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (5): BasicBlock(
            (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (layer4): Sequential(
          (0): BasicBlock(
            (conv1): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (downsample): Sequential(
              (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (1): BasicBlock(
            (conv1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (2): BasicBlock(
            (conv1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (3): BasicBlock(
            (conv1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (4): BasicBlock(
            (conv1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (5): BasicBlock(
            (conv1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (layer5): Sequential(
          (0): BasicBlock(
            (conv1): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (downsample): Sequential(
              (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (1): BasicBlock(
            (conv1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (2): BasicBlock(
            (conv1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
      )
      (positional_encoding): PositionalEncoding(
        (dropout): Dropout(p=0.15, inplace=False)
      )
      (trans_encoder): TransformerEncoder(
        (layers): ModuleList(
          (0-2): 3 x TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
              (conv1): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1))
              (conv2): Conv2d(768, 1536, kernel_size=(1, 1), stride=(1, 1))
              (conv3): Conv2d(768, 2304, kernel_size=(1, 1), stride=(1, 1))
            )
            (conv1): Conv2d(768, 2048, kernel_size=(1, 1), stride=(1, 1))
            (conv2): Conv2d(2048, 768, kernel_size=(1, 1), stride=(1, 1))
            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.15, inplace=False)
            (dropout2): Dropout(p=0.15, inplace=False)
          )
        )
        (pos_encoding): PositionalEncoding(
          (dropout): Dropout(p=0.0, inplace=False)
        )
      )
    )
    (semantic_branch): SEM_Pre(
      (embedding): Embeddings(
        (embedding): Embedding(81, 768, padding_idx=0)
      )
      (positional_encoding): PositionalEncoding(
        (dropout): Dropout(p=0.15, inplace=False)
      )
    )
    (positional_branch): POS_Pre(
      (pos_encoding): PositionalEncoding(
        (dropout): Dropout(p=0.15, inplace=False)
      )
      (linear1): Linear(in_features=768, out_features=768, bias=True)
      (linear2): Linear(in_features=768, out_features=768, bias=True)
      (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    )
    (mdcdp): MDCDP(
      (layers_pos): ModuleList(
        (0-2): 3 x CommonAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): Linear(in_features=768, out_features=768, bias=True)
            (conv1): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1))
            (conv2): Conv2d(768, 1536, kernel_size=(1, 1), stride=(1, 1))
            (conv3): Conv2d(768, 2304, kernel_size=(1, 1), stride=(1, 1))
          )
          (linear1): Linear(in_features=768, out_features=1024, bias=True)
          (dropout): Dropout(p=0.05, inplace=False)
          (linear2): Linear(in_features=1024, out_features=768, bias=True)
          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (dropout2): Dropout(p=0.15, inplace=False)
          (dropout3): Dropout(p=0.15, inplace=False)
        )
      )
      (layers2): ModuleList(
        (0-2): 3 x CommonAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): Linear(in_features=768, out_features=768, bias=True)
            (conv1): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1))
            (conv2): Conv2d(768, 1536, kernel_size=(1, 1), stride=(1, 1))
            (conv3): Conv2d(768, 2304, kernel_size=(1, 1), stride=(1, 1))
          )
          (linear1): Linear(in_features=768, out_features=1024, bias=True)
          (dropout): Dropout(p=0.05, inplace=False)
          (linear2): Linear(in_features=1024, out_features=768, bias=True)
          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (dropout2): Dropout(p=0.15, inplace=False)
          (dropout3): Dropout(p=0.15, inplace=False)
        )
      )
      (layers3): ModuleList(
        (0-2): 3 x CommonAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): Linear(in_features=768, out_features=768, bias=True)
            (conv1): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1))
            (conv2): Conv2d(768, 1536, kernel_size=(1, 1), stride=(1, 1))
            (conv3): Conv2d(768, 2304, kernel_size=(1, 1), stride=(1, 1))
          )
          (linear1): Linear(in_features=768, out_features=1024, bias=True)
          (dropout): Dropout(p=0.05, inplace=False)
          (linear2): Linear(in_features=1024, out_features=768, bias=True)
          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (dropout2): Dropout(p=0.15, inplace=False)
          (dropout3): Dropout(p=0.15, inplace=False)
        )
      )
      (dynamic_shared_fusion): DSF(
        (w_att): Linear(in_features=1024, out_features=512, bias=True)
      )
    )
    (tgt_word_prj): Linear(in_features=768, out_features=81, bias=False)
  )
)
2026-01-05 09:39:35,704 - CDistNet - INFO - model parameter:-------
Trainable: 65.501256 M
2026-01-05 09:39:35,705 - CDistNet - INFO - model struct:-------
DataParallel(
  (module): CDistNet(
    (visual_branch): VIS_Pre(
      (transform): TPS_SpatialTransformerNetwork(
        (LocalizationNetwork): LocalizationNetwork(
          (conv): Sequential(
            (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU(inplace=True)
            (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
            (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (6): ReLU(inplace=True)
            (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
            (8): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (9): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (10): ReLU(inplace=True)
            (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
            (12): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (13): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (14): ReLU(inplace=True)
            (15): AdaptiveAvgPool2d(output_size=1)
          )
          (localization_fc1): Sequential(
            (0): Linear(in_features=512, out_features=256, bias=True)
            (1): ReLU(inplace=True)
          )
          (localization_fc2): Linear(in_features=256, out_features=40, bias=True)
        )
        (GridGenerator): GridGenerator()
      )
      (backbone): ABI_ResNet(
        (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (convbnrelu): ConvBnRelu(
          (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
          (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (layer1): Sequential(
          (0): BasicBlock(
            (conv1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (downsample): Sequential(
              (0): Conv2d(32, 32, kernel_size=(1, 1), stride=(2, 2), bias=False)
              (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (1): BasicBlock(
            (conv1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (2): BasicBlock(
            (conv1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (layer2): Sequential(
          (0): BasicBlock(
            (conv1): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (downsample): Sequential(
              (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (1): BasicBlock(
            (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (2): BasicBlock(
            (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (3): BasicBlock(
            (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (layer3): Sequential(
          (0): BasicBlock(
            (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (downsample): Sequential(
              (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
              (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (1): BasicBlock(
            (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (2): BasicBlock(
            (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (3): BasicBlock(
            (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (4): BasicBlock(
            (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (5): BasicBlock(
            (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (layer4): Sequential(
          (0): BasicBlock(
            (conv1): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (downsample): Sequential(
              (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (1): BasicBlock(
            (conv1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (2): BasicBlock(
            (conv1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (3): BasicBlock(
            (conv1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (4): BasicBlock(
            (conv1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (5): BasicBlock(
            (conv1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (layer5): Sequential(
          (0): BasicBlock(
            (conv1): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (downsample): Sequential(
              (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (1): BasicBlock(
            (conv1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (2): BasicBlock(
            (conv1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
      )
      (positional_encoding): PositionalEncoding(
        (dropout): Dropout(p=0.15, inplace=False)
      )
      (trans_encoder): TransformerEncoder(
        (layers): ModuleList(
          (0-2): 3 x TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): Linear(in_features=512, out_features=512, bias=True)
              (conv1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
              (conv2): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1))
              (conv3): Conv2d(512, 1536, kernel_size=(1, 1), stride=(1, 1))
            )
            (conv1): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1))
            (conv2): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1))
            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.15, inplace=False)
            (dropout2): Dropout(p=0.15, inplace=False)
          )
        )
        (pos_encoding): PositionalEncoding(
          (dropout): Dropout(p=0.0, inplace=False)
        )
      )
    )
    (semantic_branch): SEM_Pre(
      (embedding): Embeddings(
        (embedding): Embedding(81, 512, padding_idx=0)
      )
      (positional_encoding): PositionalEncoding(
        (dropout): Dropout(p=0.15, inplace=False)
      )
    )
    (positional_branch): POS_Pre(
      (pos_encoding): PositionalEncoding(
        (dropout): Dropout(p=0.15, inplace=False)
      )
      (linear1): Linear(in_features=512, out_features=512, bias=True)
      (linear2): Linear(in_features=512, out_features=512, bias=True)
      (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    )
    (mdcdp): MDCDP(
      (layers_pos): ModuleList(
        (0-2): 3 x CommonAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
            (conv1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
            (conv2): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1))
            (conv3): Conv2d(512, 1536, kernel_size=(1, 1), stride=(1, 1))
          )
          (linear1): Linear(in_features=512, out_features=1024, bias=True)
          (dropout): Dropout(p=0.05, inplace=False)
          (linear2): Linear(in_features=1024, out_features=512, bias=True)
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (dropout2): Dropout(p=0.15, inplace=False)
          (dropout3): Dropout(p=0.15, inplace=False)
        )
      )
      (layers2): ModuleList(
        (0-2): 3 x CommonAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
            (conv1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
            (conv2): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1))
            (conv3): Conv2d(512, 1536, kernel_size=(1, 1), stride=(1, 1))
          )
          (linear1): Linear(in_features=512, out_features=1024, bias=True)
          (dropout): Dropout(p=0.05, inplace=False)
          (linear2): Linear(in_features=1024, out_features=512, bias=True)
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (dropout2): Dropout(p=0.15, inplace=False)
          (dropout3): Dropout(p=0.15, inplace=False)
        )
      )
      (layers3): ModuleList(
        (0-2): 3 x CommonAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
            (conv1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
            (conv2): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1))
            (conv3): Conv2d(512, 1536, kernel_size=(1, 1), stride=(1, 1))
          )
          (linear1): Linear(in_features=512, out_features=1024, bias=True)
          (dropout): Dropout(p=0.05, inplace=False)
          (linear2): Linear(in_features=1024, out_features=512, bias=True)
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (dropout2): Dropout(p=0.15, inplace=False)
          (dropout3): Dropout(p=0.15, inplace=False)
        )
      )
      (dynamic_shared_fusion): DSF(
        (w_att): Linear(in_features=1024, out_features=512, bias=True)
      )
    )
    (tgt_word_prj): Linear(in_features=512, out_features=81, bias=False)
  )
)
2026-01-05 09:39:36,637 - CDistNet - INFO - epoch: 0  iter: 0/1  loss:  4.724386  lr:  0.000000  eta: 0:00:00
2026-01-05 09:39:36,637 - CDistNet - INFO - Now: best_acc in epoch:0,iteration:0
2026-01-05 09:39:36,638 - CDistNet - INFO -   - (Training)   loss:  4.72439, accuracy: 1.176 %, time: 0.016 min
2026-01-05 09:39:37,139 - CDistNet - INFO - epoch: 1  iter: 0/1  loss:  4.713113  lr:  0.000000  eta: 0:00:00
2026-01-05 09:39:37,139 - CDistNet - INFO - Now: best_acc in epoch:0,iteration:0
2026-01-05 09:39:37,140 - CDistNet - INFO -   - (Training)   loss:  4.71311, accuracy: 1.176 %, time: 0.008 min
2026-01-05 09:39:37,637 - CDistNet - INFO - epoch: 2  iter: 0/1  loss:  4.716096  lr:  0.000000  eta: 0:00:00
2026-01-05 09:39:37,638 - CDistNet - INFO - Now: best_acc in epoch:0,iteration:0
2026-01-05 09:39:37,638 - CDistNet - INFO -   - (Training)   loss:  4.71610, accuracy: 0.196 %, time: 0.008 min
2026-01-05 09:39:38,137 - CDistNet - INFO - epoch: 3  iter: 0/1  loss:  4.738621  lr:  0.000000  eta: 0:00:00
2026-01-05 09:39:38,137 - CDistNet - INFO - Now: best_acc in epoch:0,iteration:0
2026-01-05 09:39:38,138 - CDistNet - INFO -   - (Training)   loss:  4.73862, accuracy: 1.373 %, time: 0.008 min
2026-01-05 09:39:38,636 - CDistNet - INFO - epoch: 4  iter: 0/1  loss:  4.727367  lr:  0.000000  eta: 0:00:00
2026-01-05 09:39:38,636 - CDistNet - INFO - Now: best_acc in epoch:0,iteration:0
2026-01-05 09:39:38,637 - CDistNet - INFO -   - (Training)   loss:  4.72737, accuracy: 0.588 %, time: 0.008 min
2026-01-05 09:39:39,138 - CDistNet - INFO - epoch: 5  iter: 0/1  loss:  4.710626  lr:  0.000000  eta: 0:00:00
2026-01-05 09:39:39,138 - CDistNet - INFO - Now: best_acc in epoch:0,iteration:0
2026-01-05 09:39:39,139 - CDistNet - INFO -   - (Training)   loss:  4.71063, accuracy: 0.392 %, time: 0.008 min
2026-01-05 09:39:39,638 - CDistNet - INFO - epoch: 6  iter: 0/1  loss:  4.755153  lr:  0.000000  eta: 0:00:00
2026-01-05 09:39:39,888 - CDistNet - INFO - eval_loss:4.4879,eval_acc:0.0000--------

2026-01-05 09:39:39,889 - CDistNet - INFO - Now: best_acc in epoch:0,iteration:0
2026-01-05 09:39:39,890 - CDistNet - INFO -   - (Training)   loss:  4.75515, accuracy: 1.176 %, time: 0.013 min
2026-01-05 09:39:39,890 - CDistNet - INFO - Start eval ...
2026-01-05 09:39:40,097 - CDistNet - INFO -   - (Validation)   loss:  4.48794, accuracy: 0.000 %, time: 0.003 min
2026-01-05 09:39:40,097 - CDistNet - INFO - Saving model ...
2026-01-05 09:39:40,360 - CDistNet - INFO - Saved!
2026-01-05 09:39:40,862 - CDistNet - INFO - epoch: 7  iter: 0/1  loss:  4.737243  lr:  0.000010  eta: 0:00:00
2026-01-05 09:39:41,065 - CDistNet - INFO - eval_loss:4.2753,eval_acc:0.1200--------

2026-01-05 09:39:41,065 - CDistNet - INFO - Saving model: best_acc in epoch:7,iteration:0
2026-01-05 09:39:41,294 - CDistNet - INFO - Saved!
2026-01-05 09:39:41,296 - CDistNet - INFO - Now: best_acc in epoch:7,iteration:0
2026-01-05 09:39:41,296 - CDistNet - INFO -   - (Training)   loss:  4.73724, accuracy: 1.176 %, time: 0.016 min
2026-01-05 09:39:41,296 - CDistNet - INFO - Start eval ...
2026-01-05 09:39:41,502 - CDistNet - INFO -   - (Validation)   loss:  4.27527, accuracy: 12.000 %, time: 0.003 min
2026-01-05 09:39:41,502 - CDistNet - INFO - Saving model ...
2026-01-05 09:39:41,749 - CDistNet - INFO - Saved!
2026-01-05 09:39:42,249 - CDistNet - INFO - epoch: 8  iter: 0/1  loss:  4.583358  lr:  0.000010  eta: 0:00:00
2026-01-05 09:39:42,465 - CDistNet - INFO - eval_loss:4.1164,eval_acc:0.1467--------

2026-01-05 09:39:42,466 - CDistNet - INFO - Saving model: best_acc in epoch:8,iteration:0
2026-01-05 09:39:42,735 - CDistNet - INFO - Saved!
2026-01-05 09:39:42,737 - CDistNet - INFO - Now: best_acc in epoch:8,iteration:0
2026-01-05 09:39:42,737 - CDistNet - INFO -   - (Training)   loss:  4.58336, accuracy: 3.725 %, time: 0.016 min
2026-01-05 09:39:42,738 - CDistNet - INFO - Start eval ...
2026-01-05 09:39:42,943 - CDistNet - INFO -   - (Validation)   loss:  4.11638, accuracy: 14.667 %, time: 0.003 min
2026-01-05 09:39:42,943 - CDistNet - INFO - Saving model ...
2026-01-05 09:39:43,185 - CDistNet - INFO - Saved!
2026-01-05 09:39:43,684 - CDistNet - INFO - epoch: 9  iter: 0/1  loss:  4.357809  lr:  0.000010  eta: 0:00:00
2026-01-05 09:39:43,890 - CDistNet - INFO - eval_loss:4.0052,eval_acc:0.1467--------

2026-01-05 09:39:43,891 - CDistNet - INFO - Saving model: best_acc in epoch:9,iteration:0
2026-01-05 09:39:44,154 - CDistNet - INFO - Saved!
2026-01-05 09:39:44,154 - CDistNet - INFO - Saving last epoch model in epoch:9,iteration:0
2026-01-05 09:39:44,422 - CDistNet - INFO - Saved!
2026-01-05 09:39:44,423 - CDistNet - INFO - Now: best_acc in epoch:9,iteration:0
2026-01-05 09:39:44,424 - CDistNet - INFO -   - (Training)   loss:  4.35781, accuracy: 10.000 %, time: 0.021 min
2026-01-05 09:39:44,424 - CDistNet - INFO - Start eval ...
2026-01-05 09:39:44,628 - CDistNet - INFO -   - (Validation)   loss:  4.00524, accuracy: 14.667 %, time: 0.003 min
2026-01-05 09:39:44,628 - CDistNet - INFO - Saving model ...
2026-01-05 09:39:44,870 - CDistNet - INFO - Saved!
2026-01-05 09:39:45,367 - CDistNet - INFO - epoch: 10  iter: 0/1  loss:  4.246517  lr:  0.000010  eta: 0:00:00
2026-01-05 09:39:45,586 - CDistNet - INFO - eval_loss:3.9326,eval_acc:0.1467--------

2026-01-05 09:39:45,587 - CDistNet - INFO - Saving model: best_acc in epoch:10,iteration:0
2026-01-05 09:39:45,861 - CDistNet - INFO - Saved!
2026-01-05 09:39:45,861 - CDistNet - INFO - Saving last epoch model in epoch:10,iteration:0
2026-01-05 09:39:46,109 - CDistNet - INFO - Saved!
2026-01-05 09:39:46,109 - CDistNet - INFO - Now: best_acc in epoch:10,iteration:0
2026-01-05 09:39:46,110 - CDistNet - INFO -   - (Training)   loss:  4.24652, accuracy: 13.725 %, time: 0.021 min
2026-01-05 09:39:46,110 - CDistNet - INFO - Start eval ...
2026-01-05 09:39:46,315 - CDistNet - INFO -   - (Validation)   loss:  3.93264, accuracy: 14.667 %, time: 0.003 min
2026-01-05 09:39:46,315 - CDistNet - INFO - Saving model ...
2026-01-05 09:39:46,555 - CDistNet - INFO - Saved!
2026-01-05 09:39:47,058 - CDistNet - INFO - epoch: 11  iter: 0/1  loss:  4.123199  lr:  0.000010  eta: 0:00:00
2026-01-05 09:39:47,260 - CDistNet - INFO - eval_loss:3.8808,eval_acc:0.1467--------

2026-01-05 09:39:47,261 - CDistNet - INFO - Saving model: best_acc in epoch:11,iteration:0
2026-01-05 09:39:47,497 - CDistNet - INFO - Saved!
2026-01-05 09:39:47,497 - CDistNet - INFO - Saving last epoch model in epoch:11,iteration:0
2026-01-05 09:39:47,742 - CDistNet - INFO - Saved!
2026-01-05 09:39:47,743 - CDistNet - INFO - Now: best_acc in epoch:11,iteration:0
2026-01-05 09:39:47,743 - CDistNet - INFO -   - (Training)   loss:  4.12320, accuracy: 14.902 %, time: 0.020 min
2026-01-05 09:39:47,744 - CDistNet - INFO - Start eval ...
2026-01-05 09:39:47,948 - CDistNet - INFO -   - (Validation)   loss:  3.88079, accuracy: 14.667 %, time: 0.003 min
2026-01-05 09:39:47,948 - CDistNet - INFO - Saving model ...
2026-01-05 09:39:48,190 - CDistNet - INFO - Saved!
2026-01-05 09:39:48,689 - CDistNet - INFO - epoch: 12  iter: 0/1  loss:  4.041525  lr:  0.000010  eta: 0:00:00
2026-01-05 09:39:48,890 - CDistNet - INFO - eval_loss:3.8364,eval_acc:0.1467--------

2026-01-05 09:39:48,891 - CDistNet - INFO - Saving model: best_acc in epoch:12,iteration:0
2026-01-05 09:39:49,133 - CDistNet - INFO - Saved!
2026-01-05 09:39:49,133 - CDistNet - INFO - Saving last epoch model in epoch:12,iteration:0
2026-01-05 09:39:49,368 - CDistNet - INFO - Saved!
2026-01-05 09:39:49,370 - CDistNet - INFO - Now: best_acc in epoch:12,iteration:0
2026-01-05 09:39:49,371 - CDistNet - INFO -   - (Training)   loss:  4.04152, accuracy: 14.902 %, time: 0.020 min
2026-01-05 09:39:49,371 - CDistNet - INFO - Start eval ...
2026-01-05 09:39:49,576 - CDistNet - INFO -   - (Validation)   loss:  3.83645, accuracy: 14.667 %, time: 0.003 min
2026-01-05 09:39:49,576 - CDistNet - INFO - Saving model ...
2026-01-05 09:39:49,819 - CDistNet - INFO - Saved!
2026-01-05 09:39:50,321 - CDistNet - INFO - epoch: 13  iter: 0/1  loss:  3.958568  lr:  0.000010  eta: 0:00:00
2026-01-05 09:39:50,525 - CDistNet - INFO - eval_loss:3.7846,eval_acc:0.1467--------

2026-01-05 09:39:50,526 - CDistNet - INFO - Saving model: best_acc in epoch:13,iteration:0
2026-01-05 09:39:50,777 - CDistNet - INFO - Saved!
2026-01-05 09:39:50,777 - CDistNet - INFO - Saving last epoch model in epoch:13,iteration:0
2026-01-05 09:39:51,035 - CDistNet - INFO - Saved!
2026-01-05 09:39:51,036 - CDistNet - INFO - Now: best_acc in epoch:13,iteration:0
2026-01-05 09:39:51,037 - CDistNet - INFO -   - (Training)   loss:  3.95857, accuracy: 14.706 %, time: 0.020 min
2026-01-05 09:39:51,037 - CDistNet - INFO - Start eval ...
2026-01-05 09:39:51,243 - CDistNet - INFO -   - (Validation)   loss:  3.78461, accuracy: 14.667 %, time: 0.003 min
2026-01-05 09:39:51,243 - CDistNet - INFO - Saving model ...
2026-01-05 09:39:51,497 - CDistNet - INFO - Saved!
2026-01-05 09:39:51,996 - CDistNet - INFO - epoch: 14  iter: 0/1  loss:  3.870956  lr:  0.000010  eta: 0:00:00
2026-01-05 09:39:52,200 - CDistNet - INFO - eval_loss:3.7248,eval_acc:0.1467--------

2026-01-05 09:39:52,201 - CDistNet - INFO - Saving model: best_acc in epoch:14,iteration:0
2026-01-05 09:39:52,434 - CDistNet - INFO - Saved!
2026-01-05 09:39:52,434 - CDistNet - INFO - Saving last epoch model in epoch:14,iteration:0
2026-01-05 09:39:52,685 - CDistNet - INFO - Saved!
2026-01-05 09:39:52,686 - CDistNet - INFO - Now: best_acc in epoch:14,iteration:0
2026-01-05 09:39:52,686 - CDistNet - INFO -   - (Training)   loss:  3.87096, accuracy: 15.686 %, time: 0.020 min
2026-01-05 09:39:52,687 - CDistNet - INFO - Start eval ...
2026-01-05 09:39:52,891 - CDistNet - INFO -   - (Validation)   loss:  3.72481, accuracy: 14.667 %, time: 0.003 min
2026-01-05 09:39:52,891 - CDistNet - INFO - Saving model ...
2026-01-05 09:39:53,131 - CDistNet - INFO - Saved!
2026-01-05 09:39:53,628 - CDistNet - INFO - epoch: 15  iter: 0/1  loss:  3.800630  lr:  0.000010  eta: 0:00:00
2026-01-05 09:39:53,836 - CDistNet - INFO - eval_loss:3.6696,eval_acc:0.1467--------

2026-01-05 09:39:53,836 - CDistNet - INFO - Saving model: best_acc in epoch:15,iteration:0
2026-01-05 09:39:54,089 - CDistNet - INFO - Saved!
2026-01-05 09:39:54,089 - CDistNet - INFO - Saving last epoch model in epoch:15,iteration:0
2026-01-05 09:39:54,329 - CDistNet - INFO - Saved!
2026-01-05 09:39:54,330 - CDistNet - INFO - Now: best_acc in epoch:15,iteration:0
2026-01-05 09:39:54,330 - CDistNet - INFO -   - (Training)   loss:  3.80063, accuracy: 14.314 %, time: 0.020 min
2026-01-05 09:39:54,330 - CDistNet - INFO - Start eval ...
2026-01-05 09:39:54,534 - CDistNet - INFO -   - (Validation)   loss:  3.66965, accuracy: 14.667 %, time: 0.003 min
2026-01-05 09:39:54,534 - CDistNet - INFO - Saving model ...
2026-01-05 09:39:54,794 - CDistNet - INFO - Saved!
2026-01-05 09:39:55,294 - CDistNet - INFO - epoch: 16  iter: 0/1  loss:  3.764573  lr:  0.000010  eta: 0:00:00
2026-01-05 09:39:55,498 - CDistNet - INFO - eval_loss:3.6178,eval_acc:0.1467--------

2026-01-05 09:39:55,498 - CDistNet - INFO - Saving model: best_acc in epoch:16,iteration:0
2026-01-05 09:39:55,747 - CDistNet - INFO - Saved!
2026-01-05 09:39:55,747 - CDistNet - INFO - Saving last epoch model in epoch:16,iteration:0
2026-01-05 09:39:56,012 - CDistNet - INFO - Saved!
2026-01-05 09:39:56,013 - CDistNet - INFO - Now: best_acc in epoch:16,iteration:0
2026-01-05 09:39:56,014 - CDistNet - INFO -   - (Training)   loss:  3.76457, accuracy: 15.686 %, time: 0.020 min
2026-01-05 09:39:56,014 - CDistNet - INFO - Start eval ...
2026-01-05 09:39:56,218 - CDistNet - INFO -   - (Validation)   loss:  3.61777, accuracy: 14.667 %, time: 0.003 min
2026-01-05 09:39:56,218 - CDistNet - INFO - Saving model ...
2026-01-05 09:39:56,447 - CDistNet - INFO - Saved!
2026-01-05 09:39:56,944 - CDistNet - INFO - epoch: 17  iter: 0/1  loss:  3.684123  lr:  0.000010  eta: 0:00:00
2026-01-05 09:39:57,146 - CDistNet - INFO - eval_loss:3.5799,eval_acc:0.1467--------

2026-01-05 09:39:57,146 - CDistNet - INFO - Saving model: best_acc in epoch:17,iteration:0
2026-01-05 09:39:57,388 - CDistNet - INFO - Saved!
2026-01-05 09:39:57,389 - CDistNet - INFO - Saving last epoch model in epoch:17,iteration:0
2026-01-05 09:39:57,610 - CDistNet - INFO - Saved!
2026-01-05 09:39:57,611 - CDistNet - INFO - Now: best_acc in epoch:17,iteration:0
2026-01-05 09:39:57,612 - CDistNet - INFO -   - (Training)   loss:  3.68412, accuracy: 14.706 %, time: 0.019 min
2026-01-05 09:39:57,612 - CDistNet - INFO - Start eval ...
2026-01-05 09:39:57,815 - CDistNet - INFO -   - (Validation)   loss:  3.57994, accuracy: 14.667 %, time: 0.003 min
2026-01-05 09:39:57,815 - CDistNet - INFO - Saving model ...
2026-01-05 09:39:58,058 - CDistNet - INFO - Saved!
2026-01-05 09:39:58,555 - CDistNet - INFO - epoch: 18  iter: 0/1  loss:  3.631088  lr:  0.000010  eta: 0:00:00
2026-01-05 09:39:58,758 - CDistNet - INFO - eval_loss:3.5513,eval_acc:0.1533--------

2026-01-05 09:39:58,758 - CDistNet - INFO - Saving model: best_acc in epoch:18,iteration:0
2026-01-05 09:39:58,980 - CDistNet - INFO - Saved!
2026-01-05 09:39:58,980 - CDistNet - INFO - Saving last epoch model in epoch:18,iteration:0
2026-01-05 09:39:59,210 - CDistNet - INFO - Saved!
2026-01-05 09:39:59,211 - CDistNet - INFO - Now: best_acc in epoch:18,iteration:0
2026-01-05 09:39:59,211 - CDistNet - INFO -   - (Training)   loss:  3.63109, accuracy: 15.686 %, time: 0.019 min
2026-01-05 09:39:59,212 - CDistNet - INFO - Start eval ...
2026-01-05 09:39:59,415 - CDistNet - INFO -   - (Validation)   loss:  3.55128, accuracy: 15.333 %, time: 0.003 min
2026-01-05 09:39:59,415 - CDistNet - INFO - Saving model ...
2026-01-05 09:39:59,637 - CDistNet - INFO - Saved!
2026-01-05 09:40:00,136 - CDistNet - INFO - epoch: 19  iter: 0/1  loss:  3.557752  lr:  0.000010  eta: 0:00:00
2026-01-05 09:40:00,341 - CDistNet - INFO - eval_loss:3.5348,eval_acc:0.1667--------

2026-01-05 09:40:00,341 - CDistNet - INFO - Saving model: best_acc in epoch:19,iteration:0
2026-01-05 09:40:00,586 - CDistNet - INFO - Saved!
2026-01-05 09:40:00,586 - CDistNet - INFO - Saving last epoch model in epoch:19,iteration:0
2026-01-05 09:40:00,808 - CDistNet - INFO - Saved!
2026-01-05 09:40:00,809 - CDistNet - INFO - Now: best_acc in epoch:19,iteration:0
2026-01-05 09:40:00,810 - CDistNet - INFO -   - (Training)   loss:  3.55775, accuracy: 16.078 %, time: 0.020 min
2026-01-05 09:40:00,810 - CDistNet - INFO - Start eval ...
2026-01-05 09:40:01,011 - CDistNet - INFO -   - (Validation)   loss:  3.53478, accuracy: 16.667 %, time: 0.003 min
2026-01-05 09:40:01,011 - CDistNet - INFO - Saving model ...
2026-01-05 09:40:01,249 - CDistNet - INFO - Saved!
2026-01-05 09:40:01,745 - CDistNet - INFO - epoch: 20  iter: 0/1  loss:  3.573485  lr:  0.000010  eta: 0:00:00
2026-01-05 09:40:01,947 - CDistNet - INFO - eval_loss:3.5255,eval_acc:0.1667--------

2026-01-05 09:40:01,947 - CDistNet - INFO - Saving model: best_acc in epoch:20,iteration:0
2026-01-05 09:40:02,170 - CDistNet - INFO - Saved!
2026-01-05 09:40:02,170 - CDistNet - INFO - Saving last epoch model in epoch:20,iteration:0
2026-01-05 09:40:02,401 - CDistNet - INFO - Saved!
2026-01-05 09:40:02,403 - CDistNet - INFO - Now: best_acc in epoch:20,iteration:0
2026-01-05 09:40:02,403 - CDistNet - INFO -   - (Training)   loss:  3.57348, accuracy: 17.647 %, time: 0.019 min
2026-01-05 09:40:02,404 - CDistNet - INFO - Start eval ...
2026-01-05 09:40:02,607 - CDistNet - INFO -   - (Validation)   loss:  3.52553, accuracy: 16.667 %, time: 0.003 min
2026-01-05 09:40:02,608 - CDistNet - INFO - Saving model ...
2026-01-05 09:40:02,828 - CDistNet - INFO - Saved!
2026-01-05 09:40:03,325 - CDistNet - INFO - epoch: 21  iter: 0/1  loss:  3.549937  lr:  0.000010  eta: 0:00:00
2026-01-05 09:40:03,529 - CDistNet - INFO - eval_loss:3.5249,eval_acc:0.1600--------

2026-01-05 09:40:03,529 - CDistNet - INFO - Saving model: best_acc in epoch:21,iteration:0
2026-01-05 09:40:03,771 - CDistNet - INFO - Saved!
2026-01-05 09:40:03,771 - CDistNet - INFO - Saving last epoch model in epoch:21,iteration:0
2026-01-05 09:40:04,025 - CDistNet - INFO - Saved!
2026-01-05 09:40:04,026 - CDistNet - INFO - Now: best_acc in epoch:21,iteration:0
2026-01-05 09:40:04,026 - CDistNet - INFO -   - (Training)   loss:  3.54994, accuracy: 14.902 %, time: 0.020 min
2026-01-05 09:40:04,027 - CDistNet - INFO - Start eval ...
2026-01-05 09:40:04,230 - CDistNet - INFO -   - (Validation)   loss:  3.52486, accuracy: 16.000 %, time: 0.003 min
2026-01-05 09:40:04,230 - CDistNet - INFO - Saving model ...
2026-01-05 09:40:04,452 - CDistNet - INFO - Saved!
2026-01-05 09:40:04,950 - CDistNet - INFO - epoch: 22  iter: 0/1  loss:  3.476585  lr:  0.000010  eta: 0:00:00
2026-01-05 09:40:05,154 - CDistNet - INFO - eval_loss:3.5259,eval_acc:0.1533--------

2026-01-05 09:40:05,154 - CDistNet - INFO - Saving model: best_acc in epoch:22,iteration:0
2026-01-05 09:40:05,399 - CDistNet - INFO - Saved!
2026-01-05 09:40:05,399 - CDistNet - INFO - Saving last epoch model in epoch:22,iteration:0
2026-01-05 09:40:05,626 - CDistNet - INFO - Saved!
2026-01-05 09:40:05,627 - CDistNet - INFO - Now: best_acc in epoch:22,iteration:0
2026-01-05 09:40:05,627 - CDistNet - INFO -   - (Training)   loss:  3.47658, accuracy: 17.647 %, time: 0.020 min
2026-01-05 09:40:05,627 - CDistNet - INFO - Start eval ...
2026-01-05 09:40:05,830 - CDistNet - INFO -   - (Validation)   loss:  3.52593, accuracy: 15.333 %, time: 0.003 min
2026-01-05 09:40:05,830 - CDistNet - INFO - Saving model ...
2026-01-05 09:40:06,059 - CDistNet - INFO - Saved!
2026-01-05 09:40:06,557 - CDistNet - INFO - epoch: 23  iter: 0/1  loss:  3.492534  lr:  0.000010  eta: 0:00:00
2026-01-05 09:40:06,759 - CDistNet - INFO - eval_loss:3.5258,eval_acc:0.1533--------

2026-01-05 09:40:06,760 - CDistNet - INFO - Saving model: best_acc in epoch:23,iteration:0
2026-01-05 09:40:06,984 - CDistNet - INFO - Saved!
2026-01-05 09:40:06,984 - CDistNet - INFO - Saving last epoch model in epoch:23,iteration:0
2026-01-05 09:40:07,218 - CDistNet - INFO - Saved!
2026-01-05 09:40:07,219 - CDistNet - INFO - Now: best_acc in epoch:23,iteration:0
2026-01-05 09:40:07,220 - CDistNet - INFO -   - (Training)   loss:  3.49253, accuracy: 17.451 %, time: 0.019 min
2026-01-05 09:40:07,220 - CDistNet - INFO - Start eval ...
2026-01-05 09:40:07,424 - CDistNet - INFO -   - (Validation)   loss:  3.52583, accuracy: 15.333 %, time: 0.003 min
2026-01-05 09:40:07,425 - CDistNet - INFO - Saving model ...
2026-01-05 09:40:07,650 - CDistNet - INFO - Saved!
2026-01-05 09:40:08,147 - CDistNet - INFO - epoch: 24  iter: 0/1  loss:  3.482824  lr:  0.000010  eta: 0:00:00
2026-01-05 09:40:08,350 - CDistNet - INFO - eval_loss:3.5231,eval_acc:0.1533--------

2026-01-05 09:40:08,350 - CDistNet - INFO - Saving model: best_acc in epoch:24,iteration:0
2026-01-05 09:40:08,574 - CDistNet - INFO - Saved!
2026-01-05 09:40:08,575 - CDistNet - INFO - Saving last epoch model in epoch:24,iteration:0
2026-01-05 09:40:08,811 - CDistNet - INFO - Saved!
2026-01-05 09:40:08,812 - CDistNet - INFO - Now: best_acc in epoch:24,iteration:0
2026-01-05 09:40:08,813 - CDistNet - INFO -   - (Training)   loss:  3.48282, accuracy: 16.471 %, time: 0.019 min
2026-01-05 09:40:08,813 - CDistNet - INFO - Start eval ...
2026-01-05 09:40:09,015 - CDistNet - INFO -   - (Validation)   loss:  3.52310, accuracy: 15.333 %, time: 0.003 min
2026-01-05 09:40:09,016 - CDistNet - INFO - Saving model ...
2026-01-05 09:40:09,236 - CDistNet - INFO - Saved!
2026-01-05 09:40:09,734 - CDistNet - INFO - epoch: 25  iter: 0/1  loss:  3.443914  lr:  0.000010  eta: 0:00:00
2026-01-05 09:40:09,936 - CDistNet - INFO - eval_loss:3.5224,eval_acc:0.1600--------

2026-01-05 09:40:09,936 - CDistNet - INFO - Saving model: best_acc in epoch:25,iteration:0
2026-01-05 09:40:10,165 - CDistNet - INFO - Saved!
2026-01-05 09:40:10,165 - CDistNet - INFO - Saving last epoch model in epoch:25,iteration:0
2026-01-05 09:40:10,402 - CDistNet - INFO - Saved!
2026-01-05 09:40:10,403 - CDistNet - INFO - Now: best_acc in epoch:25,iteration:0
2026-01-05 09:40:10,404 - CDistNet - INFO -   - (Training)   loss:  3.44391, accuracy: 18.627 %, time: 0.019 min
2026-01-05 09:40:10,404 - CDistNet - INFO - Start eval ...
2026-01-05 09:40:10,607 - CDistNet - INFO -   - (Validation)   loss:  3.52235, accuracy: 16.000 %, time: 0.003 min
2026-01-05 09:40:10,607 - CDistNet - INFO - Saving model ...
2026-01-05 09:40:10,831 - CDistNet - INFO - Saved!
2026-01-05 09:40:11,330 - CDistNet - INFO - epoch: 26  iter: 0/1  loss:  3.413847  lr:  0.000010  eta: 0:00:00
2026-01-05 09:40:11,535 - CDistNet - INFO - eval_loss:3.5251,eval_acc:0.1600--------

2026-01-05 09:40:11,535 - CDistNet - INFO - Saving model: best_acc in epoch:26,iteration:0
2026-01-05 09:40:11,772 - CDistNet - INFO - Saved!
2026-01-05 09:40:11,772 - CDistNet - INFO - Saving last epoch model in epoch:26,iteration:0
2026-01-05 09:40:12,009 - CDistNet - INFO - Saved!
2026-01-05 09:40:12,010 - CDistNet - INFO - Now: best_acc in epoch:26,iteration:0
2026-01-05 09:40:12,011 - CDistNet - INFO -   - (Training)   loss:  3.41385, accuracy: 17.843 %, time: 0.020 min
2026-01-05 09:40:12,011 - CDistNet - INFO - Start eval ...
2026-01-05 09:40:12,216 - CDistNet - INFO -   - (Validation)   loss:  3.52511, accuracy: 16.000 %, time: 0.003 min
2026-01-05 09:40:12,216 - CDistNet - INFO - Saving model ...
2026-01-05 09:40:12,443 - CDistNet - INFO - Saved!
2026-01-05 09:40:12,941 - CDistNet - INFO - epoch: 27  iter: 0/1  loss:  3.368202  lr:  0.000010  eta: 0:00:00
2026-01-05 09:40:13,145 - CDistNet - INFO - eval_loss:3.5272,eval_acc:0.1600--------

2026-01-05 09:40:13,145 - CDistNet - INFO - Saving model: best_acc in epoch:27,iteration:0
2026-01-05 09:40:13,372 - CDistNet - INFO - Saved!
2026-01-05 09:40:13,372 - CDistNet - INFO - Saving last epoch model in epoch:27,iteration:0
2026-01-05 09:40:13,608 - CDistNet - INFO - Saved!
2026-01-05 09:40:13,609 - CDistNet - INFO - Now: best_acc in epoch:27,iteration:0
2026-01-05 09:40:13,610 - CDistNet - INFO -   - (Training)   loss:  3.36820, accuracy: 19.412 %, time: 0.019 min
2026-01-05 09:40:13,610 - CDistNet - INFO - Start eval ...
2026-01-05 09:40:13,811 - CDistNet - INFO -   - (Validation)   loss:  3.52718, accuracy: 16.000 %, time: 0.003 min
2026-01-05 09:40:13,812 - CDistNet - INFO - Saving model ...
2026-01-05 09:40:14,036 - CDistNet - INFO - Saved!
2026-01-05 09:40:14,536 - CDistNet - INFO - epoch: 28  iter: 0/1  loss:  3.355230  lr:  0.000010  eta: 0:00:00
2026-01-05 09:40:14,739 - CDistNet - INFO - eval_loss:3.5327,eval_acc:0.1578--------

2026-01-05 09:40:14,740 - CDistNet - INFO - Saving model: best_acc in epoch:28,iteration:0
2026-01-05 09:40:14,979 - CDistNet - INFO - Saved!
2026-01-05 09:40:14,979 - CDistNet - INFO - Saving last epoch model in epoch:28,iteration:0
2026-01-05 09:40:15,218 - CDistNet - INFO - Saved!
2026-01-05 09:40:15,219 - CDistNet - INFO - Now: best_acc in epoch:28,iteration:0
2026-01-05 09:40:15,220 - CDistNet - INFO -   - (Training)   loss:  3.35523, accuracy: 20.980 %, time: 0.020 min
2026-01-05 09:40:15,220 - CDistNet - INFO - Start eval ...
2026-01-05 09:40:15,422 - CDistNet - INFO -   - (Validation)   loss:  3.53274, accuracy: 15.778 %, time: 0.003 min
2026-01-05 09:40:15,422 - CDistNet - INFO - Saving model ...
2026-01-05 09:40:15,646 - CDistNet - INFO - Saved!
2026-01-05 09:40:16,144 - CDistNet - INFO - epoch: 29  iter: 0/1  loss:  3.350998  lr:  0.000010  eta: 0:00:00
2026-01-05 09:40:16,350 - CDistNet - INFO - eval_loss:3.5385,eval_acc:0.1578--------

2026-01-05 09:40:16,350 - CDistNet - INFO - Saving model: best_acc in epoch:29,iteration:0
2026-01-05 09:40:16,586 - CDistNet - INFO - Saved!
2026-01-05 09:40:16,587 - CDistNet - INFO - Saving last epoch model in epoch:29,iteration:0
2026-01-05 09:40:16,823 - CDistNet - INFO - Saved!
2026-01-05 09:40:16,824 - CDistNet - INFO - Now: best_acc in epoch:29,iteration:0
2026-01-05 09:40:16,825 - CDistNet - INFO -   - (Training)   loss:  3.35100, accuracy: 19.608 %, time: 0.020 min
2026-01-05 09:40:16,825 - CDistNet - INFO - Start eval ...
2026-01-05 09:40:17,029 - CDistNet - INFO -   - (Validation)   loss:  3.53850, accuracy: 15.778 %, time: 0.003 min
2026-01-05 09:40:17,029 - CDistNet - INFO - Saving model ...
2026-01-05 09:40:17,249 - CDistNet - INFO - Saved!
2026-01-05 09:40:17,746 - CDistNet - INFO - epoch: 30  iter: 0/1  loss:  3.329795  lr:  0.000010  eta: 0:00:00
2026-01-05 09:40:17,949 - CDistNet - INFO - eval_loss:3.5421,eval_acc:0.1622--------

2026-01-05 09:40:17,949 - CDistNet - INFO - Saving model: best_acc in epoch:30,iteration:0
2026-01-05 09:40:18,178 - CDistNet - INFO - Saved!
2026-01-05 09:40:18,178 - CDistNet - INFO - Saving last epoch model in epoch:30,iteration:0
2026-01-05 09:40:18,416 - CDistNet - INFO - Saved!
2026-01-05 09:40:18,417 - CDistNet - INFO - Now: best_acc in epoch:30,iteration:0
2026-01-05 09:40:18,418 - CDistNet - INFO -   - (Training)   loss:  3.32980, accuracy: 20.784 %, time: 0.019 min
2026-01-05 09:40:18,418 - CDistNet - INFO - Start eval ...
2026-01-05 09:40:18,621 - CDistNet - INFO -   - (Validation)   loss:  3.54205, accuracy: 16.222 %, time: 0.003 min
2026-01-05 09:40:18,621 - CDistNet - INFO - Saving model ...
2026-01-05 09:40:18,843 - CDistNet - INFO - Saved!
2026-01-05 09:46:44,250 - CDistNet - INFO - model parameter:-------
Trainable: 65.499528 M
2026-01-05 09:46:44,251 - CDistNet - INFO - model struct:-------
DataParallel(
  (module): CDistNet(
    (visual_branch): VIS_Pre(
      (transform): TPS_SpatialTransformerNetwork(
        (LocalizationNetwork): LocalizationNetwork(
          (conv): Sequential(
            (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU(inplace=True)
            (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
            (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (6): ReLU(inplace=True)
            (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
            (8): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (9): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (10): ReLU(inplace=True)
            (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
            (12): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (13): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (14): ReLU(inplace=True)
            (15): AdaptiveAvgPool2d(output_size=1)
          )
          (localization_fc1): Sequential(
            (0): Linear(in_features=512, out_features=256, bias=True)
            (1): ReLU(inplace=True)
          )
          (localization_fc2): Linear(in_features=256, out_features=40, bias=True)
        )
        (GridGenerator): GridGenerator()
      )
      (backbone): ABI_ResNet(
        (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (convbnrelu): ConvBnRelu(
          (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
          (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (layer1): Sequential(
          (0): BasicBlock(
            (conv1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (downsample): Sequential(
              (0): Conv2d(32, 32, kernel_size=(1, 1), stride=(2, 2), bias=False)
              (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (1): BasicBlock(
            (conv1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (2): BasicBlock(
            (conv1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (layer2): Sequential(
          (0): BasicBlock(
            (conv1): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (downsample): Sequential(
              (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (1): BasicBlock(
            (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (2): BasicBlock(
            (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (3): BasicBlock(
            (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (layer3): Sequential(
          (0): BasicBlock(
            (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (downsample): Sequential(
              (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
              (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (1): BasicBlock(
            (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (2): BasicBlock(
            (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (3): BasicBlock(
            (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (4): BasicBlock(
            (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (5): BasicBlock(
            (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (layer4): Sequential(
          (0): BasicBlock(
            (conv1): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (downsample): Sequential(
              (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (1): BasicBlock(
            (conv1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (2): BasicBlock(
            (conv1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (3): BasicBlock(
            (conv1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (4): BasicBlock(
            (conv1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (5): BasicBlock(
            (conv1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (layer5): Sequential(
          (0): BasicBlock(
            (conv1): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (downsample): Sequential(
              (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (1): BasicBlock(
            (conv1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (2): BasicBlock(
            (conv1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
      )
      (positional_encoding): PositionalEncoding(
        (dropout): Dropout(p=0.15, inplace=False)
      )
      (trans_encoder): TransformerEncoder(
        (layers): ModuleList(
          (0-2): 3 x TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): Linear(in_features=512, out_features=512, bias=True)
              (conv1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
              (conv2): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1))
              (conv3): Conv2d(512, 1536, kernel_size=(1, 1), stride=(1, 1))
            )
            (conv1): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1))
            (conv2): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1))
            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.15, inplace=False)
            (dropout2): Dropout(p=0.15, inplace=False)
          )
        )
        (pos_encoding): PositionalEncoding(
          (dropout): Dropout(p=0.0, inplace=False)
        )
      )
    )
    (semantic_branch): SEM_Pre(
      (embedding): Embeddings(
        (embedding): Embedding(81, 512, padding_idx=0)
      )
      (positional_encoding): PositionalEncoding(
        (dropout): Dropout(p=0.15, inplace=False)
      )
    )
    (positional_branch): POS_Pre(
      (pos_encoding): PositionalEncoding(
        (dropout): Dropout(p=0.15, inplace=False)
      )
      (linear1): Linear(in_features=512, out_features=512, bias=True)
      (linear2): Linear(in_features=512, out_features=512, bias=True)
      (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    )
    (mdcdp): MDCDP(
      (layers_pos): ModuleList(
        (0-2): 3 x CommonAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
            (conv1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
            (conv2): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1))
            (conv3): Conv2d(512, 1536, kernel_size=(1, 1), stride=(1, 1))
          )
          (linear1): Linear(in_features=512, out_features=1024, bias=True)
          (dropout): Dropout(p=0.05, inplace=False)
          (linear2): Linear(in_features=1024, out_features=512, bias=True)
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (dropout2): Dropout(p=0.15, inplace=False)
          (dropout3): Dropout(p=0.15, inplace=False)
        )
      )
      (layers2): ModuleList(
        (0-2): 3 x CommonAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
            (conv1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
            (conv2): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1))
            (conv3): Conv2d(512, 1536, kernel_size=(1, 1), stride=(1, 1))
          )
          (linear1): Linear(in_features=512, out_features=1024, bias=True)
          (dropout): Dropout(p=0.05, inplace=False)
          (linear2): Linear(in_features=1024, out_features=512, bias=True)
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (dropout2): Dropout(p=0.15, inplace=False)
          (dropout3): Dropout(p=0.15, inplace=False)
        )
      )
      (layers3): ModuleList(
        (0-2): 3 x CommonAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
            (conv1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
            (conv2): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1))
            (conv3): Conv2d(512, 1536, kernel_size=(1, 1), stride=(1, 1))
          )
          (linear1): Linear(in_features=512, out_features=1024, bias=True)
          (dropout): Dropout(p=0.05, inplace=False)
          (linear2): Linear(in_features=1024, out_features=512, bias=True)
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (dropout2): Dropout(p=0.15, inplace=False)
          (dropout3): Dropout(p=0.15, inplace=False)
        )
      )
      (dynamic_shared_fusion): DSF(
        (w_att): Linear(in_features=1024, out_features=512, bias=True)
      )
    )
    (tgt_word_prj): Linear(in_features=512, out_features=81, bias=False)
  )
)
2026-01-05 09:46:45,042 - CDistNet - INFO - epoch: 0  iter: 0/1  loss:  4.551612  lr:  0.000000  eta: 0:00:00
2026-01-05 09:46:45,043 - CDistNet - INFO - Now: best_acc in epoch:0,iteration:0
2026-01-05 09:46:45,043 - CDistNet - INFO -   - (Training)   loss:  4.55161, accuracy: 1.569 %, time: 0.013 min
2026-01-05 09:46:45,481 - CDistNet - INFO - epoch: 1  iter: 0/1  loss:  4.555726  lr:  0.000000  eta: 0:00:00
2026-01-05 09:46:45,482 - CDistNet - INFO - Now: best_acc in epoch:0,iteration:0
2026-01-05 09:46:45,482 - CDistNet - INFO -   - (Training)   loss:  4.55573, accuracy: 1.961 %, time: 0.007 min
2026-01-05 09:46:45,919 - CDistNet - INFO - epoch: 2  iter: 0/1  loss:  4.566585  lr:  0.000000  eta: 0:00:00
2026-01-05 09:46:45,920 - CDistNet - INFO - Now: best_acc in epoch:0,iteration:0
2026-01-05 09:46:45,920 - CDistNet - INFO -   - (Training)   loss:  4.56658, accuracy: 1.176 %, time: 0.007 min
2026-01-05 09:46:46,357 - CDistNet - INFO - epoch: 3  iter: 0/1  loss:  4.545860  lr:  0.000000  eta: 0:00:00
2026-01-05 09:46:46,358 - CDistNet - INFO - Now: best_acc in epoch:0,iteration:0
2026-01-05 09:46:46,358 - CDistNet - INFO -   - (Training)   loss:  4.54586, accuracy: 2.157 %, time: 0.007 min
2026-01-05 09:46:46,797 - CDistNet - INFO - epoch: 4  iter: 0/1  loss:  4.511551  lr:  0.000000  eta: 0:00:00
2026-01-05 09:46:46,797 - CDistNet - INFO - Now: best_acc in epoch:0,iteration:0
2026-01-05 09:46:46,798 - CDistNet - INFO -   - (Training)   loss:  4.51155, accuracy: 0.784 %, time: 0.007 min
2026-01-05 09:46:47,236 - CDistNet - INFO - epoch: 5  iter: 0/1  loss:  4.557785  lr:  0.000000  eta: 0:00:00
2026-01-05 09:46:47,236 - CDistNet - INFO - Now: best_acc in epoch:0,iteration:0
2026-01-05 09:46:47,237 - CDistNet - INFO -   - (Training)   loss:  4.55779, accuracy: 1.765 %, time: 0.007 min
2026-01-05 09:46:47,676 - CDistNet - INFO - epoch: 6  iter: 0/1  loss:  4.577944  lr:  0.000000  eta: 0:00:00
2026-01-05 09:46:47,867 - CDistNet - INFO - eval_loss:4.3604,eval_acc:0.0333--------

2026-01-05 09:46:47,868 - CDistNet - INFO - Saving model: best_acc in epoch:6,iteration:0
2026-01-05 09:46:48,105 - CDistNet - INFO - Saved!
2026-01-05 09:46:48,106 - CDistNet - INFO - Now: best_acc in epoch:6,iteration:0
2026-01-05 09:46:48,107 - CDistNet - INFO -   - (Training)   loss:  4.57794, accuracy: 2.353 %, time: 0.014 min
2026-01-05 09:46:48,107 - CDistNet - INFO - Start eval ...
2026-01-05 09:46:48,260 - CDistNet - INFO -   - (Validation)   loss:  4.36045, accuracy: 3.333 %, time: 0.003 min
2026-01-05 09:46:48,260 - CDistNet - INFO - Saving model ...
2026-01-05 09:46:48,568 - CDistNet - INFO - Saved!
2026-01-05 09:46:49,007 - CDistNet - INFO - epoch: 7  iter: 0/1  loss:  4.519674  lr:  0.000010  eta: 0:00:00
2026-01-05 09:46:49,159 - CDistNet - INFO - eval_loss:4.1369,eval_acc:0.0600--------

2026-01-05 09:46:49,160 - CDistNet - INFO - Saving model: best_acc in epoch:7,iteration:0
2026-01-05 09:46:49,457 - CDistNet - INFO - Saved!
2026-01-05 09:46:49,458 - CDistNet - INFO - Now: best_acc in epoch:7,iteration:0
2026-01-05 09:46:49,459 - CDistNet - INFO -   - (Training)   loss:  4.51967, accuracy: 1.176 %, time: 0.015 min
2026-01-05 09:46:49,459 - CDistNet - INFO - Start eval ...
2026-01-05 09:46:49,611 - CDistNet - INFO -   - (Validation)   loss:  4.13695, accuracy: 6.000 %, time: 0.003 min
2026-01-05 09:46:49,612 - CDistNet - INFO - Saving model ...
2026-01-05 09:46:49,904 - CDistNet - INFO - Saved!
2026-01-05 09:46:50,342 - CDistNet - INFO - epoch: 8  iter: 0/1  loss:  4.349790  lr:  0.000010  eta: 0:00:00
2026-01-05 09:46:50,497 - CDistNet - INFO - eval_loss:3.9703,eval_acc:0.1267--------

2026-01-05 09:46:50,497 - CDistNet - INFO - Saving model: best_acc in epoch:8,iteration:0
2026-01-05 09:46:50,789 - CDistNet - INFO - Saved!
2026-01-05 09:46:50,790 - CDistNet - INFO - Now: best_acc in epoch:8,iteration:0
2026-01-05 09:46:50,790 - CDistNet - INFO -   - (Training)   loss:  4.34979, accuracy: 3.333 %, time: 0.015 min
2026-01-05 09:46:50,790 - CDistNet - INFO - Start eval ...
2026-01-05 09:46:50,943 - CDistNet - INFO -   - (Validation)   loss:  3.97033, accuracy: 12.667 %, time: 0.003 min
2026-01-05 09:46:50,943 - CDistNet - INFO - Saving model ...
2026-01-05 09:46:51,214 - CDistNet - INFO - Saved!
2026-01-05 09:46:51,653 - CDistNet - INFO - epoch: 9  iter: 0/1  loss:  4.161772  lr:  0.000010  eta: 0:00:00
2026-01-05 09:46:51,805 - CDistNet - INFO - eval_loss:3.8696,eval_acc:0.1467--------

2026-01-05 09:46:51,805 - CDistNet - INFO - Saving model: best_acc in epoch:9,iteration:0
2026-01-05 09:46:52,078 - CDistNet - INFO - Saved!
2026-01-05 09:46:52,078 - CDistNet - INFO - Saving last epoch model in epoch:9,iteration:0
2026-01-05 09:46:52,404 - CDistNet - INFO - Saved!
2026-01-05 09:46:52,405 - CDistNet - INFO - Now: best_acc in epoch:9,iteration:0
2026-01-05 09:46:52,405 - CDistNet - INFO -   - (Training)   loss:  4.16177, accuracy: 7.843 %, time: 0.020 min
2026-01-05 09:46:52,406 - CDistNet - INFO - Start eval ...
2026-01-05 09:46:52,559 - CDistNet - INFO -   - (Validation)   loss:  3.86959, accuracy: 14.667 %, time: 0.003 min
2026-01-05 09:46:52,559 - CDistNet - INFO - Saving model ...
2026-01-05 09:46:52,855 - CDistNet - INFO - Saved!
2026-01-05 09:46:53,294 - CDistNet - INFO - epoch: 10  iter: 0/1  loss:  4.050116  lr:  0.000010  eta: 0:00:00
2026-01-05 09:46:53,446 - CDistNet - INFO - eval_loss:3.8302,eval_acc:0.1467--------

2026-01-05 09:46:53,447 - CDistNet - INFO - Saving model: best_acc in epoch:10,iteration:0
2026-01-05 09:46:53,739 - CDistNet - INFO - Saved!
2026-01-05 09:46:53,739 - CDistNet - INFO - Saving last epoch model in epoch:10,iteration:0
2026-01-05 09:46:54,021 - CDistNet - INFO - Saved!
2026-01-05 09:46:54,022 - CDistNet - INFO - Now: best_acc in epoch:10,iteration:0
2026-01-05 09:46:54,022 - CDistNet - INFO -   - (Training)   loss:  4.05012, accuracy: 10.588 %, time: 0.019 min
2026-01-05 09:46:54,022 - CDistNet - INFO - Start eval ...
2026-01-05 09:46:54,175 - CDistNet - INFO -   - (Validation)   loss:  3.83024, accuracy: 14.667 %, time: 0.003 min
2026-01-05 09:46:54,175 - CDistNet - INFO - Saving model ...
2026-01-05 09:46:54,449 - CDistNet - INFO - Saved!
2026-01-05 09:46:54,888 - CDistNet - INFO - epoch: 11  iter: 0/1  loss:  3.939339  lr:  0.000010  eta: 0:00:00
2026-01-05 09:46:55,041 - CDistNet - INFO - eval_loss:3.8269,eval_acc:0.1467--------

2026-01-05 09:46:55,041 - CDistNet - INFO - Saving model: best_acc in epoch:11,iteration:0
2026-01-05 09:46:55,327 - CDistNet - INFO - Saved!
2026-01-05 09:46:55,328 - CDistNet - INFO - Saving last epoch model in epoch:11,iteration:0
2026-01-05 09:46:55,629 - CDistNet - INFO - Saved!
2026-01-05 09:46:55,630 - CDistNet - INFO - Now: best_acc in epoch:11,iteration:0
2026-01-05 09:46:55,631 - CDistNet - INFO -   - (Training)   loss:  3.93934, accuracy: 14.314 %, time: 0.020 min
2026-01-05 09:46:55,631 - CDistNet - INFO - Start eval ...
2026-01-05 09:46:55,785 - CDistNet - INFO -   - (Validation)   loss:  3.82691, accuracy: 14.667 %, time: 0.003 min
2026-01-05 09:46:55,785 - CDistNet - INFO - Saving model ...
2026-01-05 09:46:56,081 - CDistNet - INFO - Saved!
2026-01-05 09:46:56,521 - CDistNet - INFO - epoch: 12  iter: 0/1  loss:  3.879233  lr:  0.000010  eta: 0:00:00
2026-01-05 09:46:56,676 - CDistNet - INFO - eval_loss:3.8309,eval_acc:0.1467--------

2026-01-05 09:46:56,676 - CDistNet - INFO - Saving model: best_acc in epoch:12,iteration:0
2026-01-05 09:46:56,970 - CDistNet - INFO - Saved!
2026-01-05 09:46:56,970 - CDistNet - INFO - Saving last epoch model in epoch:12,iteration:0
2026-01-05 09:46:57,262 - CDistNet - INFO - Saved!
2026-01-05 09:46:57,263 - CDistNet - INFO - Now: best_acc in epoch:12,iteration:0
2026-01-05 09:46:57,264 - CDistNet - INFO -   - (Training)   loss:  3.87923, accuracy: 14.510 %, time: 0.020 min
2026-01-05 09:46:57,264 - CDistNet - INFO - Start eval ...
2026-01-05 09:46:57,420 - CDistNet - INFO -   - (Validation)   loss:  3.83089, accuracy: 14.667 %, time: 0.003 min
2026-01-05 09:46:57,420 - CDistNet - INFO - Saving model ...
2026-01-05 09:46:57,697 - CDistNet - INFO - Saved!
2026-01-05 09:46:58,140 - CDistNet - INFO - epoch: 13  iter: 0/1  loss:  3.791822  lr:  0.000010  eta: 0:00:00
2026-01-05 09:46:58,294 - CDistNet - INFO - eval_loss:3.8195,eval_acc:0.1467--------

2026-01-05 09:46:58,295 - CDistNet - INFO - Saving model: best_acc in epoch:13,iteration:0
2026-01-05 09:46:58,574 - CDistNet - INFO - Saved!
2026-01-05 09:46:58,574 - CDistNet - INFO - Saving last epoch model in epoch:13,iteration:0
2026-01-05 09:46:58,855 - CDistNet - INFO - Saved!
2026-01-05 09:46:58,857 - CDistNet - INFO - Now: best_acc in epoch:13,iteration:0
2026-01-05 09:46:58,858 - CDistNet - INFO -   - (Training)   loss:  3.79182, accuracy: 13.725 %, time: 0.019 min
2026-01-05 09:46:58,858 - CDistNet - INFO - Start eval ...
2026-01-05 09:46:59,012 - CDistNet - INFO -   - (Validation)   loss:  3.81952, accuracy: 14.667 %, time: 0.003 min
2026-01-05 09:46:59,012 - CDistNet - INFO - Saving model ...
2026-01-05 09:46:59,286 - CDistNet - INFO - Saved!
2026-01-05 09:46:59,727 - CDistNet - INFO - epoch: 14  iter: 0/1  loss:  3.786518  lr:  0.000010  eta: 0:00:00
2026-01-05 09:46:59,879 - CDistNet - INFO - eval_loss:3.7919,eval_acc:0.1467--------

2026-01-05 09:46:59,879 - CDistNet - INFO - Saving model: best_acc in epoch:14,iteration:0
2026-01-05 09:47:00,155 - CDistNet - INFO - Saved!
2026-01-05 09:47:00,155 - CDistNet - INFO - Saving last epoch model in epoch:14,iteration:0
2026-01-05 09:47:00,445 - CDistNet - INFO - Saved!
2026-01-05 09:47:00,446 - CDistNet - INFO - Now: best_acc in epoch:14,iteration:0
2026-01-05 09:47:00,446 - CDistNet - INFO -   - (Training)   loss:  3.78652, accuracy: 15.098 %, time: 0.019 min
2026-01-05 09:47:00,446 - CDistNet - INFO - Start eval ...
2026-01-05 09:47:00,600 - CDistNet - INFO -   - (Validation)   loss:  3.79195, accuracy: 14.667 %, time: 0.003 min
2026-01-05 09:47:00,601 - CDistNet - INFO - Saving model ...
2026-01-05 09:47:00,869 - CDistNet - INFO - Saved!
2026-01-05 09:47:01,310 - CDistNet - INFO - epoch: 15  iter: 0/1  loss:  3.681847  lr:  0.000010  eta: 0:00:00
2026-01-05 09:47:01,463 - CDistNet - INFO - eval_loss:3.7491,eval_acc:0.1467--------

2026-01-05 09:47:01,464 - CDistNet - INFO - Saving model: best_acc in epoch:15,iteration:0
2026-01-05 09:47:01,741 - CDistNet - INFO - Saved!
2026-01-05 09:47:01,741 - CDistNet - INFO - Saving last epoch model in epoch:15,iteration:0
2026-01-05 09:47:02,011 - CDistNet - INFO - Saved!
2026-01-05 09:47:02,012 - CDistNet - INFO - Now: best_acc in epoch:15,iteration:0
2026-01-05 09:47:02,013 - CDistNet - INFO -   - (Training)   loss:  3.68185, accuracy: 15.294 %, time: 0.019 min
2026-01-05 09:47:02,013 - CDistNet - INFO - Start eval ...
2026-01-05 09:47:02,166 - CDistNet - INFO -   - (Validation)   loss:  3.74907, accuracy: 14.667 %, time: 0.003 min
2026-01-05 09:47:02,166 - CDistNet - INFO - Saving model ...
2026-01-05 09:47:02,437 - CDistNet - INFO - Saved!
2026-01-05 09:47:02,887 - CDistNet - INFO - epoch: 16  iter: 0/1  loss:  3.651035  lr:  0.000010  eta: 0:00:00
2026-01-05 09:47:03,044 - CDistNet - INFO - eval_loss:3.6987,eval_acc:0.1511--------

2026-01-05 09:47:03,044 - CDistNet - INFO - Saving model: best_acc in epoch:16,iteration:0
2026-01-05 09:47:03,320 - CDistNet - INFO - Saved!
2026-01-05 09:47:03,320 - CDistNet - INFO - Saving last epoch model in epoch:16,iteration:0
2026-01-05 09:47:03,586 - CDistNet - INFO - Saved!
2026-01-05 09:47:03,588 - CDistNet - INFO - Now: best_acc in epoch:16,iteration:0
2026-01-05 09:47:03,588 - CDistNet - INFO -   - (Training)   loss:  3.65104, accuracy: 15.294 %, time: 0.019 min
2026-01-05 09:47:03,588 - CDistNet - INFO - Start eval ...
2026-01-05 09:47:03,742 - CDistNet - INFO -   - (Validation)   loss:  3.69869, accuracy: 15.111 %, time: 0.003 min
2026-01-05 09:47:03,742 - CDistNet - INFO - Saving model ...
2026-01-05 09:47:04,007 - CDistNet - INFO - Saved!
2026-01-05 09:47:04,448 - CDistNet - INFO - epoch: 17  iter: 0/1  loss:  3.602014  lr:  0.000010  eta: 0:00:00
2026-01-05 09:47:04,603 - CDistNet - INFO - eval_loss:3.6556,eval_acc:0.1533--------

2026-01-05 09:47:04,603 - CDistNet - INFO - Saving model: best_acc in epoch:17,iteration:0
2026-01-05 09:47:04,879 - CDistNet - INFO - Saved!
2026-01-05 09:47:04,879 - CDistNet - INFO - Saving last epoch model in epoch:17,iteration:0
2026-01-05 09:47:05,154 - CDistNet - INFO - Saved!
2026-01-05 09:47:05,155 - CDistNet - INFO - Now: best_acc in epoch:17,iteration:0
2026-01-05 09:47:05,156 - CDistNet - INFO -   - (Training)   loss:  3.60201, accuracy: 15.490 %, time: 0.019 min
2026-01-05 09:47:05,156 - CDistNet - INFO - Start eval ...
2026-01-05 09:47:05,308 - CDistNet - INFO -   - (Validation)   loss:  3.65560, accuracy: 15.333 %, time: 0.003 min
2026-01-05 09:47:05,308 - CDistNet - INFO - Saving model ...
2026-01-05 09:47:05,584 - CDistNet - INFO - Saved!
2026-01-05 09:47:06,024 - CDistNet - INFO - epoch: 18  iter: 0/1  loss:  3.546980  lr:  0.000010  eta: 0:00:00
2026-01-05 09:47:06,180 - CDistNet - INFO - eval_loss:3.6183,eval_acc:0.1533--------

2026-01-05 09:47:06,180 - CDistNet - INFO - Saving model: best_acc in epoch:18,iteration:0
2026-01-05 09:47:06,455 - CDistNet - INFO - Saved!
2026-01-05 09:47:06,455 - CDistNet - INFO - Saving last epoch model in epoch:18,iteration:0
2026-01-05 09:47:06,727 - CDistNet - INFO - Saved!
2026-01-05 09:47:06,728 - CDistNet - INFO - Now: best_acc in epoch:18,iteration:0
2026-01-05 09:47:06,729 - CDistNet - INFO -   - (Training)   loss:  3.54698, accuracy: 16.275 %, time: 0.019 min
2026-01-05 09:47:06,729 - CDistNet - INFO - Start eval ...
2026-01-05 09:47:06,882 - CDistNet - INFO -   - (Validation)   loss:  3.61835, accuracy: 15.333 %, time: 0.003 min
2026-01-05 09:47:06,882 - CDistNet - INFO - Saving model ...
2026-01-05 09:47:07,149 - CDistNet - INFO - Saved!
2026-01-05 09:47:07,590 - CDistNet - INFO - epoch: 19  iter: 0/1  loss:  3.555956  lr:  0.000010  eta: 0:00:00
2026-01-05 09:47:07,743 - CDistNet - INFO - eval_loss:3.5955,eval_acc:0.1533--------

2026-01-05 09:47:07,743 - CDistNet - INFO - Saving model: best_acc in epoch:19,iteration:0
2026-01-05 09:47:08,016 - CDistNet - INFO - Saved!
2026-01-05 09:47:08,016 - CDistNet - INFO - Saving last epoch model in epoch:19,iteration:0
2026-01-05 09:47:08,290 - CDistNet - INFO - Saved!
2026-01-05 09:47:08,291 - CDistNet - INFO - Now: best_acc in epoch:19,iteration:0
2026-01-05 09:47:08,292 - CDistNet - INFO -   - (Training)   loss:  3.55596, accuracy: 14.510 %, time: 0.019 min
2026-01-05 09:47:08,292 - CDistNet - INFO - Start eval ...
2026-01-05 09:47:08,444 - CDistNet - INFO -   - (Validation)   loss:  3.59554, accuracy: 15.333 %, time: 0.003 min
2026-01-05 09:47:08,445 - CDistNet - INFO - Saving model ...
2026-01-05 09:47:08,712 - CDistNet - INFO - Saved!
2026-01-05 09:47:09,153 - CDistNet - INFO - epoch: 20  iter: 0/1  loss:  3.517609  lr:  0.000010  eta: 0:00:00
2026-01-05 09:47:09,309 - CDistNet - INFO - eval_loss:3.5806,eval_acc:0.1556--------

2026-01-05 09:47:09,309 - CDistNet - INFO - Saving model: best_acc in epoch:20,iteration:0
2026-01-05 09:47:09,585 - CDistNet - INFO - Saved!
2026-01-05 09:47:09,586 - CDistNet - INFO - Saving last epoch model in epoch:20,iteration:0
2026-01-05 09:47:09,856 - CDistNet - INFO - Saved!
2026-01-05 09:47:09,857 - CDistNet - INFO - Now: best_acc in epoch:20,iteration:0
2026-01-05 09:47:09,858 - CDistNet - INFO -   - (Training)   loss:  3.51761, accuracy: 17.647 %, time: 0.019 min
2026-01-05 09:47:09,858 - CDistNet - INFO - Start eval ...
2026-01-05 09:47:10,011 - CDistNet - INFO -   - (Validation)   loss:  3.58062, accuracy: 15.556 %, time: 0.003 min
2026-01-05 09:47:10,011 - CDistNet - INFO - Saving model ...
2026-01-05 09:47:10,283 - CDistNet - INFO - Saved!
2026-01-05 09:47:10,723 - CDistNet - INFO - epoch: 21  iter: 0/1  loss:  3.469633  lr:  0.000010  eta: 0:00:00
2026-01-05 09:47:10,877 - CDistNet - INFO - eval_loss:3.5745,eval_acc:0.1644--------

2026-01-05 09:47:10,877 - CDistNet - INFO - Saving model: best_acc in epoch:21,iteration:0
2026-01-05 09:47:11,156 - CDistNet - INFO - Saved!
2026-01-05 09:47:11,156 - CDistNet - INFO - Saving last epoch model in epoch:21,iteration:0
2026-01-05 09:47:11,447 - CDistNet - INFO - Saved!
2026-01-05 09:47:11,448 - CDistNet - INFO - Now: best_acc in epoch:21,iteration:0
2026-01-05 09:47:11,449 - CDistNet - INFO -   - (Training)   loss:  3.46963, accuracy: 17.647 %, time: 0.019 min
2026-01-05 09:47:11,449 - CDistNet - INFO - Start eval ...
2026-01-05 09:47:11,602 - CDistNet - INFO -   - (Validation)   loss:  3.57451, accuracy: 16.444 %, time: 0.003 min
2026-01-05 09:47:11,602 - CDistNet - INFO - Saving model ...
2026-01-05 09:47:11,877 - CDistNet - INFO - Saved!
2026-01-05 09:47:12,317 - CDistNet - INFO - epoch: 22  iter: 0/1  loss:  3.479866  lr:  0.000010  eta: 0:00:00
2026-01-05 09:47:12,470 - CDistNet - INFO - eval_loss:3.5704,eval_acc:0.1644--------

2026-01-05 09:47:12,470 - CDistNet - INFO - Saving model: best_acc in epoch:22,iteration:0
2026-01-05 09:47:12,743 - CDistNet - INFO - Saved!
2026-01-05 09:47:12,744 - CDistNet - INFO - Saving last epoch model in epoch:22,iteration:0
2026-01-05 09:47:13,016 - CDistNet - INFO - Saved!
2026-01-05 09:47:13,018 - CDistNet - INFO - Now: best_acc in epoch:22,iteration:0
2026-01-05 09:47:13,018 - CDistNet - INFO -   - (Training)   loss:  3.47987, accuracy: 16.275 %, time: 0.019 min
2026-01-05 09:47:13,019 - CDistNet - INFO - Start eval ...
2026-01-05 09:47:13,171 - CDistNet - INFO -   - (Validation)   loss:  3.57042, accuracy: 16.444 %, time: 0.003 min
2026-01-05 09:47:13,171 - CDistNet - INFO - Saving model ...
2026-01-05 09:47:13,447 - CDistNet - INFO - Saved!
2026-01-05 09:47:13,887 - CDistNet - INFO - epoch: 23  iter: 0/1  loss:  3.428288  lr:  0.000010  eta: 0:00:00
2026-01-05 09:47:14,042 - CDistNet - INFO - eval_loss:3.5697,eval_acc:0.1689--------

2026-01-05 09:47:14,042 - CDistNet - INFO - Saving model: best_acc in epoch:23,iteration:0
2026-01-05 09:47:14,311 - CDistNet - INFO - Saved!
2026-01-05 09:47:14,311 - CDistNet - INFO - Saving last epoch model in epoch:23,iteration:0
2026-01-05 09:47:14,580 - CDistNet - INFO - Saved!
2026-01-05 09:47:14,581 - CDistNet - INFO - Now: best_acc in epoch:23,iteration:0
2026-01-05 09:47:14,582 - CDistNet - INFO -   - (Training)   loss:  3.42829, accuracy: 18.039 %, time: 0.019 min
2026-01-05 09:47:14,582 - CDistNet - INFO - Start eval ...
2026-01-05 09:47:14,736 - CDistNet - INFO -   - (Validation)   loss:  3.56971, accuracy: 16.889 %, time: 0.003 min
2026-01-05 09:47:14,736 - CDistNet - INFO - Saving model ...
2026-01-05 09:47:15,004 - CDistNet - INFO - Saved!
2026-01-05 09:47:15,445 - CDistNet - INFO - epoch: 24  iter: 0/1  loss:  3.418147  lr:  0.000010  eta: 0:00:00
2026-01-05 09:47:15,598 - CDistNet - INFO - eval_loss:3.5703,eval_acc:0.1600--------

2026-01-05 09:47:15,599 - CDistNet - INFO - Saving model: best_acc in epoch:24,iteration:0
2026-01-05 09:47:15,882 - CDistNet - INFO - Saved!
2026-01-05 09:47:15,882 - CDistNet - INFO - Saving last epoch model in epoch:24,iteration:0
2026-01-05 09:47:16,154 - CDistNet - INFO - Saved!
2026-01-05 09:47:16,155 - CDistNet - INFO - Now: best_acc in epoch:24,iteration:0
2026-01-05 09:47:16,156 - CDistNet - INFO -   - (Training)   loss:  3.41815, accuracy: 15.490 %, time: 0.019 min
2026-01-05 09:47:16,156 - CDistNet - INFO - Start eval ...
2026-01-05 09:47:16,309 - CDistNet - INFO -   - (Validation)   loss:  3.57030, accuracy: 16.000 %, time: 0.003 min
2026-01-05 09:47:16,309 - CDistNet - INFO - Saving model ...
2026-01-05 09:47:16,594 - CDistNet - INFO - Saved!
2026-01-05 09:47:17,034 - CDistNet - INFO - epoch: 25  iter: 0/1  loss:  3.400057  lr:  0.000010  eta: 0:00:00
2026-01-05 09:47:17,186 - CDistNet - INFO - eval_loss:3.5723,eval_acc:0.1622--------

2026-01-05 09:47:17,187 - CDistNet - INFO - Saving model: best_acc in epoch:25,iteration:0
2026-01-05 09:47:17,472 - CDistNet - INFO - Saved!
2026-01-05 09:47:17,472 - CDistNet - INFO - Saving last epoch model in epoch:25,iteration:0
2026-01-05 09:47:17,748 - CDistNet - INFO - Saved!
2026-01-05 09:47:17,749 - CDistNet - INFO - Now: best_acc in epoch:25,iteration:0
2026-01-05 09:47:17,749 - CDistNet - INFO -   - (Training)   loss:  3.40006, accuracy: 17.647 %, time: 0.019 min
2026-01-05 09:47:17,750 - CDistNet - INFO - Start eval ...
2026-01-05 09:47:17,902 - CDistNet - INFO -   - (Validation)   loss:  3.57235, accuracy: 16.222 %, time: 0.003 min
2026-01-05 09:47:17,902 - CDistNet - INFO - Saving model ...
2026-01-05 09:47:18,175 - CDistNet - INFO - Saved!
2026-01-05 09:47:18,615 - CDistNet - INFO - epoch: 26  iter: 0/1  loss:  3.401018  lr:  0.000010  eta: 0:00:00
2026-01-05 09:47:18,768 - CDistNet - INFO - eval_loss:3.5790,eval_acc:0.1600--------

2026-01-05 09:47:18,768 - CDistNet - INFO - Saving model: best_acc in epoch:26,iteration:0
2026-01-05 09:47:19,062 - CDistNet - INFO - Saved!
2026-01-05 09:47:19,062 - CDistNet - INFO - Saving last epoch model in epoch:26,iteration:0
2026-01-05 09:47:19,424 - CDistNet - INFO - Saved!
2026-01-05 09:47:19,426 - CDistNet - INFO - Now: best_acc in epoch:26,iteration:0
2026-01-05 09:47:19,426 - CDistNet - INFO -   - (Training)   loss:  3.40102, accuracy: 17.843 %, time: 0.021 min
2026-01-05 09:47:19,426 - CDistNet - INFO - Start eval ...
2026-01-05 09:47:19,580 - CDistNet - INFO -   - (Validation)   loss:  3.57901, accuracy: 16.000 %, time: 0.003 min
2026-01-05 09:47:19,580 - CDistNet - INFO - Saving model ...
2026-01-05 09:47:19,857 - CDistNet - INFO - Saved!
2026-01-05 09:47:20,297 - CDistNet - INFO - epoch: 27  iter: 0/1  loss:  3.363657  lr:  0.000010  eta: 0:00:00
2026-01-05 09:47:20,450 - CDistNet - INFO - eval_loss:3.5872,eval_acc:0.1600--------

2026-01-05 09:47:20,450 - CDistNet - INFO - Saving model: best_acc in epoch:27,iteration:0
2026-01-05 09:47:20,724 - CDistNet - INFO - Saved!
2026-01-05 09:47:20,725 - CDistNet - INFO - Saving last epoch model in epoch:27,iteration:0
2026-01-05 09:47:21,005 - CDistNet - INFO - Saved!
2026-01-05 09:47:21,006 - CDistNet - INFO - Now: best_acc in epoch:27,iteration:0
2026-01-05 09:47:21,006 - CDistNet - INFO -   - (Training)   loss:  3.36366, accuracy: 18.431 %, time: 0.019 min
2026-01-05 09:47:21,006 - CDistNet - INFO - Start eval ...
2026-01-05 09:47:21,158 - CDistNet - INFO -   - (Validation)   loss:  3.58719, accuracy: 16.000 %, time: 0.003 min
2026-01-05 09:47:21,158 - CDistNet - INFO - Saving model ...
2026-01-05 09:47:21,427 - CDistNet - INFO - Saved!
2026-01-05 09:47:21,867 - CDistNet - INFO - epoch: 28  iter: 0/1  loss:  3.356687  lr:  0.000010  eta: 0:00:00
2026-01-05 09:47:22,021 - CDistNet - INFO - eval_loss:3.5947,eval_acc:0.1556--------

2026-01-05 09:47:22,021 - CDistNet - INFO - Saving model: best_acc in epoch:28,iteration:0
2026-01-05 09:47:22,302 - CDistNet - INFO - Saved!
2026-01-05 09:47:22,302 - CDistNet - INFO - Saving last epoch model in epoch:28,iteration:0
2026-01-05 09:47:22,576 - CDistNet - INFO - Saved!
2026-01-05 09:47:22,577 - CDistNet - INFO - Now: best_acc in epoch:28,iteration:0
2026-01-05 09:47:22,578 - CDistNet - INFO -   - (Training)   loss:  3.35669, accuracy: 19.216 %, time: 0.019 min
2026-01-05 09:47:22,578 - CDistNet - INFO - Start eval ...
2026-01-05 09:47:22,731 - CDistNet - INFO -   - (Validation)   loss:  3.59474, accuracy: 15.556 %, time: 0.003 min
2026-01-05 09:47:22,731 - CDistNet - INFO - Saving model ...
2026-01-05 09:47:23,005 - CDistNet - INFO - Saved!
2026-01-05 09:47:23,444 - CDistNet - INFO - epoch: 29  iter: 0/1  loss:  3.352053  lr:  0.000010  eta: 0:00:00
2026-01-05 09:47:23,598 - CDistNet - INFO - eval_loss:3.6020,eval_acc:0.1533--------

2026-01-05 09:47:23,598 - CDistNet - INFO - Saving model: best_acc in epoch:29,iteration:0
2026-01-05 09:47:23,873 - CDistNet - INFO - Saved!
2026-01-05 09:47:23,873 - CDistNet - INFO - Saving last epoch model in epoch:29,iteration:0
2026-01-05 09:47:24,145 - CDistNet - INFO - Saved!
2026-01-05 09:47:24,146 - CDistNet - INFO - Now: best_acc in epoch:29,iteration:0
2026-01-05 09:47:24,147 - CDistNet - INFO -   - (Training)   loss:  3.35205, accuracy: 18.235 %, time: 0.019 min
2026-01-05 09:47:24,147 - CDistNet - INFO - Start eval ...
2026-01-05 09:47:24,300 - CDistNet - INFO -   - (Validation)   loss:  3.60196, accuracy: 15.333 %, time: 0.003 min
2026-01-05 09:47:24,300 - CDistNet - INFO - Saving model ...
2026-01-05 09:47:24,573 - CDistNet - INFO - Saved!
2026-01-05 09:47:25,014 - CDistNet - INFO - epoch: 30  iter: 0/1  loss:  3.325870  lr:  0.000010  eta: 0:00:00
2026-01-05 09:47:25,167 - CDistNet - INFO - eval_loss:3.6055,eval_acc:0.1533--------

2026-01-05 09:47:25,168 - CDistNet - INFO - Saving model: best_acc in epoch:30,iteration:0
2026-01-05 09:47:25,435 - CDistNet - INFO - Saved!
2026-01-05 09:47:25,436 - CDistNet - INFO - Saving last epoch model in epoch:30,iteration:0
2026-01-05 09:47:25,708 - CDistNet - INFO - Saved!
2026-01-05 09:47:25,709 - CDistNet - INFO - Now: best_acc in epoch:30,iteration:0
2026-01-05 09:47:25,710 - CDistNet - INFO -   - (Training)   loss:  3.32587, accuracy: 19.412 %, time: 0.019 min
2026-01-05 09:47:25,710 - CDistNet - INFO - Start eval ...
2026-01-05 09:47:25,863 - CDistNet - INFO -   - (Validation)   loss:  3.60554, accuracy: 15.333 %, time: 0.003 min
2026-01-05 09:47:25,863 - CDistNet - INFO - Saving model ...
2026-01-05 09:47:26,143 - CDistNet - INFO - Saved!
2026-01-05 10:30:42,112 - CDistNet - INFO - model parameter:-------
Trainable: 65.499528 M
2026-01-05 10:30:42,113 - CDistNet - INFO - model struct:-------
DataParallel(
  (module): CDistNet(
    (visual_branch): VIS_Pre(
      (transform): TPS_SpatialTransformerNetwork(
        (LocalizationNetwork): LocalizationNetwork(
          (conv): Sequential(
            (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU(inplace=True)
            (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
            (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (6): ReLU(inplace=True)
            (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
            (8): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (9): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (10): ReLU(inplace=True)
            (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
            (12): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (13): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (14): ReLU(inplace=True)
            (15): AdaptiveAvgPool2d(output_size=1)
          )
          (localization_fc1): Sequential(
            (0): Linear(in_features=512, out_features=256, bias=True)
            (1): ReLU(inplace=True)
          )
          (localization_fc2): Linear(in_features=256, out_features=40, bias=True)
        )
        (GridGenerator): GridGenerator()
      )
      (backbone): ABI_ResNet(
        (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (convbnrelu): ConvBnRelu(
          (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
          (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (layer1): Sequential(
          (0): BasicBlock(
            (conv1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (downsample): Sequential(
              (0): Conv2d(32, 32, kernel_size=(1, 1), stride=(2, 2), bias=False)
              (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (1): BasicBlock(
            (conv1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (2): BasicBlock(
            (conv1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (layer2): Sequential(
          (0): BasicBlock(
            (conv1): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (downsample): Sequential(
              (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (1): BasicBlock(
            (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (2): BasicBlock(
            (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (3): BasicBlock(
            (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (layer3): Sequential(
          (0): BasicBlock(
            (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (downsample): Sequential(
              (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
              (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (1): BasicBlock(
            (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (2): BasicBlock(
            (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (3): BasicBlock(
            (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (4): BasicBlock(
            (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (5): BasicBlock(
            (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (layer4): Sequential(
          (0): BasicBlock(
            (conv1): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (downsample): Sequential(
              (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (1): BasicBlock(
            (conv1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (2): BasicBlock(
            (conv1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (3): BasicBlock(
            (conv1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (4): BasicBlock(
            (conv1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (5): BasicBlock(
            (conv1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (layer5): Sequential(
          (0): BasicBlock(
            (conv1): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (downsample): Sequential(
              (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (1): BasicBlock(
            (conv1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (2): BasicBlock(
            (conv1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
      )
      (positional_encoding): PositionalEncoding(
        (dropout): Dropout(p=0.15, inplace=False)
      )
      (trans_encoder): TransformerEncoder(
        (layers): ModuleList(
          (0-2): 3 x TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): Linear(in_features=512, out_features=512, bias=True)
              (conv1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
              (conv2): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1))
              (conv3): Conv2d(512, 1536, kernel_size=(1, 1), stride=(1, 1))
            )
            (conv1): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1))
            (conv2): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1))
            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.15, inplace=False)
            (dropout2): Dropout(p=0.15, inplace=False)
          )
        )
        (pos_encoding): PositionalEncoding(
          (dropout): Dropout(p=0.0, inplace=False)
        )
      )
    )
    (semantic_branch): SEM_Pre(
      (embedding): Embeddings(
        (embedding): Embedding(81, 512, padding_idx=0)
      )
      (positional_encoding): PositionalEncoding(
        (dropout): Dropout(p=0.15, inplace=False)
      )
    )
    (positional_branch): POS_Pre(
      (pos_encoding): PositionalEncoding(
        (dropout): Dropout(p=0.15, inplace=False)
      )
      (linear1): Linear(in_features=512, out_features=512, bias=True)
      (linear2): Linear(in_features=512, out_features=512, bias=True)
      (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    )
    (mdcdp): MDCDP(
      (layers_pos): ModuleList(
        (0-2): 3 x CommonAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
            (conv1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
            (conv2): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1))
            (conv3): Conv2d(512, 1536, kernel_size=(1, 1), stride=(1, 1))
          )
          (linear1): Linear(in_features=512, out_features=1024, bias=True)
          (dropout): Dropout(p=0.05, inplace=False)
          (linear2): Linear(in_features=1024, out_features=512, bias=True)
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (dropout2): Dropout(p=0.15, inplace=False)
          (dropout3): Dropout(p=0.15, inplace=False)
        )
      )
      (layers2): ModuleList(
        (0-2): 3 x CommonAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
            (conv1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
            (conv2): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1))
            (conv3): Conv2d(512, 1536, kernel_size=(1, 1), stride=(1, 1))
          )
          (linear1): Linear(in_features=512, out_features=1024, bias=True)
          (dropout): Dropout(p=0.05, inplace=False)
          (linear2): Linear(in_features=1024, out_features=512, bias=True)
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (dropout2): Dropout(p=0.15, inplace=False)
          (dropout3): Dropout(p=0.15, inplace=False)
        )
      )
      (layers3): ModuleList(
        (0-2): 3 x CommonAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
            (conv1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
            (conv2): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1))
            (conv3): Conv2d(512, 1536, kernel_size=(1, 1), stride=(1, 1))
          )
          (linear1): Linear(in_features=512, out_features=1024, bias=True)
          (dropout): Dropout(p=0.05, inplace=False)
          (linear2): Linear(in_features=1024, out_features=512, bias=True)
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (dropout2): Dropout(p=0.15, inplace=False)
          (dropout3): Dropout(p=0.15, inplace=False)
        )
      )
      (dynamic_shared_fusion): DSF(
        (w_att): Linear(in_features=1024, out_features=512, bias=True)
      )
    )
    (tgt_word_prj): Linear(in_features=512, out_features=81, bias=False)
  )
)
2026-01-05 10:31:11,425 - CDistNet - INFO - model parameter:-------
Trainable: 65.499528 M
2026-01-05 10:31:11,426 - CDistNet - INFO - model struct:-------
DataParallel(
  (module): CDistNet(
    (visual_branch): VIS_Pre(
      (transform): TPS_SpatialTransformerNetwork(
        (LocalizationNetwork): LocalizationNetwork(
          (conv): Sequential(
            (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU(inplace=True)
            (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
            (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (6): ReLU(inplace=True)
            (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
            (8): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (9): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (10): ReLU(inplace=True)
            (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
            (12): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (13): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (14): ReLU(inplace=True)
            (15): AdaptiveAvgPool2d(output_size=1)
          )
          (localization_fc1): Sequential(
            (0): Linear(in_features=512, out_features=256, bias=True)
            (1): ReLU(inplace=True)
          )
          (localization_fc2): Linear(in_features=256, out_features=40, bias=True)
        )
        (GridGenerator): GridGenerator()
      )
      (backbone): ABI_ResNet(
        (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (convbnrelu): ConvBnRelu(
          (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
          (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (layer1): Sequential(
          (0): BasicBlock(
            (conv1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (downsample): Sequential(
              (0): Conv2d(32, 32, kernel_size=(1, 1), stride=(2, 2), bias=False)
              (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (1): BasicBlock(
            (conv1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (2): BasicBlock(
            (conv1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (layer2): Sequential(
          (0): BasicBlock(
            (conv1): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (downsample): Sequential(
              (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (1): BasicBlock(
            (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (2): BasicBlock(
            (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (3): BasicBlock(
            (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (layer3): Sequential(
          (0): BasicBlock(
            (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (downsample): Sequential(
              (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
              (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (1): BasicBlock(
            (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (2): BasicBlock(
            (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (3): BasicBlock(
            (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (4): BasicBlock(
            (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (5): BasicBlock(
            (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (layer4): Sequential(
          (0): BasicBlock(
            (conv1): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (downsample): Sequential(
              (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (1): BasicBlock(
            (conv1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (2): BasicBlock(
            (conv1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (3): BasicBlock(
            (conv1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (4): BasicBlock(
            (conv1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (5): BasicBlock(
            (conv1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (layer5): Sequential(
          (0): BasicBlock(
            (conv1): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (downsample): Sequential(
              (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (1): BasicBlock(
            (conv1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (2): BasicBlock(
            (conv1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
      )
      (positional_encoding): PositionalEncoding(
        (dropout): Dropout(p=0.15, inplace=False)
      )
      (trans_encoder): TransformerEncoder(
        (layers): ModuleList(
          (0-2): 3 x TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): Linear(in_features=512, out_features=512, bias=True)
              (conv1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
              (conv2): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1))
              (conv3): Conv2d(512, 1536, kernel_size=(1, 1), stride=(1, 1))
            )
            (conv1): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1))
            (conv2): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1))
            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.15, inplace=False)
            (dropout2): Dropout(p=0.15, inplace=False)
          )
        )
        (pos_encoding): PositionalEncoding(
          (dropout): Dropout(p=0.0, inplace=False)
        )
      )
    )
    (semantic_branch): SEM_Pre(
      (embedding): Embeddings(
        (embedding): Embedding(81, 512, padding_idx=0)
      )
      (positional_encoding): PositionalEncoding(
        (dropout): Dropout(p=0.15, inplace=False)
      )
    )
    (positional_branch): POS_Pre(
      (pos_encoding): PositionalEncoding(
        (dropout): Dropout(p=0.15, inplace=False)
      )
      (linear1): Linear(in_features=512, out_features=512, bias=True)
      (linear2): Linear(in_features=512, out_features=512, bias=True)
      (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    )
    (mdcdp): MDCDP(
      (layers_pos): ModuleList(
        (0-2): 3 x CommonAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
            (conv1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
            (conv2): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1))
            (conv3): Conv2d(512, 1536, kernel_size=(1, 1), stride=(1, 1))
          )
          (linear1): Linear(in_features=512, out_features=1024, bias=True)
          (dropout): Dropout(p=0.05, inplace=False)
          (linear2): Linear(in_features=1024, out_features=512, bias=True)
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (dropout2): Dropout(p=0.15, inplace=False)
          (dropout3): Dropout(p=0.15, inplace=False)
        )
      )
      (layers2): ModuleList(
        (0-2): 3 x CommonAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
            (conv1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
            (conv2): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1))
            (conv3): Conv2d(512, 1536, kernel_size=(1, 1), stride=(1, 1))
          )
          (linear1): Linear(in_features=512, out_features=1024, bias=True)
          (dropout): Dropout(p=0.05, inplace=False)
          (linear2): Linear(in_features=1024, out_features=512, bias=True)
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (dropout2): Dropout(p=0.15, inplace=False)
          (dropout3): Dropout(p=0.15, inplace=False)
        )
      )
      (layers3): ModuleList(
        (0-2): 3 x CommonAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
            (conv1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
            (conv2): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1))
            (conv3): Conv2d(512, 1536, kernel_size=(1, 1), stride=(1, 1))
          )
          (linear1): Linear(in_features=512, out_features=1024, bias=True)
          (dropout): Dropout(p=0.05, inplace=False)
          (linear2): Linear(in_features=1024, out_features=512, bias=True)
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (dropout2): Dropout(p=0.15, inplace=False)
          (dropout3): Dropout(p=0.15, inplace=False)
        )
      )
      (dynamic_shared_fusion): DSF(
        (w_att): Linear(in_features=1024, out_features=512, bias=True)
      )
    )
    (tgt_word_prj): Linear(in_features=512, out_features=81, bias=False)
  )
)
2026-01-05 10:32:20,078 - CDistNet - INFO - model parameter:-------
Trainable: 65.499528 M
2026-01-05 10:32:20,079 - CDistNet - INFO - model struct:-------
DataParallel(
  (module): CDistNet(
    (visual_branch): VIS_Pre(
      (transform): TPS_SpatialTransformerNetwork(
        (LocalizationNetwork): LocalizationNetwork(
          (conv): Sequential(
            (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU(inplace=True)
            (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
            (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (6): ReLU(inplace=True)
            (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
            (8): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (9): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (10): ReLU(inplace=True)
            (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
            (12): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (13): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (14): ReLU(inplace=True)
            (15): AdaptiveAvgPool2d(output_size=1)
          )
          (localization_fc1): Sequential(
            (0): Linear(in_features=512, out_features=256, bias=True)
            (1): ReLU(inplace=True)
          )
          (localization_fc2): Linear(in_features=256, out_features=40, bias=True)
        )
        (GridGenerator): GridGenerator()
      )
      (backbone): ABI_ResNet(
        (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (convbnrelu): ConvBnRelu(
          (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
          (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (layer1): Sequential(
          (0): BasicBlock(
            (conv1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (downsample): Sequential(
              (0): Conv2d(32, 32, kernel_size=(1, 1), stride=(2, 2), bias=False)
              (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (1): BasicBlock(
            (conv1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (2): BasicBlock(
            (conv1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (layer2): Sequential(
          (0): BasicBlock(
            (conv1): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (downsample): Sequential(
              (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (1): BasicBlock(
            (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (2): BasicBlock(
            (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (3): BasicBlock(
            (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (layer3): Sequential(
          (0): BasicBlock(
            (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (downsample): Sequential(
              (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
              (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (1): BasicBlock(
            (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (2): BasicBlock(
            (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (3): BasicBlock(
            (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (4): BasicBlock(
            (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (5): BasicBlock(
            (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (layer4): Sequential(
          (0): BasicBlock(
            (conv1): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (downsample): Sequential(
              (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (1): BasicBlock(
            (conv1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (2): BasicBlock(
            (conv1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (3): BasicBlock(
            (conv1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (4): BasicBlock(
            (conv1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (5): BasicBlock(
            (conv1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (layer5): Sequential(
          (0): BasicBlock(
            (conv1): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (downsample): Sequential(
              (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (1): BasicBlock(
            (conv1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (2): BasicBlock(
            (conv1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
      )
      (positional_encoding): PositionalEncoding(
        (dropout): Dropout(p=0.15, inplace=False)
      )
      (trans_encoder): TransformerEncoder(
        (layers): ModuleList(
          (0-2): 3 x TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): Linear(in_features=512, out_features=512, bias=True)
              (conv1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
              (conv2): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1))
              (conv3): Conv2d(512, 1536, kernel_size=(1, 1), stride=(1, 1))
            )
            (conv1): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1))
            (conv2): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1))
            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.15, inplace=False)
            (dropout2): Dropout(p=0.15, inplace=False)
          )
        )
        (pos_encoding): PositionalEncoding(
          (dropout): Dropout(p=0.0, inplace=False)
        )
      )
    )
    (semantic_branch): SEM_Pre(
      (embedding): Embeddings(
        (embedding): Embedding(81, 512, padding_idx=0)
      )
      (positional_encoding): PositionalEncoding(
        (dropout): Dropout(p=0.15, inplace=False)
      )
    )
    (positional_branch): POS_Pre(
      (pos_encoding): PositionalEncoding(
        (dropout): Dropout(p=0.15, inplace=False)
      )
      (linear1): Linear(in_features=512, out_features=512, bias=True)
      (linear2): Linear(in_features=512, out_features=512, bias=True)
      (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    )
    (mdcdp): MDCDP(
      (layers_pos): ModuleList(
        (0-2): 3 x CommonAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
            (conv1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
            (conv2): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1))
            (conv3): Conv2d(512, 1536, kernel_size=(1, 1), stride=(1, 1))
          )
          (linear1): Linear(in_features=512, out_features=1024, bias=True)
          (dropout): Dropout(p=0.05, inplace=False)
          (linear2): Linear(in_features=1024, out_features=512, bias=True)
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (dropout2): Dropout(p=0.15, inplace=False)
          (dropout3): Dropout(p=0.15, inplace=False)
        )
      )
      (layers2): ModuleList(
        (0-2): 3 x CommonAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
            (conv1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
            (conv2): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1))
            (conv3): Conv2d(512, 1536, kernel_size=(1, 1), stride=(1, 1))
          )
          (linear1): Linear(in_features=512, out_features=1024, bias=True)
          (dropout): Dropout(p=0.05, inplace=False)
          (linear2): Linear(in_features=1024, out_features=512, bias=True)
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (dropout2): Dropout(p=0.15, inplace=False)
          (dropout3): Dropout(p=0.15, inplace=False)
        )
      )
      (layers3): ModuleList(
        (0-2): 3 x CommonAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
            (conv1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
            (conv2): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1))
            (conv3): Conv2d(512, 1536, kernel_size=(1, 1), stride=(1, 1))
          )
          (linear1): Linear(in_features=512, out_features=1024, bias=True)
          (dropout): Dropout(p=0.05, inplace=False)
          (linear2): Linear(in_features=1024, out_features=512, bias=True)
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (dropout2): Dropout(p=0.15, inplace=False)
          (dropout3): Dropout(p=0.15, inplace=False)
        )
      )
      (dynamic_shared_fusion): DSF(
        (w_att): Linear(in_features=1024, out_features=512, bias=True)
      )
    )
    (tgt_word_prj): Linear(in_features=512, out_features=81, bias=False)
  )
)
2026-01-05 10:32:21,309 - CDistNet - INFO - epoch: 0  iter: 0/16411  loss:  4.946627  lr:  0.000000  eta: 5:36:01
2026-01-05 10:33:34,397 - CDistNet - INFO - epoch: 0  iter: 100/16411  loss:  4.368728  lr:  0.000001  eta: 3:20:01
2026-01-05 10:34:47,354 - CDistNet - INFO - epoch: 0  iter: 200/16411  loss:  3.540767  lr:  0.000001  eta: 3:17:57
2026-01-05 10:36:13,673 - CDistNet - INFO - model parameter:-------
Trainable: 65.499528 M
2026-01-05 10:36:13,675 - CDistNet - INFO - model struct:-------
DataParallel(
  (module): CDistNet(
    (visual_branch): VIS_Pre(
      (transform): TPS_SpatialTransformerNetwork(
        (LocalizationNetwork): LocalizationNetwork(
          (conv): Sequential(
            (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU(inplace=True)
            (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
            (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (6): ReLU(inplace=True)
            (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
            (8): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (9): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (10): ReLU(inplace=True)
            (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
            (12): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (13): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (14): ReLU(inplace=True)
            (15): AdaptiveAvgPool2d(output_size=1)
          )
          (localization_fc1): Sequential(
            (0): Linear(in_features=512, out_features=256, bias=True)
            (1): ReLU(inplace=True)
          )
          (localization_fc2): Linear(in_features=256, out_features=40, bias=True)
        )
        (GridGenerator): GridGenerator()
      )
      (backbone): ABI_ResNet(
        (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (convbnrelu): ConvBnRelu(
          (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
          (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (layer1): Sequential(
          (0): BasicBlock(
            (conv1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (downsample): Sequential(
              (0): Conv2d(32, 32, kernel_size=(1, 1), stride=(2, 2), bias=False)
              (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (1): BasicBlock(
            (conv1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (2): BasicBlock(
            (conv1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (layer2): Sequential(
          (0): BasicBlock(
            (conv1): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (downsample): Sequential(
              (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (1): BasicBlock(
            (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (2): BasicBlock(
            (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (3): BasicBlock(
            (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (layer3): Sequential(
          (0): BasicBlock(
            (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (downsample): Sequential(
              (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
              (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (1): BasicBlock(
            (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (2): BasicBlock(
            (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (3): BasicBlock(
            (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (4): BasicBlock(
            (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (5): BasicBlock(
            (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (layer4): Sequential(
          (0): BasicBlock(
            (conv1): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (downsample): Sequential(
              (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (1): BasicBlock(
            (conv1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (2): BasicBlock(
            (conv1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (3): BasicBlock(
            (conv1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (4): BasicBlock(
            (conv1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (5): BasicBlock(
            (conv1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (layer5): Sequential(
          (0): BasicBlock(
            (conv1): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (downsample): Sequential(
              (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (1): BasicBlock(
            (conv1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (2): BasicBlock(
            (conv1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
      )
      (positional_encoding): PositionalEncoding(
        (dropout): Dropout(p=0.15, inplace=False)
      )
      (trans_encoder): TransformerEncoder(
        (layers): ModuleList(
          (0-2): 3 x TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): Linear(in_features=512, out_features=512, bias=True)
              (conv1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
              (conv2): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1))
              (conv3): Conv2d(512, 1536, kernel_size=(1, 1), stride=(1, 1))
            )
            (conv1): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1))
            (conv2): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1))
            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.15, inplace=False)
            (dropout2): Dropout(p=0.15, inplace=False)
          )
        )
        (pos_encoding): PositionalEncoding(
          (dropout): Dropout(p=0.0, inplace=False)
        )
      )
    )
    (semantic_branch): SEM_Pre(
      (embedding): Embeddings(
        (embedding): Embedding(81, 512, padding_idx=0)
      )
      (positional_encoding): PositionalEncoding(
        (dropout): Dropout(p=0.15, inplace=False)
      )
    )
    (positional_branch): POS_Pre(
      (pos_encoding): PositionalEncoding(
        (dropout): Dropout(p=0.15, inplace=False)
      )
      (linear1): Linear(in_features=512, out_features=512, bias=True)
      (linear2): Linear(in_features=512, out_features=512, bias=True)
      (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    )
    (mdcdp): MDCDP(
      (layers_pos): ModuleList(
        (0-2): 3 x CommonAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
            (conv1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
            (conv2): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1))
            (conv3): Conv2d(512, 1536, kernel_size=(1, 1), stride=(1, 1))
          )
          (linear1): Linear(in_features=512, out_features=1024, bias=True)
          (dropout): Dropout(p=0.05, inplace=False)
          (linear2): Linear(in_features=1024, out_features=512, bias=True)
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (dropout2): Dropout(p=0.15, inplace=False)
          (dropout3): Dropout(p=0.15, inplace=False)
        )
      )
      (layers2): ModuleList(
        (0-2): 3 x CommonAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
            (conv1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
            (conv2): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1))
            (conv3): Conv2d(512, 1536, kernel_size=(1, 1), stride=(1, 1))
          )
          (linear1): Linear(in_features=512, out_features=1024, bias=True)
          (dropout): Dropout(p=0.05, inplace=False)
          (linear2): Linear(in_features=1024, out_features=512, bias=True)
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (dropout2): Dropout(p=0.15, inplace=False)
          (dropout3): Dropout(p=0.15, inplace=False)
        )
      )
      (layers3): ModuleList(
        (0-2): 3 x CommonAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
            (conv1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
            (conv2): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1))
            (conv3): Conv2d(512, 1536, kernel_size=(1, 1), stride=(1, 1))
          )
          (linear1): Linear(in_features=512, out_features=1024, bias=True)
          (dropout): Dropout(p=0.05, inplace=False)
          (linear2): Linear(in_features=1024, out_features=512, bias=True)
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (dropout2): Dropout(p=0.15, inplace=False)
          (dropout3): Dropout(p=0.15, inplace=False)
        )
      )
      (dynamic_shared_fusion): DSF(
        (w_att): Linear(in_features=1024, out_features=512, bias=True)
      )
    )
    (tgt_word_prj): Linear(in_features=512, out_features=81, bias=False)
  )
)
2026-01-05 10:36:15,067 - CDistNet - INFO - epoch: 0  iter: 0/13129  loss:  4.784718  lr:  0.000000  eta: 5:04:16
2026-01-05 10:37:46,101 - CDistNet - INFO - epoch: 0  iter: 100/13129  loss:  4.225180  lr:  0.000001  eta: 3:18:42
2026-01-05 10:39:17,460 - CDistNet - INFO - epoch: 0  iter: 200/13129  loss:  3.583673  lr:  0.000001  eta: 3:17:01
2026-01-05 10:40:49,612 - CDistNet - INFO - model parameter:-------
Trainable: 65.499528 M
2026-01-05 10:40:49,613 - CDistNet - INFO - model struct:-------
DataParallel(
  (module): CDistNet(
    (visual_branch): VIS_Pre(
      (transform): TPS_SpatialTransformerNetwork(
        (LocalizationNetwork): LocalizationNetwork(
          (conv): Sequential(
            (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU(inplace=True)
            (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
            (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (6): ReLU(inplace=True)
            (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
            (8): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (9): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (10): ReLU(inplace=True)
            (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
            (12): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (13): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (14): ReLU(inplace=True)
            (15): AdaptiveAvgPool2d(output_size=1)
          )
          (localization_fc1): Sequential(
            (0): Linear(in_features=512, out_features=256, bias=True)
            (1): ReLU(inplace=True)
          )
          (localization_fc2): Linear(in_features=256, out_features=40, bias=True)
        )
        (GridGenerator): GridGenerator()
      )
      (backbone): ABI_ResNet(
        (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (convbnrelu): ConvBnRelu(
          (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
          (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (layer1): Sequential(
          (0): BasicBlock(
            (conv1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (downsample): Sequential(
              (0): Conv2d(32, 32, kernel_size=(1, 1), stride=(2, 2), bias=False)
              (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (1): BasicBlock(
            (conv1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (2): BasicBlock(
            (conv1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (layer2): Sequential(
          (0): BasicBlock(
            (conv1): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (downsample): Sequential(
              (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (1): BasicBlock(
            (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (2): BasicBlock(
            (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (3): BasicBlock(
            (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (layer3): Sequential(
          (0): BasicBlock(
            (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (downsample): Sequential(
              (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
              (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (1): BasicBlock(
            (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (2): BasicBlock(
            (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (3): BasicBlock(
            (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (4): BasicBlock(
            (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (5): BasicBlock(
            (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (layer4): Sequential(
          (0): BasicBlock(
            (conv1): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (downsample): Sequential(
              (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (1): BasicBlock(
            (conv1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (2): BasicBlock(
            (conv1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (3): BasicBlock(
            (conv1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (4): BasicBlock(
            (conv1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (5): BasicBlock(
            (conv1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (layer5): Sequential(
          (0): BasicBlock(
            (conv1): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (downsample): Sequential(
              (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (1): BasicBlock(
            (conv1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (2): BasicBlock(
            (conv1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
      )
      (positional_encoding): PositionalEncoding(
        (dropout): Dropout(p=0.15, inplace=False)
      )
      (trans_encoder): TransformerEncoder(
        (layers): ModuleList(
          (0-2): 3 x TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): Linear(in_features=512, out_features=512, bias=True)
              (conv1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
              (conv2): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1))
              (conv3): Conv2d(512, 1536, kernel_size=(1, 1), stride=(1, 1))
            )
            (conv1): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1))
            (conv2): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1))
            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.15, inplace=False)
            (dropout2): Dropout(p=0.15, inplace=False)
          )
        )
        (pos_encoding): PositionalEncoding(
          (dropout): Dropout(p=0.0, inplace=False)
        )
      )
    )
    (semantic_branch): SEM_Pre(
      (embedding): Embeddings(
        (embedding): Embedding(81, 512, padding_idx=0)
      )
      (positional_encoding): PositionalEncoding(
        (dropout): Dropout(p=0.15, inplace=False)
      )
    )
    (positional_branch): POS_Pre(
      (pos_encoding): PositionalEncoding(
        (dropout): Dropout(p=0.15, inplace=False)
      )
      (linear1): Linear(in_features=512, out_features=512, bias=True)
      (linear2): Linear(in_features=512, out_features=512, bias=True)
      (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    )
    (mdcdp): MDCDP(
      (layers_pos): ModuleList(
        (0-2): 3 x CommonAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
            (conv1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
            (conv2): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1))
            (conv3): Conv2d(512, 1536, kernel_size=(1, 1), stride=(1, 1))
          )
          (linear1): Linear(in_features=512, out_features=1024, bias=True)
          (dropout): Dropout(p=0.05, inplace=False)
          (linear2): Linear(in_features=1024, out_features=512, bias=True)
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (dropout2): Dropout(p=0.15, inplace=False)
          (dropout3): Dropout(p=0.15, inplace=False)
        )
      )
      (layers2): ModuleList(
        (0-2): 3 x CommonAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
            (conv1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
            (conv2): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1))
            (conv3): Conv2d(512, 1536, kernel_size=(1, 1), stride=(1, 1))
          )
          (linear1): Linear(in_features=512, out_features=1024, bias=True)
          (dropout): Dropout(p=0.05, inplace=False)
          (linear2): Linear(in_features=1024, out_features=512, bias=True)
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (dropout2): Dropout(p=0.15, inplace=False)
          (dropout3): Dropout(p=0.15, inplace=False)
        )
      )
      (layers3): ModuleList(
        (0-2): 3 x CommonAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
            (conv1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
            (conv2): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1))
            (conv3): Conv2d(512, 1536, kernel_size=(1, 1), stride=(1, 1))
          )
          (linear1): Linear(in_features=512, out_features=1024, bias=True)
          (dropout): Dropout(p=0.05, inplace=False)
          (linear2): Linear(in_features=1024, out_features=512, bias=True)
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (dropout2): Dropout(p=0.15, inplace=False)
          (dropout3): Dropout(p=0.15, inplace=False)
        )
      )
      (dynamic_shared_fusion): DSF(
        (w_att): Linear(in_features=1024, out_features=512, bias=True)
      )
    )
    (tgt_word_prj): Linear(in_features=512, out_features=81, bias=False)
  )
)
2026-01-05 10:40:51,021 - CDistNet - INFO - epoch: 0  iter: 0/13129  loss:  4.615453  lr:  0.000000  eta: 5:07:44
2026-01-05 10:40:51,241 - CDistNet - INFO - eval_loss:4.6177,eval_acc:0.0133--------

2026-01-05 10:40:51,241 - CDistNet - INFO - Saving model: best_acc in epoch:0,iteration:0
2026-01-05 10:40:51,574 - CDistNet - INFO - Saved!
2026-01-05 10:42:22,372 - CDistNet - INFO - epoch: 0  iter: 100/13129  loss:  4.078860  lr:  0.000001  eta: 3:19:25
2026-01-05 10:43:53,312 - CDistNet - INFO - epoch: 0  iter: 200/13129  loss:  3.522016  lr:  0.000001  eta: 3:16:56
2026-01-05 10:45:23,913 - CDistNet - INFO - epoch: 0  iter: 300/13129  loss:  3.401698  lr:  0.000002  eta: 3:14:50
2026-01-05 10:46:54,592 - CDistNet - INFO - epoch: 0  iter: 400/13129  loss:  3.326576  lr:  0.000002  eta: 3:13:05
2026-01-05 10:48:25,309 - CDistNet - INFO - epoch: 0  iter: 500/13129  loss:  3.234571  lr:  0.000003  eta: 3:11:26
2026-01-05 10:49:55,913 - CDistNet - INFO - epoch: 0  iter: 600/13129  loss:  3.210098  lr:  0.000003  eta: 3:09:48
2026-01-05 10:51:26,498 - CDistNet - INFO - epoch: 0  iter: 700/13129  loss:  3.205825  lr:  0.000004  eta: 3:08:12
2026-01-05 10:52:56,971 - CDistNet - INFO - epoch: 0  iter: 800/13129  loss:  3.147351  lr:  0.000004  eta: 3:06:35
2026-01-05 10:54:27,610 - CDistNet - INFO - epoch: 0  iter: 900/13129  loss:  3.119821  lr:  0.000005  eta: 3:05:02
2026-01-05 10:55:58,424 - CDistNet - INFO - epoch: 0  iter: 1000/13129  loss:  3.055959  lr:  0.000006  eta: 3:03:31
2026-01-05 10:57:28,917 - CDistNet - INFO - epoch: 0  iter: 1100/13129  loss:  3.084847  lr:  0.000006  eta: 3:01:57
2026-01-05 10:58:59,579 - CDistNet - INFO - epoch: 0  iter: 1200/13129  loss:  3.072429  lr:  0.000007  eta: 3:00:26
2026-01-05 11:00:30,301 - CDistNet - INFO - epoch: 0  iter: 1300/13129  loss:  3.045542  lr:  0.000007  eta: 2:58:55
2026-01-05 11:02:01,131 - CDistNet - INFO - epoch: 0  iter: 1400/13129  loss:  3.023469  lr:  0.000008  eta: 2:57:24
2026-01-05 11:03:31,700 - CDistNet - INFO - epoch: 0  iter: 1500/13129  loss:  2.976335  lr:  0.000008  eta: 2:55:52
2026-01-05 11:05:02,098 - CDistNet - INFO - epoch: 0  iter: 1600/13129  loss:  2.924389  lr:  0.000009  eta: 2:54:19
2026-01-05 11:06:32,639 - CDistNet - INFO - epoch: 0  iter: 1700/13129  loss:  2.883912  lr:  0.000009  eta: 2:52:47
2026-01-05 11:08:03,185 - CDistNet - INFO - epoch: 0  iter: 1800/13129  loss:  2.843632  lr:  0.000010  eta: 2:51:15
2026-01-05 11:09:33,712 - CDistNet - INFO - epoch: 0  iter: 1900/13129  loss:  2.852902  lr:  0.000011  eta: 2:49:44
2026-01-05 11:11:04,183 - CDistNet - INFO - epoch: 0  iter: 2000/13129  loss:  2.855468  lr:  0.000011  eta: 2:48:12
2026-01-05 11:12:34,893 - CDistNet - INFO - epoch: 0  iter: 2100/13129  loss:  2.758007  lr:  0.000012  eta: 2:46:41
2026-01-05 11:14:05,361 - CDistNet - INFO - epoch: 0  iter: 2200/13129  loss:  2.803454  lr:  0.000012  eta: 2:45:09
2026-01-05 11:15:35,793 - CDistNet - INFO - epoch: 0  iter: 2300/13129  loss:  2.683941  lr:  0.000013  eta: 2:43:37
2026-01-05 11:17:06,226 - CDistNet - INFO - epoch: 0  iter: 2400/13129  loss:  2.639711  lr:  0.000013  eta: 2:42:06
2026-01-05 11:18:36,440 - CDistNet - INFO - epoch: 0  iter: 2500/13129  loss:  2.578853  lr:  0.000014  eta: 2:40:33
2026-01-05 11:20:06,951 - CDistNet - INFO - epoch: 0  iter: 2600/13129  loss:  2.593509  lr:  0.000014  eta: 2:39:02
2026-01-05 11:21:37,213 - CDistNet - INFO - epoch: 0  iter: 2700/13129  loss:  2.491800  lr:  0.000015  eta: 2:37:30
2026-01-05 11:23:07,677 - CDistNet - INFO - epoch: 0  iter: 2800/13129  loss:  2.445423  lr:  0.000015  eta: 2:35:59
2026-01-05 11:24:38,397 - CDistNet - INFO - epoch: 0  iter: 2900/13129  loss:  2.463556  lr:  0.000016  eta: 2:34:29
2026-01-05 11:26:08,682 - CDistNet - INFO - epoch: 0  iter: 3000/13129  loss:  2.343680  lr:  0.000017  eta: 2:32:57
2026-01-05 11:27:39,102 - CDistNet - INFO - epoch: 0  iter: 3100/13129  loss:  2.310957  lr:  0.000017  eta: 2:31:26
2026-01-05 11:29:09,246 - CDistNet - INFO - epoch: 0  iter: 3200/13129  loss:  2.208544  lr:  0.000018  eta: 2:29:54
2026-01-05 11:30:39,616 - CDistNet - INFO - epoch: 0  iter: 3300/13129  loss:  2.063638  lr:  0.000018  eta: 2:28:22
2026-01-05 11:32:10,070 - CDistNet - INFO - epoch: 0  iter: 3400/13129  loss:  1.984282  lr:  0.000019  eta: 2:26:52
2026-01-05 11:33:40,487 - CDistNet - INFO - epoch: 0  iter: 3500/13129  loss:  1.914904  lr:  0.000019  eta: 2:25:21
2026-01-05 11:35:10,829 - CDistNet - INFO - epoch: 0  iter: 3600/13129  loss:  1.872290  lr:  0.000020  eta: 2:23:49
2026-01-05 11:36:41,136 - CDistNet - INFO - epoch: 0  iter: 3700/13129  loss:  1.811741  lr:  0.000020  eta: 2:22:18
2026-01-05 11:38:11,396 - CDistNet - INFO - epoch: 0  iter: 3800/13129  loss:  1.648287  lr:  0.000021  eta: 2:20:47
2026-01-05 11:39:41,406 - CDistNet - INFO - epoch: 0  iter: 3900/13129  loss:  1.620267  lr:  0.000022  eta: 2:19:15
2026-01-05 11:41:11,439 - CDistNet - INFO - epoch: 0  iter: 4000/13129  loss:  1.466067  lr:  0.000022  eta: 2:17:43
2026-01-05 11:41:11,593 - CDistNet - INFO - eval_loss:2.4714,eval_acc:0.5844--------

2026-01-05 11:41:11,593 - CDistNet - INFO - Saving model: best_acc in epoch:0,iteration:4000
2026-01-05 11:41:11,907 - CDistNet - INFO - Saved!
2026-01-05 11:42:42,445 - CDistNet - INFO - epoch: 0  iter: 4100/13129  loss:  1.453650  lr:  0.000023  eta: 2:16:14
2026-01-05 11:44:12,850 - CDistNet - INFO - epoch: 0  iter: 4200/13129  loss:  1.393898  lr:  0.000023  eta: 2:14:43
2026-01-05 11:45:43,236 - CDistNet - INFO - epoch: 0  iter: 4300/13129  loss:  1.295553  lr:  0.000024  eta: 2:13:12
2026-01-05 11:47:13,562 - CDistNet - INFO - epoch: 0  iter: 4400/13129  loss:  1.282979  lr:  0.000024  eta: 2:11:41
2026-01-05 11:48:43,909 - CDistNet - INFO - epoch: 0  iter: 4500/13129  loss:  1.225063  lr:  0.000025  eta: 2:10:10
2026-01-05 11:50:14,415 - CDistNet - INFO - epoch: 0  iter: 4600/13129  loss:  1.233601  lr:  0.000025  eta: 2:08:40
2026-01-05 11:51:44,762 - CDistNet - INFO - epoch: 0  iter: 4700/13129  loss:  1.162016  lr:  0.000026  eta: 2:07:09
2026-01-05 11:53:15,188 - CDistNet - INFO - epoch: 0  iter: 4800/13129  loss:  1.112997  lr:  0.000027  eta: 2:05:38
2026-01-05 11:54:46,175 - CDistNet - INFO - epoch: 0  iter: 4900/13129  loss:  1.044347  lr:  0.000027  eta: 2:04:09
2026-01-05 11:56:17,890 - CDistNet - INFO - epoch: 0  iter: 5000/13129  loss:  1.044242  lr:  0.000028  eta: 2:02:40
2026-01-05 11:57:48,994 - CDistNet - INFO - epoch: 0  iter: 5100/13129  loss:  1.047386  lr:  0.000028  eta: 2:01:10
2026-01-05 11:59:20,166 - CDistNet - INFO - epoch: 0  iter: 5200/13129  loss:  1.014156  lr:  0.000029  eta: 1:59:41
2026-01-05 12:00:51,122 - CDistNet - INFO - epoch: 0  iter: 5300/13129  loss:  0.959727  lr:  0.000029  eta: 1:58:11
2026-01-05 12:02:21,816 - CDistNet - INFO - epoch: 0  iter: 5400/13129  loss:  0.977466  lr:  0.000030  eta: 1:56:40
2026-01-05 12:03:53,186 - CDistNet - INFO - epoch: 0  iter: 5500/13129  loss:  0.976435  lr:  0.000030  eta: 1:55:11
2026-01-05 12:05:24,353 - CDistNet - INFO - epoch: 0  iter: 5600/13129  loss:  0.917003  lr:  0.000031  eta: 1:53:41
2026-01-05 12:06:55,365 - CDistNet - INFO - epoch: 0  iter: 5700/13129  loss:  0.986019  lr:  0.000031  eta: 1:52:11
2026-01-05 12:08:26,142 - CDistNet - INFO - epoch: 0  iter: 5800/13129  loss:  1.054490  lr:  0.000032  eta: 1:50:41
2026-01-05 12:09:57,022 - CDistNet - INFO - epoch: 0  iter: 5900/13129  loss:  0.979834  lr:  0.000033  eta: 1:49:10
2026-01-05 12:11:27,975 - CDistNet - INFO - epoch: 0  iter: 6000/13129  loss:  0.974920  lr:  0.000033  eta: 1:47:40
2026-01-05 12:12:58,782 - CDistNet - INFO - epoch: 0  iter: 6100/13129  loss:  0.892004  lr:  0.000034  eta: 1:46:10
2026-01-05 12:14:29,703 - CDistNet - INFO - epoch: 0  iter: 6200/13129  loss:  0.913625  lr:  0.000034  eta: 1:44:39
2026-01-05 12:16:00,677 - CDistNet - INFO - epoch: 0  iter: 6300/13129  loss:  0.906109  lr:  0.000035  eta: 1:43:09
2026-01-05 12:17:31,265 - CDistNet - INFO - epoch: 0  iter: 6400/13129  loss:  0.907747  lr:  0.000035  eta: 1:41:38
2026-01-05 12:19:02,037 - CDistNet - INFO - epoch: 0  iter: 6500/13129  loss:  0.871090  lr:  0.000036  eta: 1:40:08
2026-01-05 12:20:32,792 - CDistNet - INFO - epoch: 0  iter: 6600/13129  loss:  0.905964  lr:  0.000036  eta: 1:38:37
2026-01-05 12:22:03,119 - CDistNet - INFO - epoch: 0  iter: 6700/13129  loss:  0.869633  lr:  0.000037  eta: 1:37:06
2026-01-05 12:23:33,935 - CDistNet - INFO - epoch: 0  iter: 6800/13129  loss:  0.876458  lr:  0.000038  eta: 1:35:36
2026-01-05 12:25:04,619 - CDistNet - INFO - epoch: 0  iter: 6900/13129  loss:  0.951761  lr:  0.000038  eta: 1:34:05
2026-01-05 12:26:35,283 - CDistNet - INFO - epoch: 0  iter: 7000/13129  loss:  0.843903  lr:  0.000039  eta: 1:32:35
2026-01-05 12:28:05,767 - CDistNet - INFO - epoch: 0  iter: 7100/13129  loss:  0.914547  lr:  0.000039  eta: 1:31:04
2026-01-05 12:29:36,439 - CDistNet - INFO - epoch: 0  iter: 7200/13129  loss:  0.857576  lr:  0.000040  eta: 1:29:33
2026-01-05 12:31:07,105 - CDistNet - INFO - epoch: 0  iter: 7300/13129  loss:  0.830272  lr:  0.000040  eta: 1:28:03
2026-01-05 12:32:37,671 - CDistNet - INFO - epoch: 0  iter: 7400/13129  loss:  0.844970  lr:  0.000041  eta: 1:26:32
2026-01-05 12:34:08,467 - CDistNet - INFO - epoch: 0  iter: 7500/13129  loss:  0.892164  lr:  0.000041  eta: 1:25:02
2026-01-05 12:35:39,083 - CDistNet - INFO - epoch: 0  iter: 7600/13129  loss:  0.856884  lr:  0.000042  eta: 1:23:31
2026-01-05 12:37:09,720 - CDistNet - INFO - epoch: 0  iter: 7700/13129  loss:  0.838568  lr:  0.000043  eta: 1:22:00
2026-01-05 12:38:39,994 - CDistNet - INFO - epoch: 0  iter: 7800/13129  loss:  0.858723  lr:  0.000043  eta: 1:20:29
2026-01-05 12:40:10,400 - CDistNet - INFO - epoch: 0  iter: 7900/13129  loss:  0.861397  lr:  0.000044  eta: 1:18:59
2026-01-05 12:41:40,873 - CDistNet - INFO - epoch: 0  iter: 8000/13129  loss:  0.827549  lr:  0.000044  eta: 1:17:28
2026-01-05 12:41:41,025 - CDistNet - INFO - eval_loss:1.6485,eval_acc:0.8044--------

2026-01-05 12:41:41,025 - CDistNet - INFO - Saving model: best_acc in epoch:0,iteration:8000
2026-01-05 12:41:41,342 - CDistNet - INFO - Saved!
2026-01-05 12:43:11,924 - CDistNet - INFO - epoch: 0  iter: 8100/13129  loss:  0.813776  lr:  0.000045  eta: 1:15:58
2026-01-05 12:44:42,386 - CDistNet - INFO - epoch: 0  iter: 8200/13129  loss:  0.915855  lr:  0.000045  eta: 1:14:27
2026-01-05 12:46:12,966 - CDistNet - INFO - epoch: 0  iter: 8300/13129  loss:  0.832282  lr:  0.000046  eta: 1:12:56
2026-01-05 12:47:43,443 - CDistNet - INFO - epoch: 0  iter: 8400/13129  loss:  0.850710  lr:  0.000046  eta: 1:11:25
2026-01-05 12:49:13,830 - CDistNet - INFO - epoch: 0  iter: 8500/13129  loss:  0.811041  lr:  0.000047  eta: 1:09:55
2026-01-05 12:50:44,143 - CDistNet - INFO - epoch: 0  iter: 8600/13129  loss:  0.808758  lr:  0.000048  eta: 1:08:24
2026-01-05 12:52:14,539 - CDistNet - INFO - epoch: 0  iter: 8700/13129  loss:  0.857317  lr:  0.000048  eta: 1:06:53
2026-01-05 12:53:45,086 - CDistNet - INFO - epoch: 0  iter: 8800/13129  loss:  0.804077  lr:  0.000049  eta: 1:05:22
2026-01-05 12:55:15,798 - CDistNet - INFO - epoch: 0  iter: 8900/13129  loss:  0.801022  lr:  0.000049  eta: 1:03:52
2026-01-05 12:56:46,433 - CDistNet - INFO - epoch: 0  iter: 9000/13129  loss:  0.802027  lr:  0.000050  eta: 1:02:21
2026-01-05 12:58:18,595 - CDistNet - INFO - epoch: 0  iter: 9100/13129  loss:  0.829551  lr:  0.000050  eta: 1:00:51
2026-01-05 12:59:49,999 - CDistNet - INFO - epoch: 0  iter: 9200/13129  loss:  0.799673  lr:  0.000051  eta: 0:59:21
2026-01-05 13:01:20,811 - CDistNet - INFO - epoch: 0  iter: 9300/13129  loss:  0.825340  lr:  0.000051  eta: 0:57:50
2026-01-05 13:02:52,337 - CDistNet - INFO - epoch: 0  iter: 9400/13129  loss:  0.819556  lr:  0.000052  eta: 0:56:20
2026-01-05 13:04:23,166 - CDistNet - INFO - epoch: 0  iter: 9500/13129  loss:  0.803988  lr:  0.000052  eta: 0:54:50
2026-01-05 13:05:57,247 - CDistNet - INFO - epoch: 0  iter: 9600/13129  loss:  0.835196  lr:  0.000053  eta: 0:53:20
2026-01-05 13:07:44,917 - CDistNet - INFO - epoch: 0  iter: 9700/13129  loss:  0.895226  lr:  0.000054  eta: 0:51:55
2026-01-05 13:09:32,560 - CDistNet - INFO - epoch: 0  iter: 9800/13129  loss:  0.837583  lr:  0.000054  eta: 0:50:30
2026-01-05 13:11:14,800 - CDistNet - INFO - epoch: 0  iter: 9900/13129  loss:  0.805984  lr:  0.000055  eta: 0:49:03
2026-01-05 13:12:52,616 - CDistNet - INFO - epoch: 0  iter: 10000/13129  loss:  0.801257  lr:  0.000055  eta: 0:47:34
2026-01-05 13:14:30,683 - CDistNet - INFO - epoch: 0  iter: 10100/13129  loss:  0.820478  lr:  0.000056  eta: 0:46:05
2026-01-05 13:16:08,315 - CDistNet - INFO - epoch: 0  iter: 10200/13129  loss:  0.819481  lr:  0.000056  eta: 0:44:35
2026-01-05 13:17:46,536 - CDistNet - INFO - epoch: 0  iter: 10300/13129  loss:  0.805960  lr:  0.000057  eta: 0:43:06
2026-01-05 13:19:23,909 - CDistNet - INFO - epoch: 0  iter: 10400/13129  loss:  0.800789  lr:  0.000057  eta: 0:41:36
2026-01-05 13:21:03,319 - CDistNet - INFO - epoch: 0  iter: 10500/13129  loss:  0.801467  lr:  0.000058  eta: 0:40:06
2026-01-05 13:22:40,640 - CDistNet - INFO - epoch: 0  iter: 10600/13129  loss:  0.798409  lr:  0.000059  eta: 0:38:36
2026-01-05 13:24:12,440 - CDistNet - INFO - epoch: 0  iter: 10700/13129  loss:  0.811881  lr:  0.000059  eta: 0:37:05
2026-01-05 13:25:44,119 - CDistNet - INFO - epoch: 0  iter: 10800/13129  loss:  0.831137  lr:  0.000060  eta: 0:35:33
2026-01-05 13:27:15,887 - CDistNet - INFO - epoch: 0  iter: 10900/13129  loss:  0.797899  lr:  0.000060  eta: 0:34:01
2026-01-05 13:28:47,903 - CDistNet - INFO - epoch: 0  iter: 11000/13129  loss:  0.798649  lr:  0.000061  eta: 0:32:30
2026-01-05 13:30:19,931 - CDistNet - INFO - epoch: 0  iter: 11100/13129  loss:  0.810615  lr:  0.000061  eta: 0:30:58
2026-01-05 13:31:51,546 - CDistNet - INFO - epoch: 0  iter: 11200/13129  loss:  0.812661  lr:  0.000062  eta: 0:29:27
2026-01-05 13:33:22,760 - CDistNet - INFO - epoch: 0  iter: 11300/13129  loss:  0.809946  lr:  0.000062  eta: 0:27:55
2026-01-05 13:34:54,215 - CDistNet - INFO - epoch: 0  iter: 11400/13129  loss:  0.791939  lr:  0.000063  eta: 0:26:23
2026-01-05 13:36:25,788 - CDistNet - INFO - epoch: 0  iter: 11500/13129  loss:  0.827150  lr:  0.000064  eta: 0:24:52
2026-01-05 13:37:57,540 - CDistNet - INFO - epoch: 0  iter: 11600/13129  loss:  0.807801  lr:  0.000064  eta: 0:23:20
2026-01-05 13:39:29,012 - CDistNet - INFO - epoch: 0  iter: 11700/13129  loss:  0.800393  lr:  0.000065  eta: 0:21:49
2026-01-05 13:41:00,690 - CDistNet - INFO - epoch: 0  iter: 11800/13129  loss:  0.827024  lr:  0.000065  eta: 0:20:17
2026-01-05 13:42:32,038 - CDistNet - INFO - epoch: 0  iter: 11900/13129  loss:  0.817263  lr:  0.000066  eta: 0:18:45
2026-01-05 13:44:03,399 - CDistNet - INFO - epoch: 0  iter: 12000/13129  loss:  0.819662  lr:  0.000066  eta: 0:17:14
2026-01-05 13:44:03,580 - CDistNet - INFO - eval_loss:1.5508,eval_acc:0.8400--------

2026-01-05 13:44:03,580 - CDistNet - INFO - Saving model: best_acc in epoch:0,iteration:12000
2026-01-05 13:44:03,947 - CDistNet - INFO - Saved!
2026-01-05 13:45:35,397 - CDistNet - INFO - epoch: 0  iter: 12100/13129  loss:  0.802491  lr:  0.000067  eta: 0:15:42
2026-01-05 13:47:07,035 - CDistNet - INFO - epoch: 0  iter: 12200/13129  loss:  0.823117  lr:  0.000067  eta: 0:14:11
2026-01-05 13:48:39,008 - CDistNet - INFO - epoch: 0  iter: 12300/13129  loss:  0.808954  lr:  0.000068  eta: 0:12:39
2026-01-05 13:50:10,678 - CDistNet - INFO - epoch: 0  iter: 12400/13129  loss:  0.803489  lr:  0.000069  eta: 0:11:07
2026-01-05 13:51:42,824 - CDistNet - INFO - epoch: 0  iter: 12500/13129  loss:  0.796504  lr:  0.000069  eta: 0:09:36
2026-01-05 13:53:14,806 - CDistNet - INFO - epoch: 0  iter: 12600/13129  loss:  0.796730  lr:  0.000070  eta: 0:08:04
2026-01-05 13:54:46,529 - CDistNet - INFO - epoch: 0  iter: 12700/13129  loss:  0.805014  lr:  0.000070  eta: 0:06:33
2026-01-05 13:56:17,601 - CDistNet - INFO - epoch: 0  iter: 12800/13129  loss:  0.818005  lr:  0.000071  eta: 0:05:01
2026-01-05 13:57:49,313 - CDistNet - INFO - epoch: 0  iter: 12900/13129  loss:  0.794013  lr:  0.000071  eta: 0:03:29
2026-01-05 13:59:21,434 - CDistNet - INFO - epoch: 0  iter: 13000/13129  loss:  0.803622  lr:  0.000072  eta: 0:01:58
2026-01-05 14:00:52,814 - CDistNet - INFO - epoch: 0  iter: 13100/13129  loss:  0.805745  lr:  0.000072  eta: 0:00:26
2026-01-05 14:01:18,635 - CDistNet - INFO - Now: best_acc in epoch:0,iteration:12000
2026-01-05 14:01:18,638 - CDistNet - INFO -   - (Training)   loss:  1.45582, accuracy: 77.869 %, time: 200.484 min
2026-01-05 14:01:19,626 - CDistNet - INFO - epoch: 1  iter: 0/13129  loss:  0.809066  lr:  0.000073  eta: 3:35:55
2026-01-05 14:01:19,781 - CDistNet - INFO - eval_loss:1.6101,eval_acc:0.8244--------

2026-01-05 14:01:19,782 - CDistNet - INFO - Saving model: best_acc in epoch:1,iteration:0
2026-01-05 14:01:20,028 - CDistNet - INFO - Saved!
2026-01-05 14:02:51,015 - CDistNet - INFO - epoch: 1  iter: 100/13129  loss:  0.797938  lr:  0.000073  eta: 3:18:36
2026-01-05 14:04:22,467 - CDistNet - INFO - epoch: 1  iter: 200/13129  loss:  0.830741  lr:  0.000074  eta: 3:17:04
2026-01-05 14:05:54,584 - CDistNet - INFO - epoch: 1  iter: 300/13129  loss:  0.803150  lr:  0.000074  eta: 3:16:01
2026-01-05 14:07:27,016 - CDistNet - INFO - epoch: 1  iter: 400/13129  loss:  0.783377  lr:  0.000075  eta: 3:14:53
2026-01-05 14:08:58,413 - CDistNet - INFO - epoch: 1  iter: 500/13129  loss:  0.803617  lr:  0.000075  eta: 3:13:09
2026-01-05 14:10:29,881 - CDistNet - INFO - epoch: 1  iter: 600/13129  loss:  0.783965  lr:  0.000076  eta: 3:11:31
2026-01-05 14:12:01,800 - CDistNet - INFO - epoch: 1  iter: 700/13129  loss:  0.811665  lr:  0.000076  eta: 3:10:03
2026-01-05 14:13:33,091 - CDistNet - INFO - epoch: 1  iter: 800/13129  loss:  0.797020  lr:  0.000077  eta: 3:08:24
2026-01-05 14:15:04,528 - CDistNet - INFO - epoch: 1  iter: 900/13129  loss:  0.802899  lr:  0.000078  eta: 3:06:49
2026-01-05 14:16:36,162 - CDistNet - INFO - epoch: 1  iter: 1000/13129  loss:  0.800164  lr:  0.000078  eta: 3:05:17
2026-01-05 14:18:07,619 - CDistNet - INFO - epoch: 1  iter: 1100/13129  loss:  0.807670  lr:  0.000079  eta: 3:03:43
2026-01-05 14:19:38,867 - CDistNet - INFO - epoch: 1  iter: 1200/13129  loss:  0.796600  lr:  0.000079  eta: 3:02:08
2026-01-05 14:21:10,341 - CDistNet - INFO - epoch: 1  iter: 1300/13129  loss:  0.808508  lr:  0.000080  eta: 3:00:35
2026-01-05 14:22:42,274 - CDistNet - INFO - epoch: 1  iter: 1400/13129  loss:  0.808815  lr:  0.000080  eta: 2:59:06
2026-01-05 14:24:13,713 - CDistNet - INFO - epoch: 1  iter: 1500/13129  loss:  0.793351  lr:  0.000081  eta: 2:57:33
2026-01-05 14:25:44,966 - CDistNet - INFO - epoch: 1  iter: 1600/13129  loss:  0.797279  lr:  0.000081  eta: 2:55:59
2026-01-05 14:27:16,088 - CDistNet - INFO - epoch: 1  iter: 1700/13129  loss:  0.796217  lr:  0.000082  eta: 2:54:24
2026-01-05 14:28:48,864 - CDistNet - INFO - epoch: 1  iter: 1800/13129  loss:  0.870602  lr:  0.000082  eta: 2:53:00
2026-01-05 14:30:22,889 - CDistNet - INFO - epoch: 1  iter: 1900/13129  loss:  0.799540  lr:  0.000083  eta: 2:51:43
2026-01-05 14:31:56,850 - CDistNet - INFO - epoch: 1  iter: 2000/13129  loss:  0.809535  lr:  0.000084  eta: 2:50:23
2026-01-05 14:33:31,169 - CDistNet - INFO - epoch: 1  iter: 2100/13129  loss:  0.817013  lr:  0.000084  eta: 2:49:04
2026-01-05 14:35:05,646 - CDistNet - INFO - epoch: 1  iter: 2200/13129  loss:  0.812110  lr:  0.000085  eta: 2:47:45
2026-01-05 14:36:39,549 - CDistNet - INFO - epoch: 1  iter: 2300/13129  loss:  0.785702  lr:  0.000085  eta: 2:46:21
2026-01-05 14:38:13,244 - CDistNet - INFO - epoch: 1  iter: 2400/13129  loss:  0.793159  lr:  0.000086  eta: 2:44:56
2026-01-05 14:39:46,705 - CDistNet - INFO - epoch: 1  iter: 2500/13129  loss:  0.791868  lr:  0.000086  eta: 2:43:29
2026-01-05 14:41:20,238 - CDistNet - INFO - epoch: 1  iter: 2600/13129  loss:  0.788999  lr:  0.000087  eta: 2:42:01
2026-01-05 14:42:53,781 - CDistNet - INFO - epoch: 1  iter: 2700/13129  loss:  0.884353  lr:  0.000087  eta: 2:40:34
2026-01-05 14:44:27,305 - CDistNet - INFO - epoch: 1  iter: 2800/13129  loss:  0.797019  lr:  0.000088  eta: 2:39:05
2026-01-05 14:46:00,966 - CDistNet - INFO - epoch: 1  iter: 2900/13129  loss:  0.789176  lr:  0.000089  eta: 2:37:37
2026-01-05 14:47:34,340 - CDistNet - INFO - epoch: 1  iter: 3000/13129  loss:  0.803150  lr:  0.000089  eta: 2:36:08
2026-01-05 14:49:07,858 - CDistNet - INFO - epoch: 1  iter: 3100/13129  loss:  0.799705  lr:  0.000090  eta: 2:34:39
2026-01-05 14:50:41,439 - CDistNet - INFO - epoch: 1  iter: 3200/13129  loss:  0.800859  lr:  0.000090  eta: 2:33:10
2026-01-05 14:52:14,977 - CDistNet - INFO - epoch: 1  iter: 3300/13129  loss:  0.812886  lr:  0.000091  eta: 2:31:40
2026-01-05 14:53:48,478 - CDistNet - INFO - epoch: 1  iter: 3400/13129  loss:  0.800723  lr:  0.000091  eta: 2:30:10
2026-01-05 14:55:22,046 - CDistNet - INFO - epoch: 1  iter: 3500/13129  loss:  0.816476  lr:  0.000092  eta: 2:28:40
2026-01-05 14:56:53,986 - CDistNet - INFO - epoch: 1  iter: 3600/13129  loss:  0.790862  lr:  0.000092  eta: 2:27:06
2026-01-05 14:58:24,985 - CDistNet - INFO - epoch: 1  iter: 3700/13129  loss:  0.816658  lr:  0.000093  eta: 2:25:29
2026-01-05 14:59:55,717 - CDistNet - INFO - epoch: 1  iter: 3800/13129  loss:  0.800361  lr:  0.000094  eta: 2:23:52
2026-01-05 15:01:26,691 - CDistNet - INFO - epoch: 1  iter: 3900/13129  loss:  0.803337  lr:  0.000094  eta: 2:22:15
2026-01-05 15:02:57,558 - CDistNet - INFO - epoch: 1  iter: 4000/13129  loss:  0.858455  lr:  0.000095  eta: 2:20:39
2026-01-05 15:02:57,730 - CDistNet - INFO - eval_loss:1.5347,eval_acc:0.8378--------

2026-01-05 15:02:57,730 - CDistNet - INFO - Saving model: best_acc in epoch:1,iteration:4000
2026-01-05 15:02:58,065 - CDistNet - INFO - Saved!
2026-01-05 15:04:29,078 - CDistNet - INFO - epoch: 1  iter: 4100/13129  loss:  0.817088  lr:  0.000095  eta: 2:19:05
2026-01-05 15:06:00,069 - CDistNet - INFO - epoch: 1  iter: 4200/13129  loss:  0.790163  lr:  0.000096  eta: 2:17:29
2026-01-05 15:07:30,963 - CDistNet - INFO - epoch: 1  iter: 4300/13129  loss:  0.811054  lr:  0.000096  eta: 2:15:54
2026-01-05 15:09:02,153 - CDistNet - INFO - epoch: 1  iter: 4400/13129  loss:  0.800240  lr:  0.000097  eta: 2:14:19
2026-01-05 15:10:33,021 - CDistNet - INFO - epoch: 1  iter: 4500/13129  loss:  0.792860  lr:  0.000097  eta: 2:12:44
2026-01-05 15:12:04,089 - CDistNet - INFO - epoch: 1  iter: 4600/13129  loss:  0.870940  lr:  0.000098  eta: 2:11:09
2026-01-05 15:13:34,879 - CDistNet - INFO - epoch: 1  iter: 4700/13129  loss:  0.836630  lr:  0.000098  eta: 2:09:34
2026-01-05 15:15:05,596 - CDistNet - INFO - epoch: 1  iter: 4800/13129  loss:  0.801294  lr:  0.000099  eta: 2:08:00
2026-01-05 15:16:36,728 - CDistNet - INFO - epoch: 1  iter: 4900/13129  loss:  0.810152  lr:  0.000100  eta: 2:06:26
2026-01-05 15:18:07,459 - CDistNet - INFO - epoch: 1  iter: 5000/13129  loss:  0.794192  lr:  0.000100  eta: 2:04:51
2026-01-05 15:19:38,340 - CDistNet - INFO - epoch: 1  iter: 5100/13129  loss:  0.787673  lr:  0.000101  eta: 2:03:17
2026-01-05 15:21:09,027 - CDistNet - INFO - epoch: 1  iter: 5200/13129  loss:  0.796498  lr:  0.000101  eta: 2:01:43
2026-01-05 15:22:39,685 - CDistNet - INFO - epoch: 1  iter: 5300/13129  loss:  0.792482  lr:  0.000102  eta: 2:00:08
2026-01-05 15:24:10,475 - CDistNet - INFO - epoch: 1  iter: 5400/13129  loss:  0.798345  lr:  0.000102  eta: 1:58:34
2026-01-05 15:25:41,041 - CDistNet - INFO - epoch: 1  iter: 5500/13129  loss:  0.794711  lr:  0.000103  eta: 1:57:00
2026-01-05 15:27:11,965 - CDistNet - INFO - epoch: 1  iter: 5600/13129  loss:  0.813332  lr:  0.000103  eta: 1:55:27
2026-01-05 15:28:42,733 - CDistNet - INFO - epoch: 1  iter: 5700/13129  loss:  0.814783  lr:  0.000104  eta: 1:53:53
2026-01-05 15:30:13,568 - CDistNet - INFO - epoch: 1  iter: 5800/13129  loss:  0.798567  lr:  0.000105  eta: 1:52:20
2026-01-05 15:31:44,412 - CDistNet - INFO - epoch: 1  iter: 5900/13129  loss:  0.809119  lr:  0.000105  eta: 1:50:46
2026-01-05 15:33:15,042 - CDistNet - INFO - epoch: 1  iter: 6000/13129  loss:  0.792079  lr:  0.000106  eta: 1:49:13
2026-01-05 15:34:45,785 - CDistNet - INFO - epoch: 1  iter: 6100/13129  loss:  0.813340  lr:  0.000106  eta: 1:47:40
2026-01-05 15:36:16,364 - CDistNet - INFO - epoch: 1  iter: 6200/13129  loss:  0.799572  lr:  0.000107  eta: 1:46:06
2026-01-05 15:37:47,289 - CDistNet - INFO - epoch: 1  iter: 6300/13129  loss:  0.799065  lr:  0.000107  eta: 1:44:33
2026-01-05 15:39:18,067 - CDistNet - INFO - epoch: 1  iter: 6400/13129  loss:  0.811912  lr:  0.000108  eta: 1:43:00
2026-01-05 15:40:48,628 - CDistNet - INFO - epoch: 1  iter: 6500/13129  loss:  0.809326  lr:  0.000108  eta: 1:41:27
2026-01-05 15:42:19,389 - CDistNet - INFO - epoch: 1  iter: 6600/13129  loss:  0.818604  lr:  0.000109  eta: 1:39:54
2026-01-05 15:43:50,361 - CDistNet - INFO - epoch: 1  iter: 6700/13129  loss:  0.816852  lr:  0.000110  eta: 1:38:22
2026-01-05 15:45:21,366 - CDistNet - INFO - epoch: 1  iter: 6800/13129  loss:  0.809848  lr:  0.000110  eta: 1:36:49
2026-01-05 15:46:52,034 - CDistNet - INFO - epoch: 1  iter: 6900/13129  loss:  0.804887  lr:  0.000111  eta: 1:35:16
2026-01-05 15:48:22,817 - CDistNet - INFO - epoch: 1  iter: 7000/13129  loss:  0.811063  lr:  0.000111  eta: 1:33:44
2026-01-05 15:49:53,672 - CDistNet - INFO - epoch: 1  iter: 7100/13129  loss:  0.797892  lr:  0.000112  eta: 1:32:11
2026-01-05 15:51:24,301 - CDistNet - INFO - epoch: 1  iter: 7200/13129  loss:  0.871600  lr:  0.000112  eta: 1:30:38
2026-01-05 15:52:55,333 - CDistNet - INFO - epoch: 1  iter: 7300/13129  loss:  0.797244  lr:  0.000113  eta: 1:29:06
2026-01-05 15:54:26,139 - CDistNet - INFO - epoch: 1  iter: 7400/13129  loss:  0.797873  lr:  0.000113  eta: 1:27:34
2026-01-05 15:55:56,741 - CDistNet - INFO - epoch: 1  iter: 7500/13129  loss:  0.860773  lr:  0.000114  eta: 1:26:01
2026-01-05 15:57:27,369 - CDistNet - INFO - epoch: 1  iter: 7600/13129  loss:  0.793709  lr:  0.000115  eta: 1:24:29
2026-01-05 15:58:57,911 - CDistNet - INFO - epoch: 1  iter: 7700/13129  loss:  0.794632  lr:  0.000115  eta: 1:22:56
2026-01-05 16:00:28,704 - CDistNet - INFO - epoch: 1  iter: 7800/13129  loss:  0.779024  lr:  0.000116  eta: 1:21:24
2026-01-05 16:01:59,315 - CDistNet - INFO - epoch: 1  iter: 7900/13129  loss:  0.800684  lr:  0.000116  eta: 1:19:51
2026-01-05 16:03:29,993 - CDistNet - INFO - epoch: 1  iter: 8000/13129  loss:  0.796230  lr:  0.000117  eta: 1:18:19
2026-01-05 16:03:30,148 - CDistNet - INFO - eval_loss:1.3977,eval_acc:0.8400--------

2026-01-05 16:03:30,148 - CDistNet - INFO - Saving model: best_acc in epoch:1,iteration:8000
2026-01-05 16:03:30,466 - CDistNet - INFO - Saved!
2026-01-05 16:05:01,263 - CDistNet - INFO - epoch: 1  iter: 8100/13129  loss:  0.785377  lr:  0.000117  eta: 1:16:47
2026-01-05 16:06:32,008 - CDistNet - INFO - epoch: 1  iter: 8200/13129  loss:  0.862558  lr:  0.000118  eta: 1:15:15
2026-01-05 16:08:02,911 - CDistNet - INFO - epoch: 1  iter: 8300/13129  loss:  0.806770  lr:  0.000118  eta: 1:13:43
2026-01-05 16:09:33,598 - CDistNet - INFO - epoch: 1  iter: 8400/13129  loss:  0.789101  lr:  0.000119  eta: 1:12:11
2026-01-05 16:11:04,279 - CDistNet - INFO - epoch: 1  iter: 8500/13129  loss:  0.803208  lr:  0.000119  eta: 1:10:39
2026-01-05 16:12:34,891 - CDistNet - INFO - epoch: 1  iter: 8600/13129  loss:  0.798259  lr:  0.000120  eta: 1:09:07
2026-01-05 16:14:05,370 - CDistNet - INFO - epoch: 1  iter: 8700/13129  loss:  0.791698  lr:  0.000121  eta: 1:07:35
2026-01-05 16:15:36,048 - CDistNet - INFO - epoch: 1  iter: 8800/13129  loss:  0.815388  lr:  0.000121  eta: 1:06:03
2026-01-05 16:17:06,528 - CDistNet - INFO - epoch: 1  iter: 8900/13129  loss:  0.799537  lr:  0.000122  eta: 1:04:31
2026-01-05 16:18:36,933 - CDistNet - INFO - epoch: 1  iter: 9000/13129  loss:  0.802373  lr:  0.000122  eta: 1:02:59
2026-01-05 16:20:07,505 - CDistNet - INFO - epoch: 1  iter: 9100/13129  loss:  0.812688  lr:  0.000123  eta: 1:01:27
2026-01-05 16:21:37,866 - CDistNet - INFO - epoch: 1  iter: 9200/13129  loss:  0.811809  lr:  0.000123  eta: 0:59:55
2026-01-05 16:23:08,465 - CDistNet - INFO - epoch: 1  iter: 9300/13129  loss:  0.798109  lr:  0.000124  eta: 0:58:23
2026-01-05 16:24:38,983 - CDistNet - INFO - epoch: 1  iter: 9400/13129  loss:  0.793098  lr:  0.000124  eta: 0:56:51
2026-01-05 16:26:09,697 - CDistNet - INFO - epoch: 1  iter: 9500/13129  loss:  0.819154  lr:  0.000125  eta: 0:55:19
2026-01-05 16:27:40,185 - CDistNet - INFO - epoch: 1  iter: 9600/13129  loss:  0.797872  lr:  0.000126  eta: 0:53:47
2026-01-05 16:29:10,868 - CDistNet - INFO - epoch: 1  iter: 9700/13129  loss:  0.786758  lr:  0.000126  eta: 0:52:16
2026-01-05 16:30:41,261 - CDistNet - INFO - epoch: 1  iter: 9800/13129  loss:  0.818399  lr:  0.000127  eta: 0:50:44
2026-01-05 16:32:11,968 - CDistNet - INFO - epoch: 1  iter: 9900/13129  loss:  0.810241  lr:  0.000127  eta: 0:49:12
2026-01-05 16:33:42,427 - CDistNet - INFO - epoch: 1  iter: 10000/13129  loss:  0.804113  lr:  0.000128  eta: 0:47:40
2026-01-05 16:35:12,876 - CDistNet - INFO - epoch: 1  iter: 10100/13129  loss:  0.804389  lr:  0.000128  eta: 0:46:09
2026-01-05 16:36:43,482 - CDistNet - INFO - epoch: 1  iter: 10200/13129  loss:  0.824108  lr:  0.000129  eta: 0:44:37
2026-01-05 16:38:14,146 - CDistNet - INFO - epoch: 1  iter: 10300/13129  loss:  0.785436  lr:  0.000129  eta: 0:43:05
2026-01-05 16:39:44,944 - CDistNet - INFO - epoch: 1  iter: 10400/13129  loss:  0.790493  lr:  0.000130  eta: 0:41:34
2026-01-05 16:41:15,702 - CDistNet - INFO - epoch: 1  iter: 10500/13129  loss:  0.806571  lr:  0.000131  eta: 0:40:02
2026-01-05 16:42:46,382 - CDistNet - INFO - epoch: 1  iter: 10600/13129  loss:  0.804981  lr:  0.000131  eta: 0:38:31
2026-01-05 16:44:17,138 - CDistNet - INFO - epoch: 1  iter: 10700/13129  loss:  0.781751  lr:  0.000132  eta: 0:36:59
2026-01-05 16:45:47,806 - CDistNet - INFO - epoch: 1  iter: 10800/13129  loss:  0.787773  lr:  0.000132  eta: 0:35:28
2026-01-05 16:47:18,729 - CDistNet - INFO - epoch: 1  iter: 10900/13129  loss:  0.806543  lr:  0.000133  eta: 0:33:56
2026-01-05 16:48:49,762 - CDistNet - INFO - epoch: 1  iter: 11000/13129  loss:  0.781269  lr:  0.000133  eta: 0:32:25
2026-01-05 16:50:20,511 - CDistNet - INFO - epoch: 1  iter: 11100/13129  loss:  0.822091  lr:  0.000134  eta: 0:30:53
2026-01-05 16:51:51,666 - CDistNet - INFO - epoch: 1  iter: 11200/13129  loss:  0.789611  lr:  0.000134  eta: 0:29:22
2026-01-05 16:53:22,878 - CDistNet - INFO - epoch: 1  iter: 11300/13129  loss:  0.786511  lr:  0.000135  eta: 0:27:50
2026-01-05 16:54:54,178 - CDistNet - INFO - epoch: 1  iter: 11400/13129  loss:  0.799136  lr:  0.000136  eta: 0:26:19
2026-01-05 16:56:25,697 - CDistNet - INFO - epoch: 1  iter: 11500/13129  loss:  0.804252  lr:  0.000136  eta: 0:24:48
2026-01-05 16:57:57,395 - CDistNet - INFO - epoch: 1  iter: 11600/13129  loss:  0.798015  lr:  0.000137  eta: 0:23:16
2026-01-05 16:59:28,617 - CDistNet - INFO - epoch: 1  iter: 11700/13129  loss:  0.792680  lr:  0.000137  eta: 0:21:45
2026-01-05 17:01:00,277 - CDistNet - INFO - epoch: 1  iter: 11800/13129  loss:  0.789751  lr:  0.000138  eta: 0:20:14
2026-01-05 17:02:32,305 - CDistNet - INFO - epoch: 1  iter: 11900/13129  loss:  0.792605  lr:  0.000138  eta: 0:18:42
2026-01-05 17:04:05,100 - CDistNet - INFO - epoch: 1  iter: 12000/13129  loss:  0.798909  lr:  0.000139  eta: 0:17:11
2026-01-05 17:04:05,258 - CDistNet - INFO - eval_loss:1.4947,eval_acc:0.8400--------

2026-01-05 17:05:37,177 - CDistNet - INFO - epoch: 1  iter: 12100/13129  loss:  0.790429  lr:  0.000139  eta: 0:15:40
2026-01-05 17:07:09,329 - CDistNet - INFO - epoch: 1  iter: 12200/13129  loss:  0.791823  lr:  0.000140  eta: 0:14:09
2026-01-05 17:08:41,557 - CDistNet - INFO - epoch: 1  iter: 12300/13129  loss:  0.813695  lr:  0.000140  eta: 0:12:37
2026-01-05 17:10:13,317 - CDistNet - INFO - epoch: 1  iter: 12400/13129  loss:  0.795859  lr:  0.000141  eta: 0:11:06
2026-01-05 17:11:45,024 - CDistNet - INFO - epoch: 1  iter: 12500/13129  loss:  0.787837  lr:  0.000142  eta: 0:09:34
2026-01-05 17:13:16,797 - CDistNet - INFO - epoch: 1  iter: 12600/13129  loss:  0.819334  lr:  0.000142  eta: 0:08:03
2026-01-05 17:14:48,614 - CDistNet - INFO - epoch: 1  iter: 12700/13129  loss:  0.798609  lr:  0.000143  eta: 0:06:32
2026-01-05 17:16:20,230 - CDistNet - INFO - epoch: 1  iter: 12800/13129  loss:  0.802476  lr:  0.000143  eta: 0:05:00
2026-01-05 17:17:51,758 - CDistNet - INFO - epoch: 1  iter: 12900/13129  loss:  0.796382  lr:  0.000144  eta: 0:03:29
2026-01-05 17:19:23,613 - CDistNet - INFO - epoch: 1  iter: 13000/13129  loss:  0.797904  lr:  0.000144  eta: 0:01:57
2026-01-05 17:20:55,140 - CDistNet - INFO - epoch: 1  iter: 13100/13129  loss:  0.798509  lr:  0.000145  eta: 0:00:26
2026-01-05 17:21:20,760 - CDistNet - INFO - Now: best_acc in epoch:1,iteration:8000
2026-01-05 17:21:20,762 - CDistNet - INFO -   - (Training)   loss:  0.80459, accuracy: 98.935 %, time: 200.035 min
2026-01-05 17:21:21,740 - CDistNet - INFO - epoch: 2  iter: 0/13129  loss:  0.804322  lr:  0.000145  eta: 3:33:40
2026-01-05 17:21:21,898 - CDistNet - INFO - eval_loss:1.3481,eval_acc:0.8511--------

2026-01-05 17:21:21,899 - CDistNet - INFO - Saving model: best_acc in epoch:2,iteration:0
2026-01-05 17:21:22,194 - CDistNet - INFO - Saved!
2026-01-05 17:22:53,942 - CDistNet - INFO - epoch: 2  iter: 100/13129  loss:  0.792316  lr:  0.000146  eta: 3:20:20
2026-01-05 17:24:25,624 - CDistNet - INFO - epoch: 2  iter: 200/13129  loss:  0.800298  lr:  0.000146  eta: 3:18:10
2026-01-05 17:25:57,053 - CDistNet - INFO - epoch: 2  iter: 300/13129  loss:  0.884057  lr:  0.000147  eta: 3:16:15
2026-01-05 17:27:28,767 - CDistNet - INFO - epoch: 2  iter: 400/13129  loss:  0.785899  lr:  0.000147  eta: 3:14:41
2026-01-05 17:29:00,021 - CDistNet - INFO - epoch: 2  iter: 500/13129  loss:  0.784795  lr:  0.000148  eta: 3:12:56
2026-01-05 17:30:31,300 - CDistNet - INFO - epoch: 2  iter: 600/13129  loss:  0.787568  lr:  0.000148  eta: 3:11:16
2026-01-05 17:32:02,717 - CDistNet - INFO - epoch: 2  iter: 700/13129  loss:  0.797015  lr:  0.000149  eta: 3:09:42
2026-01-05 17:33:34,015 - CDistNet - INFO - epoch: 2  iter: 800/13129  loss:  0.812813  lr:  0.000149  eta: 3:08:06
2026-01-05 17:35:05,389 - CDistNet - INFO - epoch: 2  iter: 900/13129  loss:  0.792405  lr:  0.000150  eta: 3:06:32
2026-01-05 17:36:36,718 - CDistNet - INFO - epoch: 2  iter: 1000/13129  loss:  0.796174  lr:  0.000151  eta: 3:04:58
2026-01-05 17:38:07,902 - CDistNet - INFO - epoch: 2  iter: 1100/13129  loss:  0.819716  lr:  0.000151  eta: 3:03:23
2026-01-05 17:39:39,180 - CDistNet - INFO - epoch: 2  iter: 1200/13129  loss:  0.792968  lr:  0.000152  eta: 3:01:50
2026-01-05 17:41:10,296 - CDistNet - INFO - epoch: 2  iter: 1300/13129  loss:  0.782652  lr:  0.000152  eta: 3:00:15
2026-01-05 17:42:41,347 - CDistNet - INFO - epoch: 2  iter: 1400/13129  loss:  0.800877  lr:  0.000153  eta: 2:58:40
2026-01-05 17:44:12,259 - CDistNet - INFO - epoch: 2  iter: 1500/13129  loss:  0.794213  lr:  0.000153  eta: 2:57:05
2026-01-05 17:45:43,169 - CDistNet - INFO - epoch: 2  iter: 1600/13129  loss:  0.807010  lr:  0.000154  eta: 2:55:30
2026-01-05 17:47:14,372 - CDistNet - INFO - epoch: 2  iter: 1700/13129  loss:  0.800256  lr:  0.000154  eta: 2:53:58
2026-01-05 17:48:45,655 - CDistNet - INFO - epoch: 2  iter: 1800/13129  loss:  0.791856  lr:  0.000155  eta: 2:52:27
2026-01-05 17:50:16,822 - CDistNet - INFO - epoch: 2  iter: 1900/13129  loss:  0.814847  lr:  0.000156  eta: 2:50:54
2026-01-05 17:51:48,094 - CDistNet - INFO - epoch: 2  iter: 2000/13129  loss:  0.796990  lr:  0.000156  eta: 2:49:23
2026-01-05 17:53:19,245 - CDistNet - INFO - epoch: 2  iter: 2100/13129  loss:  0.789013  lr:  0.000157  eta: 2:47:50
2026-01-05 17:54:50,362 - CDistNet - INFO - epoch: 2  iter: 2200/13129  loss:  0.817001  lr:  0.000157  eta: 2:46:18
2026-01-05 17:56:21,303 - CDistNet - INFO - epoch: 2  iter: 2300/13129  loss:  0.782035  lr:  0.000158  eta: 2:44:45
2026-01-05 17:57:52,290 - CDistNet - INFO - epoch: 2  iter: 2400/13129  loss:  0.815557  lr:  0.000158  eta: 2:43:12
2026-01-05 17:59:23,307 - CDistNet - INFO - epoch: 2  iter: 2500/13129  loss:  0.801381  lr:  0.000159  eta: 2:41:40
2026-01-05 18:00:54,255 - CDistNet - INFO - epoch: 2  iter: 2600/13129  loss:  0.782083  lr:  0.000159  eta: 2:40:08
2026-01-05 18:02:25,152 - CDistNet - INFO - epoch: 2  iter: 2700/13129  loss:  0.799514  lr:  0.000160  eta: 2:38:35
2026-01-05 18:03:56,097 - CDistNet - INFO - epoch: 2  iter: 2800/13129  loss:  0.812117  lr:  0.000161  eta: 2:37:03
2026-01-05 18:05:27,004 - CDistNet - INFO - epoch: 2  iter: 2900/13129  loss:  0.780165  lr:  0.000161  eta: 2:35:30
2026-01-05 18:06:58,369 - CDistNet - INFO - epoch: 2  iter: 3000/13129  loss:  0.803241  lr:  0.000162  eta: 2:33:59
2026-01-05 18:08:29,546 - CDistNet - INFO - epoch: 2  iter: 3100/13129  loss:  0.802566  lr:  0.000162  eta: 2:32:28
2026-01-05 18:10:00,444 - CDistNet - INFO - epoch: 2  iter: 3200/13129  loss:  0.796571  lr:  0.000163  eta: 2:30:56
2026-01-05 18:11:31,497 - CDistNet - INFO - epoch: 2  iter: 3300/13129  loss:  0.799500  lr:  0.000163  eta: 2:29:24
2026-01-05 18:13:02,582 - CDistNet - INFO - epoch: 2  iter: 3400/13129  loss:  0.808670  lr:  0.000164  eta: 2:27:53
2026-01-05 18:14:33,521 - CDistNet - INFO - epoch: 2  iter: 3500/13129  loss:  0.808662  lr:  0.000164  eta: 2:26:21
2026-01-05 18:16:04,638 - CDistNet - INFO - epoch: 2  iter: 3600/13129  loss:  0.786095  lr:  0.000165  eta: 2:24:49
2026-01-05 18:17:35,517 - CDistNet - INFO - epoch: 2  iter: 3700/13129  loss:  0.892375  lr:  0.000166  eta: 2:23:17
2026-01-05 18:19:06,472 - CDistNet - INFO - epoch: 2  iter: 3800/13129  loss:  0.817241  lr:  0.000166  eta: 2:21:46
2026-01-05 18:20:37,528 - CDistNet - INFO - epoch: 2  iter: 3900/13129  loss:  0.813465  lr:  0.000167  eta: 2:20:14
2026-01-05 18:22:08,253 - CDistNet - INFO - epoch: 2  iter: 4000/13129  loss:  0.782642  lr:  0.000167  eta: 2:18:42
2026-01-05 18:22:08,409 - CDistNet - INFO - eval_loss:1.5019,eval_acc:0.8267--------

2026-01-05 18:23:39,330 - CDistNet - INFO - epoch: 2  iter: 4100/13129  loss:  0.791181  lr:  0.000168  eta: 2:17:11
2026-01-05 18:25:10,271 - CDistNet - INFO - epoch: 2  iter: 4200/13129  loss:  0.791956  lr:  0.000168  eta: 2:15:39
2026-01-05 18:26:41,064 - CDistNet - INFO - epoch: 2  iter: 4300/13129  loss:  0.808584  lr:  0.000169  eta: 2:14:07
2026-01-05 18:28:11,737 - CDistNet - INFO - epoch: 2  iter: 4400/13129  loss:  0.777060  lr:  0.000169  eta: 2:12:35
2026-01-05 18:29:42,810 - CDistNet - INFO - epoch: 2  iter: 4500/13129  loss:  0.797513  lr:  0.000170  eta: 2:11:04
2026-01-05 18:31:13,814 - CDistNet - INFO - epoch: 2  iter: 4600/13129  loss:  0.789178  lr:  0.000170  eta: 2:09:32
2026-01-05 18:32:44,703 - CDistNet - INFO - epoch: 2  iter: 4700/13129  loss:  0.806640  lr:  0.000171  eta: 2:08:01
2026-01-05 18:34:15,293 - CDistNet - INFO - epoch: 2  iter: 4800/13129  loss:  0.810462  lr:  0.000172  eta: 2:06:29
2026-01-05 18:35:45,910 - CDistNet - INFO - epoch: 2  iter: 4900/13129  loss:  0.802928  lr:  0.000172  eta: 2:04:57
2026-01-05 18:37:17,513 - CDistNet - INFO - epoch: 2  iter: 5000/13129  loss:  0.792674  lr:  0.000173  eta: 2:03:26
2026-01-05 18:38:48,829 - CDistNet - INFO - epoch: 2  iter: 5100/13129  loss:  0.782810  lr:  0.000173  eta: 2:01:56
2026-01-05 18:40:19,922 - CDistNet - INFO - epoch: 2  iter: 5200/13129  loss:  0.782089  lr:  0.000174  eta: 2:00:24
2026-01-05 18:41:50,958 - CDistNet - INFO - epoch: 2  iter: 5300/13129  loss:  0.798365  lr:  0.000174  eta: 1:58:53
2026-01-05 18:43:21,882 - CDistNet - INFO - epoch: 2  iter: 5400/13129  loss:  0.785680  lr:  0.000175  eta: 1:57:22
2026-01-05 18:44:52,933 - CDistNet - INFO - epoch: 2  iter: 5500/13129  loss:  0.791748  lr:  0.000175  eta: 1:55:51
2026-01-05 18:46:24,098 - CDistNet - INFO - epoch: 2  iter: 5600/13129  loss:  0.801998  lr:  0.000176  eta: 1:54:20
2026-01-05 18:47:54,987 - CDistNet - INFO - epoch: 2  iter: 5700/13129  loss:  0.787830  lr:  0.000177  eta: 1:52:48
2026-01-05 18:49:25,913 - CDistNet - INFO - epoch: 2  iter: 5800/13129  loss:  0.802728  lr:  0.000177  eta: 1:51:17
2026-01-05 18:50:56,873 - CDistNet - INFO - epoch: 2  iter: 5900/13129  loss:  0.794731  lr:  0.000178  eta: 1:49:45
2026-01-05 18:52:27,910 - CDistNet - INFO - epoch: 2  iter: 6000/13129  loss:  0.803063  lr:  0.000178  eta: 1:48:14
2026-01-05 18:53:58,795 - CDistNet - INFO - epoch: 2  iter: 6100/13129  loss:  0.809905  lr:  0.000179  eta: 1:46:43
2026-01-05 18:55:29,763 - CDistNet - INFO - epoch: 2  iter: 6200/13129  loss:  0.805107  lr:  0.000179  eta: 1:45:12
2026-01-05 18:57:00,464 - CDistNet - INFO - epoch: 2  iter: 6300/13129  loss:  0.782671  lr:  0.000180  eta: 1:43:40
2026-01-05 18:58:31,260 - CDistNet - INFO - epoch: 2  iter: 6400/13129  loss:  0.783107  lr:  0.000180  eta: 1:42:09
2026-01-05 19:00:02,268 - CDistNet - INFO - epoch: 2  iter: 6500/13129  loss:  0.781659  lr:  0.000181  eta: 1:40:38
2026-01-05 19:01:33,145 - CDistNet - INFO - epoch: 2  iter: 6600/13129  loss:  0.792039  lr:  0.000182  eta: 1:39:06
2026-01-05 19:03:03,885 - CDistNet - INFO - epoch: 2  iter: 6700/13129  loss:  0.786529  lr:  0.000182  eta: 1:37:35
2026-01-05 19:04:34,709 - CDistNet - INFO - epoch: 2  iter: 6800/13129  loss:  0.793480  lr:  0.000183  eta: 1:36:04
2026-01-05 19:06:05,433 - CDistNet - INFO - epoch: 2  iter: 6900/13129  loss:  0.790921  lr:  0.000183  eta: 1:34:32
2026-01-05 19:07:36,240 - CDistNet - INFO - epoch: 2  iter: 7000/13129  loss:  0.797235  lr:  0.000184  eta: 1:33:01
2026-01-05 19:09:07,137 - CDistNet - INFO - epoch: 2  iter: 7100/13129  loss:  0.807121  lr:  0.000184  eta: 1:31:30
2026-01-05 19:10:38,087 - CDistNet - INFO - epoch: 2  iter: 7200/13129  loss:  0.800741  lr:  0.000185  eta: 1:29:59
2026-01-05 19:12:09,057 - CDistNet - INFO - epoch: 2  iter: 7300/13129  loss:  0.811886  lr:  0.000185  eta: 1:28:27
2026-01-05 19:13:39,863 - CDistNet - INFO - epoch: 2  iter: 7400/13129  loss:  0.786703  lr:  0.000186  eta: 1:26:56
2026-01-05 19:15:10,809 - CDistNet - INFO - epoch: 2  iter: 7500/13129  loss:  0.784754  lr:  0.000186  eta: 1:25:25
2026-01-05 19:16:41,741 - CDistNet - INFO - epoch: 2  iter: 7600/13129  loss:  0.801960  lr:  0.000187  eta: 1:23:54
2026-01-05 19:18:12,498 - CDistNet - INFO - epoch: 2  iter: 7700/13129  loss:  0.782266  lr:  0.000188  eta: 1:22:23
2026-01-05 19:19:43,344 - CDistNet - INFO - epoch: 2  iter: 7800/13129  loss:  0.796847  lr:  0.000188  eta: 1:20:51
2026-01-05 19:21:14,258 - CDistNet - INFO - epoch: 2  iter: 7900/13129  loss:  0.800350  lr:  0.000189  eta: 1:19:20
2026-01-05 19:22:44,900 - CDistNet - INFO - epoch: 2  iter: 8000/13129  loss:  0.796791  lr:  0.000189  eta: 1:17:49
2026-01-05 19:22:45,054 - CDistNet - INFO - eval_loss:1.5516,eval_acc:0.8089--------

2026-01-05 19:24:16,086 - CDistNet - INFO - epoch: 2  iter: 8100/13129  loss:  0.790293  lr:  0.000190  eta: 1:16:18
2026-01-05 19:25:47,200 - CDistNet - INFO - epoch: 2  iter: 8200/13129  loss:  0.809206  lr:  0.000190  eta: 1:14:47
2026-01-05 19:27:18,019 - CDistNet - INFO - epoch: 2  iter: 8300/13129  loss:  0.805781  lr:  0.000191  eta: 1:13:16
2026-01-05 19:28:48,648 - CDistNet - INFO - epoch: 2  iter: 8400/13129  loss:  0.815384  lr:  0.000191  eta: 1:11:45
2026-01-05 19:30:19,501 - CDistNet - INFO - epoch: 2  iter: 8500/13129  loss:  0.793165  lr:  0.000192  eta: 1:10:13
2026-01-05 19:31:50,333 - CDistNet - INFO - epoch: 2  iter: 8600/13129  loss:  0.797439  lr:  0.000193  eta: 1:08:42
2026-01-05 19:33:20,919 - CDistNet - INFO - epoch: 2  iter: 8700/13129  loss:  0.804702  lr:  0.000193  eta: 1:07:11
2026-01-05 19:34:51,704 - CDistNet - INFO - epoch: 2  iter: 8800/13129  loss:  0.796738  lr:  0.000194  eta: 1:05:40
2026-01-05 19:36:22,318 - CDistNet - INFO - epoch: 2  iter: 8900/13129  loss:  0.793493  lr:  0.000194  eta: 1:04:09
2026-01-05 19:37:52,943 - CDistNet - INFO - epoch: 2  iter: 9000/13129  loss:  0.822595  lr:  0.000195  eta: 1:02:37
2026-01-05 19:39:23,724 - CDistNet - INFO - epoch: 2  iter: 9100/13129  loss:  0.815300  lr:  0.000195  eta: 1:01:06
2026-01-05 19:40:54,659 - CDistNet - INFO - epoch: 2  iter: 9200/13129  loss:  0.812993  lr:  0.000196  eta: 0:59:35
2026-01-05 19:42:25,335 - CDistNet - INFO - epoch: 2  iter: 9300/13129  loss:  0.796603  lr:  0.000196  eta: 0:58:04
2026-01-05 19:43:56,659 - CDistNet - INFO - epoch: 2  iter: 9400/13129  loss:  0.794008  lr:  0.000197  eta: 0:56:33
2026-01-05 19:45:27,560 - CDistNet - INFO - epoch: 2  iter: 9500/13129  loss:  0.779004  lr:  0.000198  eta: 0:55:02
2026-01-05 19:46:58,454 - CDistNet - INFO - epoch: 2  iter: 9600/13129  loss:  0.809699  lr:  0.000198  eta: 0:53:31
2026-01-05 19:48:29,080 - CDistNet - INFO - epoch: 2  iter: 9700/13129  loss:  0.799586  lr:  0.000199  eta: 0:52:00
2026-01-05 19:49:59,984 - CDistNet - INFO - epoch: 2  iter: 9800/13129  loss:  0.816209  lr:  0.000199  eta: 0:50:29
2026-01-05 19:51:30,961 - CDistNet - INFO - epoch: 2  iter: 9900/13129  loss:  0.784817  lr:  0.000200  eta: 0:48:58
2026-01-05 19:53:01,747 - CDistNet - INFO - epoch: 2  iter: 10000/13129  loss:  0.779644  lr:  0.000200  eta: 0:47:27
2026-01-05 19:54:32,622 - CDistNet - INFO - epoch: 2  iter: 10100/13129  loss:  0.777977  lr:  0.000201  eta: 0:45:56
2026-01-05 19:56:03,439 - CDistNet - INFO - epoch: 2  iter: 10200/13129  loss:  0.785458  lr:  0.000201  eta: 0:44:25
2026-01-05 19:57:34,588 - CDistNet - INFO - epoch: 2  iter: 10300/13129  loss:  0.791537  lr:  0.000202  eta: 0:42:54
2026-01-05 19:59:05,556 - CDistNet - INFO - epoch: 2  iter: 10400/13129  loss:  0.788296  lr:  0.000203  eta: 0:41:23
2026-01-05 20:00:36,408 - CDistNet - INFO - epoch: 2  iter: 10500/13129  loss:  0.794137  lr:  0.000203  eta: 0:39:52
2026-01-05 20:02:07,179 - CDistNet - INFO - epoch: 2  iter: 10600/13129  loss:  0.787123  lr:  0.000204  eta: 0:38:21
2026-01-05 20:03:38,177 - CDistNet - INFO - epoch: 2  iter: 10700/13129  loss:  0.796950  lr:  0.000204  eta: 0:36:50
2026-01-05 20:05:08,906 - CDistNet - INFO - epoch: 2  iter: 10800/13129  loss:  0.782103  lr:  0.000205  eta: 0:35:19
2026-01-05 20:06:39,944 - CDistNet - INFO - epoch: 2  iter: 10900/13129  loss:  0.799394  lr:  0.000205  eta: 0:33:48
2026-01-05 20:08:10,825 - CDistNet - INFO - epoch: 2  iter: 11000/13129  loss:  0.795592  lr:  0.000206  eta: 0:32:17
2026-01-05 20:09:41,752 - CDistNet - INFO - epoch: 2  iter: 11100/13129  loss:  0.783056  lr:  0.000206  eta: 0:30:46
2026-01-05 20:11:12,431 - CDistNet - INFO - epoch: 2  iter: 11200/13129  loss:  0.792866  lr:  0.000207  eta: 0:29:15
2026-01-05 20:12:43,510 - CDistNet - INFO - epoch: 2  iter: 11300/13129  loss:  0.814642  lr:  0.000207  eta: 0:27:44
2026-01-05 20:14:14,151 - CDistNet - INFO - epoch: 2  iter: 11400/13129  loss:  0.798575  lr:  0.000208  eta: 0:26:13
2026-01-05 20:15:45,079 - CDistNet - INFO - epoch: 2  iter: 11500/13129  loss:  0.809539  lr:  0.000209  eta: 0:24:42
2026-01-05 20:17:15,742 - CDistNet - INFO - epoch: 2  iter: 11600/13129  loss:  0.806217  lr:  0.000209  eta: 0:23:11
2026-01-05 20:18:46,516 - CDistNet - INFO - epoch: 2  iter: 11700/13129  loss:  0.801575  lr:  0.000210  eta: 0:21:40
2026-01-05 20:20:17,118 - CDistNet - INFO - epoch: 2  iter: 11800/13129  loss:  0.787411  lr:  0.000210  eta: 0:20:09
2026-01-05 20:21:48,062 - CDistNet - INFO - epoch: 2  iter: 11900/13129  loss:  0.786899  lr:  0.000211  eta: 0:18:38
2026-01-05 20:23:19,019 - CDistNet - INFO - epoch: 2  iter: 12000/13129  loss:  0.793939  lr:  0.000211  eta: 0:17:07
2026-01-05 20:23:19,175 - CDistNet - INFO - eval_loss:1.3764,eval_acc:0.8467--------

2026-01-05 20:24:49,789 - CDistNet - INFO - epoch: 2  iter: 12100/13129  loss:  0.789039  lr:  0.000212  eta: 0:15:36
2026-01-05 20:26:20,640 - CDistNet - INFO - epoch: 2  iter: 12200/13129  loss:  0.811521  lr:  0.000212  eta: 0:14:05
2026-01-05 20:27:51,549 - CDistNet - INFO - epoch: 2  iter: 12300/13129  loss:  0.791165  lr:  0.000213  eta: 0:12:34
2026-01-05 20:29:22,278 - CDistNet - INFO - epoch: 2  iter: 12400/13129  loss:  0.776471  lr:  0.000214  eta: 0:11:03
2026-01-05 20:30:53,240 - CDistNet - INFO - epoch: 2  iter: 12500/13129  loss:  0.800118  lr:  0.000214  eta: 0:09:32
2026-01-05 20:32:23,920 - CDistNet - INFO - epoch: 2  iter: 12600/13129  loss:  0.800999  lr:  0.000215  eta: 0:08:01
2026-01-05 20:33:54,645 - CDistNet - INFO - epoch: 2  iter: 12700/13129  loss:  0.784215  lr:  0.000215  eta: 0:06:30
2026-01-05 20:35:25,688 - CDistNet - INFO - epoch: 2  iter: 12800/13129  loss:  0.789894  lr:  0.000216  eta: 0:04:59
2026-01-05 20:36:56,499 - CDistNet - INFO - epoch: 2  iter: 12900/13129  loss:  0.789628  lr:  0.000216  eta: 0:03:28
2026-01-05 20:38:27,386 - CDistNet - INFO - epoch: 2  iter: 13000/13129  loss:  0.797256  lr:  0.000217  eta: 0:01:57
2026-01-05 20:39:57,968 - CDistNet - INFO - epoch: 2  iter: 13100/13129  loss:  0.794367  lr:  0.000217  eta: 0:00:26
2026-01-05 20:40:23,199 - CDistNet - INFO - Now: best_acc in epoch:2,iteration:0
2026-01-05 20:40:23,199 - CDistNet - INFO -   - (Training)   loss:  0.79898, accuracy: 99.064 %, time: 199.041 min
2026-01-05 20:40:24,173 - CDistNet - INFO - epoch: 3  iter: 0/13129  loss:  0.789491  lr:  0.000218  eta: 3:32:46
2026-01-05 20:40:24,328 - CDistNet - INFO - eval_loss:1.3450,eval_acc:0.8511--------

2026-01-05 20:40:24,328 - CDistNet - INFO - Saving model: best_acc in epoch:3,iteration:0
2026-01-05 20:40:24,568 - CDistNet - INFO - Saved!
2026-01-05 20:41:55,237 - CDistNet - INFO - epoch: 3  iter: 100/13129  loss:  0.782769  lr:  0.000218  eta: 3:17:52
2026-01-05 20:43:25,878 - CDistNet - INFO - epoch: 3  iter: 200/13129  loss:  0.791123  lr:  0.000219  eta: 3:15:50
2026-01-05 20:44:56,770 - CDistNet - INFO - epoch: 3  iter: 300/13129  loss:  0.781735  lr:  0.000219  eta: 3:14:19
2026-01-05 20:46:27,507 - CDistNet - INFO - epoch: 3  iter: 400/13129  loss:  0.801990  lr:  0.000220  eta: 3:12:44
2026-01-05 20:47:58,343 - CDistNet - INFO - epoch: 3  iter: 500/13129  loss:  0.787720  lr:  0.000220  eta: 3:11:13
2026-01-05 20:49:29,263 - CDistNet - INFO - epoch: 3  iter: 600/13129  loss:  0.781880  lr:  0.000221  eta: 3:09:43
2026-01-05 20:51:00,128 - CDistNet - INFO - epoch: 3  iter: 700/13129  loss:  0.787941  lr:  0.000221  eta: 3:08:12
2026-01-05 20:52:30,871 - CDistNet - INFO - epoch: 3  iter: 800/13129  loss:  0.801992  lr:  0.000220  eta: 3:06:40
2026-01-05 20:54:01,858 - CDistNet - INFO - epoch: 3  iter: 900/13129  loss:  0.816937  lr:  0.000220  eta: 3:05:11
2026-01-05 20:55:32,686 - CDistNet - INFO - epoch: 3  iter: 1000/13129  loss:  0.791305  lr:  0.000220  eta: 3:03:40
2026-01-05 20:57:03,573 - CDistNet - INFO - epoch: 3  iter: 1100/13129  loss:  0.829963  lr:  0.000220  eta: 3:02:09
2026-01-05 20:58:34,425 - CDistNet - INFO - epoch: 3  iter: 1200/13129  loss:  0.791034  lr:  0.000219  eta: 3:00:38
2026-01-05 21:00:05,252 - CDistNet - INFO - epoch: 3  iter: 1300/13129  loss:  0.785256  lr:  0.000219  eta: 2:59:07
2026-01-05 21:01:35,937 - CDistNet - INFO - epoch: 3  iter: 1400/13129  loss:  0.803561  lr:  0.000219  eta: 2:57:35
2026-01-05 21:03:06,696 - CDistNet - INFO - epoch: 3  iter: 1500/13129  loss:  0.808839  lr:  0.000219  eta: 2:56:03
2026-01-05 21:04:37,735 - CDistNet - INFO - epoch: 3  iter: 1600/13129  loss:  0.827354  lr:  0.000218  eta: 2:54:34
2026-01-05 21:06:08,554 - CDistNet - INFO - epoch: 3  iter: 1700/13129  loss:  0.788928  lr:  0.000218  eta: 2:53:03
2026-01-05 21:07:39,259 - CDistNet - INFO - epoch: 3  iter: 1800/13129  loss:  0.777332  lr:  0.000218  eta: 2:51:31
2026-01-05 21:09:10,173 - CDistNet - INFO - epoch: 3  iter: 1900/13129  loss:  0.793538  lr:  0.000217  eta: 2:50:01
2026-01-05 21:10:40,971 - CDistNet - INFO - epoch: 3  iter: 2000/13129  loss:  0.791411  lr:  0.000217  eta: 2:48:29
2026-01-05 21:12:11,813 - CDistNet - INFO - epoch: 3  iter: 2100/13129  loss:  0.790956  lr:  0.000217  eta: 2:46:59
2026-01-05 21:13:42,664 - CDistNet - INFO - epoch: 3  iter: 2200/13129  loss:  0.789577  lr:  0.000217  eta: 2:45:28
2026-01-05 21:15:13,402 - CDistNet - INFO - epoch: 3  iter: 2300/13129  loss:  0.790936  lr:  0.000216  eta: 2:43:56
2026-01-05 21:16:44,180 - CDistNet - INFO - epoch: 3  iter: 2400/13129  loss:  0.802450  lr:  0.000216  eta: 2:42:25
2026-01-05 21:18:15,066 - CDistNet - INFO - epoch: 3  iter: 2500/13129  loss:  0.857701  lr:  0.000216  eta: 2:40:55
2026-01-05 21:19:45,800 - CDistNet - INFO - epoch: 3  iter: 2600/13129  loss:  0.799711  lr:  0.000216  eta: 2:39:23
2026-01-05 21:21:16,491 - CDistNet - INFO - epoch: 3  iter: 2700/13129  loss:  0.819802  lr:  0.000215  eta: 2:37:52
2026-01-05 21:22:47,009 - CDistNet - INFO - epoch: 3  iter: 2800/13129  loss:  0.798228  lr:  0.000215  eta: 2:36:20
2026-01-05 21:24:17,595 - CDistNet - INFO - epoch: 3  iter: 2900/13129  loss:  0.801929  lr:  0.000215  eta: 2:34:48
2026-01-05 21:25:48,399 - CDistNet - INFO - epoch: 3  iter: 3000/13129  loss:  0.797282  lr:  0.000215  eta: 2:33:18
2026-01-05 21:27:19,322 - CDistNet - INFO - epoch: 3  iter: 3100/13129  loss:  0.793935  lr:  0.000214  eta: 2:31:47
2026-01-05 21:28:50,021 - CDistNet - INFO - epoch: 3  iter: 3200/13129  loss:  0.807585  lr:  0.000214  eta: 2:30:16
2026-01-05 21:30:20,801 - CDistNet - INFO - epoch: 3  iter: 3300/13129  loss:  0.799842  lr:  0.000214  eta: 2:28:45
2026-01-05 21:31:51,451 - CDistNet - INFO - epoch: 3  iter: 3400/13129  loss:  0.789862  lr:  0.000214  eta: 2:27:14
2026-01-05 21:33:22,100 - CDistNet - INFO - epoch: 3  iter: 3500/13129  loss:  0.803011  lr:  0.000213  eta: 2:25:43
2026-01-05 21:34:52,752 - CDistNet - INFO - epoch: 3  iter: 3600/13129  loss:  0.802657  lr:  0.000213  eta: 2:24:11
2026-01-05 21:36:23,641 - CDistNet - INFO - epoch: 3  iter: 3700/13129  loss:  0.789803  lr:  0.000213  eta: 2:22:41
2026-01-05 21:37:54,450 - CDistNet - INFO - epoch: 3  iter: 3800/13129  loss:  0.785507  lr:  0.000213  eta: 2:21:10
2026-01-05 21:39:25,160 - CDistNet - INFO - epoch: 3  iter: 3900/13129  loss:  0.808672  lr:  0.000212  eta: 2:19:39
2026-01-05 21:40:55,693 - CDistNet - INFO - epoch: 3  iter: 4000/13129  loss:  0.802773  lr:  0.000212  eta: 2:18:08
2026-01-05 21:40:55,850 - CDistNet - INFO - eval_loss:1.5061,eval_acc:0.8511--------

2026-01-05 21:42:26,368 - CDistNet - INFO - epoch: 3  iter: 4100/13129  loss:  0.820906  lr:  0.000212  eta: 2:16:37
2026-01-05 21:43:57,216 - CDistNet - INFO - epoch: 3  iter: 4200/13129  loss:  0.793313  lr:  0.000212  eta: 2:15:06
2026-01-05 21:45:27,937 - CDistNet - INFO - epoch: 3  iter: 4300/13129  loss:  0.801931  lr:  0.000211  eta: 2:13:35
2026-01-05 21:46:58,805 - CDistNet - INFO - epoch: 3  iter: 4400/13129  loss:  0.792355  lr:  0.000211  eta: 2:12:04
2026-01-05 21:48:29,578 - CDistNet - INFO - epoch: 3  iter: 4500/13129  loss:  0.791405  lr:  0.000211  eta: 2:10:34
2026-01-05 21:50:00,334 - CDistNet - INFO - epoch: 3  iter: 4600/13129  loss:  0.793247  lr:  0.000211  eta: 2:09:03
2026-01-05 21:51:31,249 - CDistNet - INFO - epoch: 3  iter: 4700/13129  loss:  0.808812  lr:  0.000210  eta: 2:07:32
2026-01-05 21:53:02,074 - CDistNet - INFO - epoch: 3  iter: 4800/13129  loss:  0.790452  lr:  0.000210  eta: 2:06:01
2026-01-05 21:54:32,685 - CDistNet - INFO - epoch: 3  iter: 4900/13129  loss:  0.795451  lr:  0.000210  eta: 2:04:30
2026-01-05 21:56:03,442 - CDistNet - INFO - epoch: 3  iter: 5000/13129  loss:  0.796760  lr:  0.000210  eta: 2:03:00
2026-01-05 21:57:34,078 - CDistNet - INFO - epoch: 3  iter: 5100/13129  loss:  0.785814  lr:  0.000210  eta: 2:01:29
2026-01-05 21:59:04,955 - CDistNet - INFO - epoch: 3  iter: 5200/13129  loss:  0.793565  lr:  0.000209  eta: 1:59:58
2026-01-05 22:00:35,783 - CDistNet - INFO - epoch: 3  iter: 5300/13129  loss:  0.795604  lr:  0.000209  eta: 1:58:27
2026-01-05 22:02:06,920 - CDistNet - INFO - epoch: 3  iter: 5400/13129  loss:  0.786591  lr:  0.000209  eta: 1:56:57
2026-01-05 22:03:37,601 - CDistNet - INFO - epoch: 3  iter: 5500/13129  loss:  0.792459  lr:  0.000209  eta: 1:55:26
2026-01-05 22:05:08,401 - CDistNet - INFO - epoch: 3  iter: 5600/13129  loss:  0.791934  lr:  0.000208  eta: 1:53:55
2026-01-05 22:06:39,489 - CDistNet - INFO - epoch: 3  iter: 5700/13129  loss:  0.796191  lr:  0.000208  eta: 1:52:25
2026-01-05 22:08:10,159 - CDistNet - INFO - epoch: 3  iter: 5800/13129  loss:  0.797470  lr:  0.000208  eta: 1:50:54
2026-01-05 22:09:40,763 - CDistNet - INFO - epoch: 3  iter: 5900/13129  loss:  0.788286  lr:  0.000208  eta: 1:49:23
2026-01-05 22:11:11,607 - CDistNet - INFO - epoch: 3  iter: 6000/13129  loss:  0.784821  lr:  0.000207  eta: 1:47:52
2026-01-05 22:12:42,403 - CDistNet - INFO - epoch: 3  iter: 6100/13129  loss:  0.797177  lr:  0.000207  eta: 1:46:21
2026-01-05 22:14:13,063 - CDistNet - INFO - epoch: 3  iter: 6200/13129  loss:  0.789274  lr:  0.000207  eta: 1:44:50
2026-01-05 22:15:43,635 - CDistNet - INFO - epoch: 3  iter: 6300/13129  loss:  0.792085  lr:  0.000207  eta: 1:43:19
2026-01-05 22:17:14,345 - CDistNet - INFO - epoch: 3  iter: 6400/13129  loss:  0.815431  lr:  0.000207  eta: 1:41:48
2026-01-05 22:18:45,162 - CDistNet - INFO - epoch: 3  iter: 6500/13129  loss:  0.791217  lr:  0.000206  eta: 1:40:18
2026-01-05 22:20:15,982 - CDistNet - INFO - epoch: 3  iter: 6600/13129  loss:  0.797920  lr:  0.000206  eta: 1:38:47
2026-01-05 22:21:46,675 - CDistNet - INFO - epoch: 3  iter: 6700/13129  loss:  0.789651  lr:  0.000206  eta: 1:37:16
2026-01-05 22:23:17,613 - CDistNet - INFO - epoch: 3  iter: 6800/13129  loss:  0.791727  lr:  0.000206  eta: 1:35:45
2026-01-05 22:24:48,199 - CDistNet - INFO - epoch: 3  iter: 6900/13129  loss:  0.789108  lr:  0.000205  eta: 1:34:14
2026-01-05 22:26:19,001 - CDistNet - INFO - epoch: 3  iter: 7000/13129  loss:  0.790568  lr:  0.000205  eta: 1:32:44
2026-01-05 22:27:49,800 - CDistNet - INFO - epoch: 3  iter: 7100/13129  loss:  0.789982  lr:  0.000205  eta: 1:31:13
2026-01-05 22:29:20,869 - CDistNet - INFO - epoch: 3  iter: 7200/13129  loss:  0.803017  lr:  0.000205  eta: 1:29:42
2026-01-05 22:30:51,513 - CDistNet - INFO - epoch: 3  iter: 7300/13129  loss:  0.787659  lr:  0.000205  eta: 1:28:11
2026-01-05 22:32:22,336 - CDistNet - INFO - epoch: 3  iter: 7400/13129  loss:  0.803873  lr:  0.000204  eta: 1:26:41
2026-01-05 22:33:53,088 - CDistNet - INFO - epoch: 3  iter: 7500/13129  loss:  0.802268  lr:  0.000204  eta: 1:25:10
2026-01-05 22:35:23,887 - CDistNet - INFO - epoch: 3  iter: 7600/13129  loss:  0.794698  lr:  0.000204  eta: 1:23:39
2026-01-05 22:36:54,750 - CDistNet - INFO - epoch: 3  iter: 7700/13129  loss:  0.795272  lr:  0.000204  eta: 1:22:08
2026-01-05 22:38:25,665 - CDistNet - INFO - epoch: 3  iter: 7800/13129  loss:  0.792146  lr:  0.000203  eta: 1:20:38
2026-01-05 22:39:56,607 - CDistNet - INFO - epoch: 3  iter: 7900/13129  loss:  0.789667  lr:  0.000203  eta: 1:19:07
2026-01-05 22:41:27,492 - CDistNet - INFO - epoch: 3  iter: 8000/13129  loss:  0.809285  lr:  0.000203  eta: 1:17:36
2026-01-05 22:41:27,647 - CDistNet - INFO - eval_loss:1.3999,eval_acc:0.8511--------

2026-01-05 22:42:58,643 - CDistNet - INFO - epoch: 3  iter: 8100/13129  loss:  0.816836  lr:  0.000203  eta: 1:16:06
2026-01-05 22:44:29,456 - CDistNet - INFO - epoch: 3  iter: 8200/13129  loss:  0.777992  lr:  0.000203  eta: 1:14:35
2026-01-05 22:46:00,200 - CDistNet - INFO - epoch: 3  iter: 8300/13129  loss:  0.814205  lr:  0.000202  eta: 1:13:04
2026-01-05 22:47:30,895 - CDistNet - INFO - epoch: 3  iter: 8400/13129  loss:  0.792995  lr:  0.000202  eta: 1:11:33
2026-01-05 22:49:01,842 - CDistNet - INFO - epoch: 3  iter: 8500/13129  loss:  0.786735  lr:  0.000202  eta: 1:10:02
2026-01-05 22:50:32,513 - CDistNet - INFO - epoch: 3  iter: 8600/13129  loss:  0.801112  lr:  0.000202  eta: 1:08:32
2026-01-05 22:52:03,478 - CDistNet - INFO - epoch: 3  iter: 8700/13129  loss:  0.797520  lr:  0.000202  eta: 1:07:01
2026-01-05 22:53:34,625 - CDistNet - INFO - epoch: 3  iter: 8800/13129  loss:  0.779992  lr:  0.000201  eta: 1:05:30
2026-01-05 22:55:05,635 - CDistNet - INFO - epoch: 3  iter: 8900/13129  loss:  0.794428  lr:  0.000201  eta: 1:04:00
2026-01-05 22:56:36,521 - CDistNet - INFO - epoch: 3  iter: 9000/13129  loss:  0.792348  lr:  0.000201  eta: 1:02:29
2026-01-05 22:58:07,356 - CDistNet - INFO - epoch: 3  iter: 9100/13129  loss:  0.801057  lr:  0.000201  eta: 1:00:58
2026-01-05 22:59:38,042 - CDistNet - INFO - epoch: 3  iter: 9200/13129  loss:  0.788479  lr:  0.000200  eta: 0:59:27
2026-01-05 23:01:08,878 - CDistNet - INFO - epoch: 3  iter: 9300/13129  loss:  0.789804  lr:  0.000200  eta: 0:57:56
2026-01-05 23:02:39,836 - CDistNet - INFO - epoch: 3  iter: 9400/13129  loss:  0.790421  lr:  0.000200  eta: 0:56:26
2026-01-05 23:04:10,713 - CDistNet - INFO - epoch: 3  iter: 9500/13129  loss:  0.798933  lr:  0.000200  eta: 0:54:55
2026-01-05 23:05:41,413 - CDistNet - INFO - epoch: 3  iter: 9600/13129  loss:  0.793032  lr:  0.000200  eta: 0:53:24
2026-01-05 23:07:12,433 - CDistNet - INFO - epoch: 3  iter: 9700/13129  loss:  0.795018  lr:  0.000199  eta: 0:51:53
2026-01-05 23:08:43,252 - CDistNet - INFO - epoch: 3  iter: 9800/13129  loss:  0.786918  lr:  0.000199  eta: 0:50:22
2026-01-05 23:10:14,181 - CDistNet - INFO - epoch: 3  iter: 9900/13129  loss:  0.783376  lr:  0.000199  eta: 0:48:52
2026-01-05 23:11:45,098 - CDistNet - INFO - epoch: 3  iter: 10000/13129  loss:  0.773758  lr:  0.000199  eta: 0:47:21
2026-01-05 23:13:15,765 - CDistNet - INFO - epoch: 3  iter: 10100/13129  loss:  0.829083  lr:  0.000199  eta: 0:45:50
2026-01-05 23:14:46,438 - CDistNet - INFO - epoch: 3  iter: 10200/13129  loss:  0.772056  lr:  0.000198  eta: 0:44:19
2026-01-05 23:16:17,387 - CDistNet - INFO - epoch: 3  iter: 10300/13129  loss:  0.785588  lr:  0.000198  eta: 0:42:48
2026-01-05 23:17:48,349 - CDistNet - INFO - epoch: 3  iter: 10400/13129  loss:  0.800807  lr:  0.000198  eta: 0:41:18
2026-01-05 23:19:19,137 - CDistNet - INFO - epoch: 3  iter: 10500/13129  loss:  0.787554  lr:  0.000198  eta: 0:39:47
2026-01-05 23:20:49,865 - CDistNet - INFO - epoch: 3  iter: 10600/13129  loss:  0.796801  lr:  0.000198  eta: 0:38:16
2026-01-05 23:22:20,589 - CDistNet - INFO - epoch: 3  iter: 10700/13129  loss:  0.783219  lr:  0.000197  eta: 0:36:45
2026-01-05 23:23:52,632 - CDistNet - INFO - epoch: 3  iter: 10800/13129  loss:  0.787128  lr:  0.000197  eta: 0:35:15
2026-01-05 23:25:24,520 - CDistNet - INFO - epoch: 3  iter: 10900/13129  loss:  0.786382  lr:  0.000197  eta: 0:33:44
2026-01-05 23:26:57,205 - CDistNet - INFO - epoch: 3  iter: 11000/13129  loss:  0.806504  lr:  0.000197  eta: 0:32:14
2026-01-05 23:28:28,832 - CDistNet - INFO - epoch: 3  iter: 11100/13129  loss:  0.796325  lr:  0.000197  eta: 0:30:43
2026-01-05 23:30:00,466 - CDistNet - INFO - epoch: 3  iter: 11200/13129  loss:  0.804663  lr:  0.000196  eta: 0:29:12
2026-01-05 23:31:31,980 - CDistNet - INFO - epoch: 3  iter: 11300/13129  loss:  0.795602  lr:  0.000196  eta: 0:27:41
2026-01-05 23:33:03,565 - CDistNet - INFO - epoch: 3  iter: 11400/13129  loss:  0.786391  lr:  0.000196  eta: 0:26:11
2026-01-05 23:34:34,677 - CDistNet - INFO - epoch: 3  iter: 11500/13129  loss:  0.800192  lr:  0.000196  eta: 0:24:40
2026-01-05 23:36:05,731 - CDistNet - INFO - epoch: 3  iter: 11600/13129  loss:  0.784740  lr:  0.000196  eta: 0:23:09
2026-01-05 23:37:36,947 - CDistNet - INFO - epoch: 3  iter: 11700/13129  loss:  0.796868  lr:  0.000196  eta: 0:21:38
2026-01-05 23:39:08,046 - CDistNet - INFO - epoch: 3  iter: 11800/13129  loss:  0.780646  lr:  0.000195  eta: 0:20:07
2026-01-05 23:40:39,494 - CDistNet - INFO - epoch: 3  iter: 11900/13129  loss:  0.797831  lr:  0.000195  eta: 0:18:36
2026-01-05 23:42:10,725 - CDistNet - INFO - epoch: 3  iter: 12000/13129  loss:  0.790829  lr:  0.000195  eta: 0:17:06
2026-01-05 23:42:10,883 - CDistNet - INFO - eval_loss:1.3372,eval_acc:0.8467--------

2026-01-05 23:43:41,937 - CDistNet - INFO - epoch: 3  iter: 12100/13129  loss:  0.807681  lr:  0.000195  eta: 0:15:35
2026-01-05 23:45:13,246 - CDistNet - INFO - epoch: 3  iter: 12200/13129  loss:  0.781231  lr:  0.000195  eta: 0:14:04
2026-01-05 23:46:44,463 - CDistNet - INFO - epoch: 3  iter: 12300/13129  loss:  0.799508  lr:  0.000194  eta: 0:12:33
2026-01-05 23:48:15,905 - CDistNet - INFO - epoch: 3  iter: 12400/13129  loss:  0.805310  lr:  0.000194  eta: 0:11:02
2026-01-05 23:49:46,930 - CDistNet - INFO - epoch: 3  iter: 12500/13129  loss:  0.798734  lr:  0.000194  eta: 0:09:31
2026-01-05 23:51:17,780 - CDistNet - INFO - epoch: 3  iter: 12600/13129  loss:  0.793609  lr:  0.000194  eta: 0:08:00
2026-01-05 23:52:48,779 - CDistNet - INFO - epoch: 3  iter: 12700/13129  loss:  0.807167  lr:  0.000194  eta: 0:06:29
2026-01-05 23:54:19,722 - CDistNet - INFO - epoch: 3  iter: 12800/13129  loss:  0.797207  lr:  0.000193  eta: 0:04:59
2026-01-05 23:55:50,720 - CDistNet - INFO - epoch: 3  iter: 12900/13129  loss:  0.802129  lr:  0.000193  eta: 0:03:28
2026-01-05 23:57:22,014 - CDistNet - INFO - epoch: 3  iter: 13000/13129  loss:  0.790722  lr:  0.000193  eta: 0:01:57
2026-01-05 23:58:52,981 - CDistNet - INFO - epoch: 3  iter: 13100/13129  loss:  0.798321  lr:  0.000193  eta: 0:00:26
2026-01-05 23:59:18,422 - CDistNet - INFO - Now: best_acc in epoch:3,iteration:0
2026-01-05 23:59:18,423 - CDistNet - INFO -   - (Training)   loss:  0.79635, accuracy: 99.133 %, time: 198.920 min
2026-01-05 23:59:19,399 - CDistNet - INFO - epoch: 4  iter: 0/13129  loss:  0.781535  lr:  0.000193  eta: 3:33:16
2026-01-05 23:59:19,553 - CDistNet - INFO - eval_loss:1.3360,eval_acc:0.8556--------

2026-01-05 23:59:19,554 - CDistNet - INFO - Saving model: best_acc in epoch:4,iteration:0
2026-01-05 23:59:19,789 - CDistNet - INFO - Saved!
2026-01-06 00:00:50,731 - CDistNet - INFO - epoch: 4  iter: 100/13129  loss:  0.847571  lr:  0.000193  eta: 3:18:27
2026-01-06 00:02:21,669 - CDistNet - INFO - epoch: 4  iter: 200/13129  loss:  0.795088  lr:  0.000192  eta: 3:16:26
2026-01-06 00:03:52,633 - CDistNet - INFO - epoch: 4  iter: 300/13129  loss:  0.801467  lr:  0.000192  eta: 3:14:47
2026-01-06 00:05:23,699 - CDistNet - INFO - epoch: 4  iter: 400/13129  loss:  0.801386  lr:  0.000192  eta: 3:13:14
2026-01-06 00:06:54,782 - CDistNet - INFO - epoch: 4  iter: 500/13129  loss:  0.815222  lr:  0.000192  eta: 3:11:43
2026-01-06 00:08:25,767 - CDistNet - INFO - epoch: 4  iter: 600/13129  loss:  0.788667  lr:  0.000192  eta: 3:10:10
2026-01-06 00:09:56,844 - CDistNet - INFO - epoch: 4  iter: 700/13129  loss:  0.804024  lr:  0.000192  eta: 3:08:39
2026-01-06 00:11:28,115 - CDistNet - INFO - epoch: 4  iter: 800/13129  loss:  0.802680  lr:  0.000191  eta: 3:07:11
2026-01-06 00:13:01,070 - CDistNet - INFO - epoch: 4  iter: 900/13129  loss:  0.780042  lr:  0.000191  eta: 3:06:05
2026-01-06 00:14:33,518 - CDistNet - INFO - epoch: 4  iter: 1000/13129  loss:  0.784280  lr:  0.000191  eta: 3:04:48
2026-01-06 00:16:05,584 - CDistNet - INFO - epoch: 4  iter: 1100/13129  loss:  0.786090  lr:  0.000191  eta: 3:03:23
2026-01-06 00:17:36,990 - CDistNet - INFO - epoch: 4  iter: 1200/13129  loss:  0.808973  lr:  0.000191  eta: 3:01:51
2026-01-06 00:19:08,257 - CDistNet - INFO - epoch: 4  iter: 1300/13129  loss:  0.790763  lr:  0.000191  eta: 3:00:18
2026-01-06 00:20:39,446 - CDistNet - INFO - epoch: 4  iter: 1400/13129  loss:  0.779128  lr:  0.000190  eta: 2:58:44
2026-01-06 00:22:11,064 - CDistNet - INFO - epoch: 4  iter: 1500/13129  loss:  0.792305  lr:  0.000190  eta: 2:57:14
2026-01-06 00:23:42,496 - CDistNet - INFO - epoch: 4  iter: 1600/13129  loss:  0.778305  lr:  0.000190  eta: 2:55:42
2026-01-06 00:25:13,666 - CDistNet - INFO - epoch: 4  iter: 1700/13129  loss:  0.777769  lr:  0.000190  eta: 2:54:09
2026-01-06 00:26:44,887 - CDistNet - INFO - epoch: 4  iter: 1800/13129  loss:  0.780089  lr:  0.000190  eta: 2:52:36
2026-01-06 00:28:16,769 - CDistNet - INFO - epoch: 4  iter: 1900/13129  loss:  0.795720  lr:  0.000189  eta: 2:51:08
2026-01-06 00:29:50,371 - CDistNet - INFO - epoch: 4  iter: 2000/13129  loss:  0.809300  lr:  0.000189  eta: 2:49:48
2026-01-06 00:31:22,000 - CDistNet - INFO - epoch: 4  iter: 2100/13129  loss:  0.785591  lr:  0.000189  eta: 2:48:17
2026-01-06 00:32:53,498 - CDistNet - INFO - epoch: 4  iter: 2200/13129  loss:  0.807992  lr:  0.000189  eta: 2:46:45
2026-01-06 00:34:25,041 - CDistNet - INFO - epoch: 4  iter: 2300/13129  loss:  0.792511  lr:  0.000189  eta: 2:45:14
2026-01-06 00:35:56,257 - CDistNet - INFO - epoch: 4  iter: 2400/13129  loss:  0.785399  lr:  0.000189  eta: 2:43:41
2026-01-06 00:37:27,758 - CDistNet - INFO - epoch: 4  iter: 2500/13129  loss:  0.794111  lr:  0.000188  eta: 2:42:09
2026-01-06 00:38:59,029 - CDistNet - INFO - epoch: 4  iter: 2600/13129  loss:  0.795698  lr:  0.000188  eta: 2:40:36
2026-01-06 00:40:30,558 - CDistNet - INFO - epoch: 4  iter: 2700/13129  loss:  0.801550  lr:  0.000188  eta: 2:39:05
2026-01-06 00:42:01,890 - CDistNet - INFO - epoch: 4  iter: 2800/13129  loss:  0.792353  lr:  0.000188  eta: 2:37:33
2026-01-06 00:43:32,969 - CDistNet - INFO - epoch: 4  iter: 2900/13129  loss:  0.790523  lr:  0.000188  eta: 2:35:59
2026-01-06 00:45:03,925 - CDistNet - INFO - epoch: 4  iter: 3000/13129  loss:  0.836587  lr:  0.000188  eta: 2:34:26
2026-01-06 00:46:35,258 - CDistNet - INFO - epoch: 4  iter: 3100/13129  loss:  0.799254  lr:  0.000187  eta: 2:32:54
2026-01-06 00:48:06,312 - CDistNet - INFO - epoch: 4  iter: 3200/13129  loss:  0.793054  lr:  0.000187  eta: 2:31:21
2026-01-06 00:49:37,481 - CDistNet - INFO - epoch: 4  iter: 3300/13129  loss:  0.818290  lr:  0.000187  eta: 2:29:49
2026-01-06 00:51:08,884 - CDistNet - INFO - epoch: 4  iter: 3400/13129  loss:  0.791358  lr:  0.000187  eta: 2:28:17
2026-01-06 00:52:39,974 - CDistNet - INFO - epoch: 4  iter: 3500/13129  loss:  0.791383  lr:  0.000187  eta: 2:26:45
2026-01-06 00:54:11,266 - CDistNet - INFO - epoch: 4  iter: 3600/13129  loss:  0.792538  lr:  0.000187  eta: 2:25:13
2026-01-06 00:55:42,361 - CDistNet - INFO - epoch: 4  iter: 3700/13129  loss:  0.781401  lr:  0.000186  eta: 2:23:41
2026-01-06 00:57:13,351 - CDistNet - INFO - epoch: 4  iter: 3800/13129  loss:  0.793190  lr:  0.000186  eta: 2:22:08
2026-01-06 00:58:46,434 - CDistNet - INFO - epoch: 4  iter: 3900/13129  loss:  0.810896  lr:  0.000186  eta: 2:20:41
2026-01-06 01:00:18,439 - CDistNet - INFO - epoch: 4  iter: 4000/13129  loss:  0.809998  lr:  0.000186  eta: 2:19:10
2026-01-06 01:00:18,629 - CDistNet - INFO - eval_loss:1.3228,eval_acc:0.8467--------

2026-01-06 01:01:50,469 - CDistNet - INFO - epoch: 4  iter: 4100/13129  loss:  0.802658  lr:  0.000186  eta: 2:17:40
2026-01-06 01:03:21,727 - CDistNet - INFO - epoch: 4  iter: 4200/13129  loss:  0.785284  lr:  0.000186  eta: 2:16:08
2026-01-06 01:04:55,083 - CDistNet - INFO - epoch: 4  iter: 4300/13129  loss:  0.790886  lr:  0.000185  eta: 2:14:41
2026-01-06 01:06:26,478 - CDistNet - INFO - epoch: 4  iter: 4400/13129  loss:  0.796901  lr:  0.000185  eta: 2:13:09
2026-01-06 01:08:08,773 - CDistNet - INFO - epoch: 4  iter: 4500/13129  loss:  0.789585  lr:  0.000185  eta: 2:11:58
2026-01-06 01:09:52,032 - CDistNet - INFO - epoch: 4  iter: 4600/13129  loss:  0.789638  lr:  0.000185  eta: 2:10:47
2026-01-06 01:11:35,735 - CDistNet - INFO - epoch: 4  iter: 4700/13129  loss:  0.797967  lr:  0.000185  eta: 2:09:36
2026-01-06 01:13:19,432 - CDistNet - INFO - epoch: 4  iter: 4800/13129  loss:  0.786739  lr:  0.000185  eta: 2:08:24
2026-01-06 01:15:03,024 - CDistNet - INFO - epoch: 4  iter: 4900/13129  loss:  0.773518  lr:  0.000184  eta: 2:07:10
2026-01-06 01:16:46,823 - CDistNet - INFO - epoch: 4  iter: 5000/13129  loss:  0.781220  lr:  0.000184  eta: 2:05:55
2026-01-06 01:18:30,133 - CDistNet - INFO - epoch: 4  iter: 5100/13129  loss:  0.787757  lr:  0.000184  eta: 2:04:39
2026-01-06 01:20:13,594 - CDistNet - INFO - epoch: 4  iter: 5200/13129  loss:  0.800969  lr:  0.000184  eta: 2:03:21
2026-01-06 01:21:56,904 - CDistNet - INFO - epoch: 4  iter: 5300/13129  loss:  0.805867  lr:  0.000184  eta: 2:02:03
2026-01-06 01:23:40,449 - CDistNet - INFO - epoch: 4  iter: 5400/13129  loss:  0.796195  lr:  0.000184  eta: 2:00:43
2026-01-06 01:25:23,925 - CDistNet - INFO - epoch: 4  iter: 5500/13129  loss:  0.786411  lr:  0.000183  eta: 1:59:23
2026-01-06 01:27:07,216 - CDistNet - INFO - epoch: 4  iter: 5600/13129  loss:  0.791225  lr:  0.000183  eta: 1:58:02
2026-01-06 01:28:50,662 - CDistNet - INFO - epoch: 4  iter: 5700/13129  loss:  0.781955  lr:  0.000183  eta: 1:56:40
2026-01-06 01:30:34,307 - CDistNet - INFO - epoch: 4  iter: 5800/13129  loss:  0.810610  lr:  0.000183  eta: 1:55:18
2026-01-06 01:32:17,763 - CDistNet - INFO - epoch: 4  iter: 5900/13129  loss:  0.785318  lr:  0.000183  eta: 1:53:54
2026-01-06 01:34:01,106 - CDistNet - INFO - epoch: 4  iter: 6000/13129  loss:  0.787092  lr:  0.000183  eta: 1:52:30
2026-01-06 01:35:44,427 - CDistNet - INFO - epoch: 4  iter: 6100/13129  loss:  0.783495  lr:  0.000183  eta: 1:51:06
2026-01-06 01:37:28,174 - CDistNet - INFO - epoch: 4  iter: 6200/13129  loss:  0.788682  lr:  0.000182  eta: 1:49:41
2026-01-06 01:39:11,760 - CDistNet - INFO - epoch: 4  iter: 6300/13129  loss:  0.799002  lr:  0.000182  eta: 1:48:15
2026-01-06 01:40:54,707 - CDistNet - INFO - epoch: 4  iter: 6400/13129  loss:  0.781841  lr:  0.000182  eta: 1:46:48
2026-01-06 01:42:37,370 - CDistNet - INFO - epoch: 4  iter: 6500/13129  loss:  0.800346  lr:  0.000182  eta: 1:45:20
2026-01-06 01:44:20,580 - CDistNet - INFO - epoch: 4  iter: 6600/13129  loss:  0.791171  lr:  0.000182  eta: 1:43:53
2026-01-06 01:46:03,531 - CDistNet - INFO - epoch: 4  iter: 6700/13129  loss:  0.793054  lr:  0.000182  eta: 1:42:25
2026-01-06 01:47:46,307 - CDistNet - INFO - epoch: 4  iter: 6800/13129  loss:  0.803638  lr:  0.000181  eta: 1:40:56
2026-01-06 01:49:29,099 - CDistNet - INFO - epoch: 4  iter: 6900/13129  loss:  0.784927  lr:  0.000181  eta: 1:39:26
2026-01-06 01:51:12,185 - CDistNet - INFO - epoch: 4  iter: 7000/13129  loss:  0.791947  lr:  0.000181  eta: 1:37:57
2026-01-06 01:52:55,464 - CDistNet - INFO - epoch: 4  iter: 7100/13129  loss:  0.778403  lr:  0.000181  eta: 1:36:27
2026-01-06 01:54:38,642 - CDistNet - INFO - epoch: 4  iter: 7200/13129  loss:  0.773823  lr:  0.000181  eta: 1:34:57
2026-01-06 01:56:21,755 - CDistNet - INFO - epoch: 4  iter: 7300/13129  loss:  0.776898  lr:  0.000181  eta: 1:33:27
2026-01-06 01:58:04,908 - CDistNet - INFO - epoch: 4  iter: 7400/13129  loss:  0.812974  lr:  0.000181  eta: 1:31:56
2026-01-06 01:59:47,802 - CDistNet - INFO - epoch: 4  iter: 7500/13129  loss:  0.783678  lr:  0.000180  eta: 1:30:25
2026-01-06 02:01:31,023 - CDistNet - INFO - epoch: 4  iter: 7600/13129  loss:  0.790373  lr:  0.000180  eta: 1:28:53
2026-01-06 02:03:13,945 - CDistNet - INFO - epoch: 4  iter: 7700/13129  loss:  0.781502  lr:  0.000180  eta: 1:27:21
2026-01-06 02:04:56,950 - CDistNet - INFO - epoch: 4  iter: 7800/13129  loss:  0.786854  lr:  0.000180  eta: 1:25:49
2026-01-06 02:06:40,068 - CDistNet - INFO - epoch: 4  iter: 7900/13129  loss:  0.784500  lr:  0.000180  eta: 1:24:17
2026-01-06 02:08:23,141 - CDistNet - INFO - epoch: 4  iter: 8000/13129  loss:  0.789103  lr:  0.000180  eta: 1:22:44
2026-01-06 02:08:23,306 - CDistNet - INFO - eval_loss:1.5491,eval_acc:0.8311--------

2026-01-06 02:10:06,340 - CDistNet - INFO - epoch: 4  iter: 8100/13129  loss:  0.795556  lr:  0.000180  eta: 1:21:11
2026-01-06 02:11:48,905 - CDistNet - INFO - epoch: 4  iter: 8200/13129  loss:  0.796709  lr:  0.000179  eta: 1:19:38
2026-01-06 02:13:31,900 - CDistNet - INFO - epoch: 4  iter: 8300/13129  loss:  0.790397  lr:  0.000179  eta: 1:18:05
2026-01-06 02:15:14,977 - CDistNet - INFO - epoch: 4  iter: 8400/13129  loss:  0.781429  lr:  0.000179  eta: 1:16:31
2026-01-06 02:16:57,932 - CDistNet - INFO - epoch: 4  iter: 8500/13129  loss:  0.815732  lr:  0.000179  eta: 1:14:57
2026-01-06 02:18:40,744 - CDistNet - INFO - epoch: 4  iter: 8600/13129  loss:  0.782080  lr:  0.000179  eta: 1:13:23
2026-01-06 02:20:23,820 - CDistNet - INFO - epoch: 4  iter: 8700/13129  loss:  0.804500  lr:  0.000179  eta: 1:11:49
2026-01-06 02:22:06,917 - CDistNet - INFO - epoch: 4  iter: 8800/13129  loss:  0.779816  lr:  0.000178  eta: 1:10:14
2026-01-06 02:23:49,899 - CDistNet - INFO - epoch: 4  iter: 8900/13129  loss:  0.778694  lr:  0.000178  eta: 1:08:39
2026-01-06 02:25:32,398 - CDistNet - INFO - epoch: 4  iter: 9000/13129  loss:  0.806498  lr:  0.000178  eta: 1:07:04
2026-01-06 02:27:15,604 - CDistNet - INFO - epoch: 4  iter: 9100/13129  loss:  0.845206  lr:  0.000178  eta: 1:05:29
2026-01-06 02:28:58,213 - CDistNet - INFO - epoch: 4  iter: 9200/13129  loss:  0.800441  lr:  0.000178  eta: 1:03:54
2026-01-06 02:30:40,941 - CDistNet - INFO - epoch: 4  iter: 9300/13129  loss:  0.795860  lr:  0.000178  eta: 1:02:19
2026-01-06 02:32:23,848 - CDistNet - INFO - epoch: 4  iter: 9400/13129  loss:  0.789879  lr:  0.000178  eta: 1:00:43
2026-01-06 02:34:06,622 - CDistNet - INFO - epoch: 4  iter: 9500/13129  loss:  0.795471  lr:  0.000177  eta: 0:59:07
2026-01-06 02:35:49,434 - CDistNet - INFO - epoch: 4  iter: 9600/13129  loss:  0.791853  lr:  0.000177  eta: 0:57:31
2026-01-06 02:37:32,376 - CDistNet - INFO - epoch: 4  iter: 9700/13129  loss:  0.783747  lr:  0.000177  eta: 0:55:55
2026-01-06 02:39:15,583 - CDistNet - INFO - epoch: 4  iter: 9800/13129  loss:  0.793300  lr:  0.000177  eta: 0:54:19
2026-01-06 02:40:58,314 - CDistNet - INFO - epoch: 4  iter: 9900/13129  loss:  0.804554  lr:  0.000177  eta: 0:52:43
2026-01-06 02:42:41,012 - CDistNet - INFO - epoch: 4  iter: 10000/13129  loss:  0.803575  lr:  0.000177  eta: 0:51:06
2026-01-06 02:44:24,281 - CDistNet - INFO - epoch: 4  iter: 10100/13129  loss:  0.801083  lr:  0.000177  eta: 0:49:30
2026-01-06 02:46:07,384 - CDistNet - INFO - epoch: 4  iter: 10200/13129  loss:  0.795331  lr:  0.000176  eta: 0:47:53
2026-01-06 02:47:50,132 - CDistNet - INFO - epoch: 4  iter: 10300/13129  loss:  0.792580  lr:  0.000176  eta: 0:46:17
2026-01-06 02:49:33,117 - CDistNet - INFO - epoch: 4  iter: 10400/13129  loss:  0.796036  lr:  0.000176  eta: 0:44:40
2026-01-06 02:51:15,797 - CDistNet - INFO - epoch: 4  iter: 10500/13129  loss:  0.784543  lr:  0.000176  eta: 0:43:03
2026-01-06 02:52:58,771 - CDistNet - INFO - epoch: 4  iter: 10600/13129  loss:  0.792329  lr:  0.000176  eta: 0:41:25
2026-01-06 02:54:41,648 - CDistNet - INFO - epoch: 4  iter: 10700/13129  loss:  0.792855  lr:  0.000176  eta: 0:39:48
2026-01-06 02:56:24,539 - CDistNet - INFO - epoch: 4  iter: 10800/13129  loss:  0.787614  lr:  0.000176  eta: 0:38:11
2026-01-06 02:58:07,324 - CDistNet - INFO - epoch: 4  iter: 10900/13129  loss:  0.791949  lr:  0.000175  eta: 0:36:33
2026-01-06 02:59:49,965 - CDistNet - INFO - epoch: 4  iter: 11000/13129  loss:  0.796990  lr:  0.000175  eta: 0:34:56
2026-01-06 03:01:32,810 - CDistNet - INFO - epoch: 4  iter: 11100/13129  loss:  0.800434  lr:  0.000175  eta: 0:33:18
2026-01-06 03:03:15,660 - CDistNet - INFO - epoch: 4  iter: 11200/13129  loss:  0.808070  lr:  0.000175  eta: 0:31:40
2026-01-06 03:04:58,802 - CDistNet - INFO - epoch: 4  iter: 11300/13129  loss:  0.799680  lr:  0.000175  eta: 0:30:03
2026-01-06 03:06:41,557 - CDistNet - INFO - epoch: 4  iter: 11400/13129  loss:  0.795575  lr:  0.000175  eta: 0:28:25
2026-01-06 03:08:24,869 - CDistNet - INFO - epoch: 4  iter: 11500/13129  loss:  0.814674  lr:  0.000175  eta: 0:26:47
2026-01-06 03:10:07,568 - CDistNet - INFO - epoch: 4  iter: 11600/13129  loss:  0.793217  lr:  0.000175  eta: 0:25:08
2026-01-06 03:11:50,050 - CDistNet - INFO - epoch: 4  iter: 11700/13129  loss:  0.794666  lr:  0.000174  eta: 0:23:30
2026-01-06 03:13:32,739 - CDistNet - INFO - epoch: 4  iter: 11800/13129  loss:  0.794425  lr:  0.000174  eta: 0:21:52
2026-01-06 03:15:15,224 - CDistNet - INFO - epoch: 4  iter: 11900/13129  loss:  0.778206  lr:  0.000174  eta: 0:20:14
2026-01-06 03:16:57,964 - CDistNet - INFO - epoch: 4  iter: 12000/13129  loss:  0.792326  lr:  0.000174  eta: 0:18:35
2026-01-06 03:16:58,128 - CDistNet - INFO - eval_loss:1.4187,eval_acc:0.8467--------

2026-01-06 03:18:40,780 - CDistNet - INFO - epoch: 4  iter: 12100/13129  loss:  0.786298  lr:  0.000174  eta: 0:16:57
2026-01-06 03:20:23,846 - CDistNet - INFO - epoch: 4  iter: 12200/13129  loss:  0.786783  lr:  0.000174  eta: 0:15:18
2026-01-06 03:22:06,536 - CDistNet - INFO - epoch: 4  iter: 12300/13129  loss:  0.798112  lr:  0.000174  eta: 0:13:40
2026-01-06 03:23:49,163 - CDistNet - INFO - epoch: 4  iter: 12400/13129  loss:  0.788298  lr:  0.000173  eta: 0:12:01
2026-01-06 03:25:31,940 - CDistNet - INFO - epoch: 4  iter: 12500/13129  loss:  0.792924  lr:  0.000173  eta: 0:10:22
2026-01-06 03:27:14,426 - CDistNet - INFO - epoch: 4  iter: 12600/13129  loss:  0.778637  lr:  0.000173  eta: 0:08:43
2026-01-06 03:28:57,218 - CDistNet - INFO - epoch: 4  iter: 12700/13129  loss:  0.785327  lr:  0.000173  eta: 0:07:04
2026-01-06 03:30:39,914 - CDistNet - INFO - epoch: 4  iter: 12800/13129  loss:  0.798508  lr:  0.000173  eta: 0:05:25
2026-01-06 03:32:22,850 - CDistNet - INFO - epoch: 4  iter: 12900/13129  loss:  0.777545  lr:  0.000173  eta: 0:03:46
2026-01-06 03:34:05,551 - CDistNet - INFO - epoch: 4  iter: 13000/13129  loss:  0.803393  lr:  0.000173  eta: 0:02:07
2026-01-06 03:35:48,339 - CDistNet - INFO - epoch: 4  iter: 13100/13129  loss:  0.797105  lr:  0.000173  eta: 0:00:28
2026-01-06 03:36:16,931 - CDistNet - INFO - Now: best_acc in epoch:4,iteration:0
2026-01-06 03:36:16,932 - CDistNet - INFO -   - (Training)   loss:  0.79423, accuracy: 99.188 %, time: 216.975 min
2026-01-06 03:36:18,043 - CDistNet - INFO - epoch: 5  iter: 0/13129  loss:  0.780591  lr:  0.000172  eta: 4:03:00
2026-01-06 03:36:18,211 - CDistNet - INFO - eval_loss:1.3380,eval_acc:0.8533--------

2026-01-06 03:36:18,212 - CDistNet - INFO - Saving model: best_acc in epoch:5,iteration:0
2026-01-06 03:36:18,458 - CDistNet - INFO - Saved!
2026-01-06 03:38:01,148 - CDistNet - INFO - epoch: 5  iter: 100/13129  loss:  0.850442  lr:  0.000172  eta: 3:44:03
2026-01-06 03:39:43,629 - CDistNet - INFO - epoch: 5  iter: 200/13129  loss:  0.795687  lr:  0.000172  eta: 3:41:35
2026-01-06 03:41:26,459 - CDistNet - INFO - epoch: 5  iter: 300/13129  loss:  0.806559  lr:  0.000172  eta: 3:39:52
2026-01-06 03:43:08,955 - CDistNet - INFO - epoch: 5  iter: 400/13129  loss:  0.790977  lr:  0.000172  eta: 3:37:58
2026-01-06 03:44:51,692 - CDistNet - INFO - epoch: 5  iter: 500/13129  loss:  0.792868  lr:  0.000172  eta: 3:36:15
2026-01-06 03:46:34,432 - CDistNet - INFO - epoch: 5  iter: 600/13129  loss:  0.785345  lr:  0.000172  eta: 3:34:32
2026-01-06 03:48:16,961 - CDistNet - INFO - epoch: 5  iter: 700/13129  loss:  0.802786  lr:  0.000172  eta: 3:32:46
2026-01-06 03:49:59,741 - CDistNet - INFO - epoch: 5  iter: 800/13129  loss:  0.793248  lr:  0.000171  eta: 3:31:04
2026-01-06 03:51:42,287 - CDistNet - INFO - epoch: 5  iter: 900/13129  loss:  0.796429  lr:  0.000171  eta: 3:29:19
2026-01-06 03:53:24,954 - CDistNet - INFO - epoch: 5  iter: 1000/13129  loss:  0.790769  lr:  0.000171  eta: 3:27:36
2026-01-06 03:55:07,699 - CDistNet - INFO - epoch: 5  iter: 1100/13129  loss:  0.803838  lr:  0.000171  eta: 3:25:54
2026-01-06 03:56:50,257 - CDistNet - INFO - epoch: 5  iter: 1200/13129  loss:  0.782505  lr:  0.000171  eta: 3:24:10
2026-01-06 03:58:32,758 - CDistNet - INFO - epoch: 5  iter: 1300/13129  loss:  0.782386  lr:  0.000171  eta: 3:22:25
2026-01-06 04:00:15,424 - CDistNet - INFO - epoch: 5  iter: 1400/13129  loss:  0.778166  lr:  0.000171  eta: 3:20:42
2026-01-06 04:01:57,720 - CDistNet - INFO - epoch: 5  iter: 1500/13129  loss:  0.785118  lr:  0.000171  eta: 3:18:57
2026-01-06 04:03:40,280 - CDistNet - INFO - epoch: 5  iter: 1600/13129  loss:  0.796586  lr:  0.000170  eta: 3:17:13
2026-01-06 04:05:22,922 - CDistNet - INFO - epoch: 5  iter: 1700/13129  loss:  0.791068  lr:  0.000170  eta: 3:15:31
2026-01-06 04:07:05,433 - CDistNet - INFO - epoch: 5  iter: 1800/13129  loss:  0.791695  lr:  0.000170  eta: 3:13:47
2026-01-06 04:08:48,070 - CDistNet - INFO - epoch: 5  iter: 1900/13129  loss:  0.785930  lr:  0.000170  eta: 3:12:05
2026-01-06 04:10:30,377 - CDistNet - INFO - epoch: 5  iter: 2000/13129  loss:  0.779730  lr:  0.000170  eta: 3:10:20
2026-01-06 04:12:13,028 - CDistNet - INFO - epoch: 5  iter: 2100/13129  loss:  0.777728  lr:  0.000170  eta: 3:08:38
2026-01-06 04:13:55,571 - CDistNet - INFO - epoch: 5  iter: 2200/13129  loss:  0.795167  lr:  0.000170  eta: 3:06:55
2026-01-06 04:15:38,290 - CDistNet - INFO - epoch: 5  iter: 2300/13129  loss:  0.776964  lr:  0.000170  eta: 3:05:13
2026-01-06 04:17:20,821 - CDistNet - INFO - epoch: 5  iter: 2400/13129  loss:  0.790318  lr:  0.000169  eta: 3:03:30
2026-01-06 04:19:03,480 - CDistNet - INFO - epoch: 5  iter: 2500/13129  loss:  0.792533  lr:  0.000169  eta: 3:01:47
2026-01-06 04:20:46,128 - CDistNet - INFO - epoch: 5  iter: 2600/13129  loss:  0.803689  lr:  0.000169  eta: 3:00:05
2026-01-06 04:22:28,397 - CDistNet - INFO - epoch: 5  iter: 2700/13129  loss:  0.798814  lr:  0.000169  eta: 2:58:21
2026-01-06 04:24:10,741 - CDistNet - INFO - epoch: 5  iter: 2800/13129  loss:  0.788213  lr:  0.000169  eta: 2:56:37
2026-01-06 04:25:53,022 - CDistNet - INFO - epoch: 5  iter: 2900/13129  loss:  0.788516  lr:  0.000169  eta: 2:54:53
2026-01-06 04:27:35,613 - CDistNet - INFO - epoch: 5  iter: 3000/13129  loss:  0.791403  lr:  0.000169  eta: 2:53:11
2026-01-06 04:29:18,027 - CDistNet - INFO - epoch: 5  iter: 3100/13129  loss:  0.791705  lr:  0.000169  eta: 2:51:28
2026-01-06 04:31:00,609 - CDistNet - INFO - epoch: 5  iter: 3200/13129  loss:  0.790255  lr:  0.000168  eta: 2:49:45
2026-01-06 04:32:43,503 - CDistNet - INFO - epoch: 5  iter: 3300/13129  loss:  0.796149  lr:  0.000168  eta: 2:48:03
2026-01-06 04:34:26,189 - CDistNet - INFO - epoch: 5  iter: 3400/13129  loss:  0.784444  lr:  0.000168  eta: 2:46:21
2026-01-06 04:36:08,533 - CDistNet - INFO - epoch: 5  iter: 3500/13129  loss:  0.806382  lr:  0.000168  eta: 2:44:38
2026-01-06 04:37:51,078 - CDistNet - INFO - epoch: 5  iter: 3600/13129  loss:  0.797246  lr:  0.000168  eta: 2:42:55
2026-01-06 04:39:33,501 - CDistNet - INFO - epoch: 5  iter: 3700/13129  loss:  0.786523  lr:  0.000168  eta: 2:41:12
2026-01-06 04:41:15,602 - CDistNet - INFO - epoch: 5  iter: 3800/13129  loss:  0.808535  lr:  0.000168  eta: 2:39:28
2026-01-06 04:42:58,016 - CDistNet - INFO - epoch: 5  iter: 3900/13129  loss:  0.797874  lr:  0.000168  eta: 2:37:45
2026-01-06 04:44:40,734 - CDistNet - INFO - epoch: 5  iter: 4000/13129  loss:  0.789260  lr:  0.000167  eta: 2:36:03
2026-01-06 04:44:40,898 - CDistNet - INFO - eval_loss:1.4547,eval_acc:0.8578--------

2026-01-06 04:44:40,898 - CDistNet - INFO - Saving model: best_acc in epoch:5,iteration:4000
2026-01-06 04:44:41,234 - CDistNet - INFO - Saved!
2026-01-06 04:46:23,861 - CDistNet - INFO - epoch: 5  iter: 4100/13129  loss:  0.794826  lr:  0.000167  eta: 2:34:22
2026-01-06 04:48:06,818 - CDistNet - INFO - epoch: 5  iter: 4200/13129  loss:  0.800426  lr:  0.000167  eta: 2:32:40
2026-01-06 04:49:48,795 - CDistNet - INFO - epoch: 5  iter: 4300/13129  loss:  0.786280  lr:  0.000167  eta: 2:30:56
2026-01-06 04:51:31,166 - CDistNet - INFO - epoch: 5  iter: 4400/13129  loss:  0.804021  lr:  0.000167  eta: 2:29:13
2026-01-06 04:53:13,577 - CDistNet - INFO - epoch: 5  iter: 4500/13129  loss:  0.797941  lr:  0.000167  eta: 2:27:30
2026-01-06 04:54:56,521 - CDistNet - INFO - epoch: 5  iter: 4600/13129  loss:  0.795122  lr:  0.000167  eta: 2:25:48
2026-01-06 04:56:39,111 - CDistNet - INFO - epoch: 5  iter: 4700/13129  loss:  0.777429  lr:  0.000167  eta: 2:24:06
2026-01-06 04:58:21,421 - CDistNet - INFO - epoch: 5  iter: 4800/13129  loss:  0.797207  lr:  0.000167  eta: 2:22:23
2026-01-06 05:00:03,444 - CDistNet - INFO - epoch: 5  iter: 4900/13129  loss:  0.779589  lr:  0.000166  eta: 2:20:39
2026-01-06 05:01:46,217 - CDistNet - INFO - epoch: 5  iter: 5000/13129  loss:  0.798790  lr:  0.000166  eta: 2:18:57
2026-01-06 05:03:28,681 - CDistNet - INFO - epoch: 5  iter: 5100/13129  loss:  0.785239  lr:  0.000166  eta: 2:17:14
2026-01-06 05:05:11,055 - CDistNet - INFO - epoch: 5  iter: 5200/13129  loss:  0.781416  lr:  0.000166  eta: 2:15:31
2026-01-06 05:06:53,772 - CDistNet - INFO - epoch: 5  iter: 5300/13129  loss:  0.794476  lr:  0.000166  eta: 2:13:49
2026-01-06 05:08:36,182 - CDistNet - INFO - epoch: 5  iter: 5400/13129  loss:  0.799703  lr:  0.000166  eta: 2:12:06
2026-01-06 05:10:18,251 - CDistNet - INFO - epoch: 5  iter: 5500/13129  loss:  0.788960  lr:  0.000166  eta: 2:10:23
2026-01-06 05:12:00,347 - CDistNet - INFO - epoch: 5  iter: 5600/13129  loss:  0.798198  lr:  0.000166  eta: 2:08:40
2026-01-06 05:13:43,164 - CDistNet - INFO - epoch: 5  iter: 5700/13129  loss:  0.792862  lr:  0.000165  eta: 2:06:58
2026-01-06 05:15:25,906 - CDistNet - INFO - epoch: 5  iter: 5800/13129  loss:  0.788037  lr:  0.000165  eta: 2:05:15
2026-01-06 05:17:08,156 - CDistNet - INFO - epoch: 5  iter: 5900/13129  loss:  0.794095  lr:  0.000165  eta: 2:03:33
2026-01-06 05:18:50,490 - CDistNet - INFO - epoch: 5  iter: 6000/13129  loss:  0.781851  lr:  0.000165  eta: 2:01:50
2026-01-06 05:20:32,678 - CDistNet - INFO - epoch: 5  iter: 6100/13129  loss:  0.786181  lr:  0.000165  eta: 2:00:07
2026-01-06 05:22:15,105 - CDistNet - INFO - epoch: 5  iter: 6200/13129  loss:  0.800585  lr:  0.000165  eta: 1:58:24
2026-01-06 05:23:57,487 - CDistNet - INFO - epoch: 5  iter: 6300/13129  loss:  0.804529  lr:  0.000165  eta: 1:56:41
2026-01-06 05:25:39,718 - CDistNet - INFO - epoch: 5  iter: 6400/13129  loss:  0.788021  lr:  0.000165  eta: 1:54:59
2026-01-06 05:27:22,211 - CDistNet - INFO - epoch: 5  iter: 6500/13129  loss:  0.787449  lr:  0.000165  eta: 1:53:16
2026-01-06 05:29:04,341 - CDistNet - INFO - epoch: 5  iter: 6600/13129  loss:  0.794229  lr:  0.000164  eta: 1:51:33
2026-01-06 05:30:46,870 - CDistNet - INFO - epoch: 5  iter: 6700/13129  loss:  0.784407  lr:  0.000164  eta: 1:49:51
2026-01-06 05:32:29,077 - CDistNet - INFO - epoch: 5  iter: 6800/13129  loss:  0.800458  lr:  0.000164  eta: 1:48:08
2026-01-06 05:34:11,152 - CDistNet - INFO - epoch: 5  iter: 6900/13129  loss:  0.793638  lr:  0.000164  eta: 1:46:25
2026-01-06 05:35:53,618 - CDistNet - INFO - epoch: 5  iter: 7000/13129  loss:  0.774358  lr:  0.000164  eta: 1:44:42
2026-01-06 05:37:36,152 - CDistNet - INFO - epoch: 5  iter: 7100/13129  loss:  0.798976  lr:  0.000164  eta: 1:43:00
2026-01-06 05:39:18,426 - CDistNet - INFO - epoch: 5  iter: 7200/13129  loss:  0.782131  lr:  0.000164  eta: 1:41:17
2026-01-06 05:41:00,862 - CDistNet - INFO - epoch: 5  iter: 7300/13129  loss:  0.797041  lr:  0.000164  eta: 1:39:35
2026-01-06 05:42:43,077 - CDistNet - INFO - epoch: 5  iter: 7400/13129  loss:  0.801696  lr:  0.000164  eta: 1:37:52
2026-01-06 05:44:25,342 - CDistNet - INFO - epoch: 5  iter: 7500/13129  loss:  0.785929  lr:  0.000163  eta: 1:36:09
2026-01-06 05:46:07,714 - CDistNet - INFO - epoch: 5  iter: 7600/13129  loss:  0.788044  lr:  0.000163  eta: 1:34:27
2026-01-06 05:47:50,217 - CDistNet - INFO - epoch: 5  iter: 7700/13129  loss:  0.792847  lr:  0.000163  eta: 1:32:44
2026-01-06 05:49:32,461 - CDistNet - INFO - epoch: 5  iter: 7800/13129  loss:  0.795383  lr:  0.000163  eta: 1:31:01
2026-01-06 05:51:14,598 - CDistNet - INFO - epoch: 5  iter: 7900/13129  loss:  0.781153  lr:  0.000163  eta: 1:29:19
2026-01-06 05:52:57,083 - CDistNet - INFO - epoch: 5  iter: 8000/13129  loss:  0.808788  lr:  0.000163  eta: 1:27:36
2026-01-06 05:52:57,247 - CDistNet - INFO - eval_loss:1.4221,eval_acc:0.8600--------

2026-01-06 05:52:57,248 - CDistNet - INFO - Saving model: best_acc in epoch:5,iteration:8000
2026-01-06 05:52:57,591 - CDistNet - INFO - Saved!
2026-01-06 05:54:40,309 - CDistNet - INFO - epoch: 5  iter: 8100/13129  loss:  0.781068  lr:  0.000163  eta: 1:25:54
2026-01-06 05:56:22,515 - CDistNet - INFO - epoch: 5  iter: 8200/13129  loss:  0.778944  lr:  0.000163  eta: 1:24:11
2026-01-06 05:58:04,941 - CDistNet - INFO - epoch: 5  iter: 8300/13129  loss:  0.804652  lr:  0.000163  eta: 1:22:29
2026-01-06 05:59:47,118 - CDistNet - INFO - epoch: 5  iter: 8400/13129  loss:  0.805344  lr:  0.000162  eta: 1:20:46
2026-01-06 06:01:29,348 - CDistNet - INFO - epoch: 5  iter: 8500/13129  loss:  0.788382  lr:  0.000162  eta: 1:19:04
2026-01-06 06:03:11,685 - CDistNet - INFO - epoch: 5  iter: 8600/13129  loss:  0.795474  lr:  0.000162  eta: 1:17:21
2026-01-06 06:04:53,765 - CDistNet - INFO - epoch: 5  iter: 8700/13129  loss:  0.769640  lr:  0.000162  eta: 1:15:38
2026-01-06 06:06:35,783 - CDistNet - INFO - epoch: 5  iter: 8800/13129  loss:  0.784604  lr:  0.000162  eta: 1:13:56
2026-01-06 06:08:18,458 - CDistNet - INFO - epoch: 5  iter: 8900/13129  loss:  0.786262  lr:  0.000162  eta: 1:12:13
2026-01-06 06:10:00,985 - CDistNet - INFO - epoch: 5  iter: 9000/13129  loss:  0.781208  lr:  0.000162  eta: 1:10:31
2026-01-06 06:11:43,344 - CDistNet - INFO - epoch: 5  iter: 9100/13129  loss:  0.784582  lr:  0.000162  eta: 1:08:48
2026-01-06 06:13:25,709 - CDistNet - INFO - epoch: 5  iter: 9200/13129  loss:  0.796561  lr:  0.000162  eta: 1:07:06
2026-01-06 06:15:08,084 - CDistNet - INFO - epoch: 5  iter: 9300/13129  loss:  0.784549  lr:  0.000161  eta: 1:05:23
2026-01-06 06:16:50,468 - CDistNet - INFO - epoch: 5  iter: 9400/13129  loss:  0.805087  lr:  0.000161  eta: 1:03:41
2026-01-06 06:18:32,685 - CDistNet - INFO - epoch: 5  iter: 9500/13129  loss:  0.815440  lr:  0.000161  eta: 1:01:58
2026-01-06 06:20:15,307 - CDistNet - INFO - epoch: 5  iter: 9600/13129  loss:  0.793598  lr:  0.000161  eta: 1:00:16
2026-01-06 06:21:57,941 - CDistNet - INFO - epoch: 5  iter: 9700/13129  loss:  0.788971  lr:  0.000161  eta: 0:58:33
2026-01-06 06:23:40,086 - CDistNet - INFO - epoch: 5  iter: 9800/13129  loss:  0.793448  lr:  0.000161  eta: 0:56:51
2026-01-06 06:25:22,566 - CDistNet - INFO - epoch: 5  iter: 9900/13129  loss:  0.801093  lr:  0.000161  eta: 0:55:08
2026-01-06 06:27:05,312 - CDistNet - INFO - epoch: 5  iter: 10000/13129  loss:  0.781530  lr:  0.000161  eta: 0:53:26
2026-01-06 06:28:47,487 - CDistNet - INFO - epoch: 5  iter: 10100/13129  loss:  0.792334  lr:  0.000161  eta: 0:51:43
2026-01-06 06:30:29,759 - CDistNet - INFO - epoch: 5  iter: 10200/13129  loss:  0.792462  lr:  0.000160  eta: 0:50:01
2026-01-06 06:32:12,200 - CDistNet - INFO - epoch: 5  iter: 10300/13129  loss:  0.787437  lr:  0.000160  eta: 0:48:18
2026-01-06 06:33:54,667 - CDistNet - INFO - epoch: 5  iter: 10400/13129  loss:  0.827873  lr:  0.000160  eta: 0:46:36
2026-01-06 06:35:36,671 - CDistNet - INFO - epoch: 5  iter: 10500/13129  loss:  0.790566  lr:  0.000160  eta: 0:44:53
2026-01-06 06:37:19,117 - CDistNet - INFO - epoch: 5  iter: 10600/13129  loss:  0.801732  lr:  0.000160  eta: 0:43:11
2026-01-06 06:39:01,539 - CDistNet - INFO - epoch: 5  iter: 10700/13129  loss:  0.789472  lr:  0.000160  eta: 0:41:28
2026-01-06 06:40:44,056 - CDistNet - INFO - epoch: 5  iter: 10800/13129  loss:  0.785656  lr:  0.000160  eta: 0:39:46
2026-01-06 06:42:26,693 - CDistNet - INFO - epoch: 5  iter: 10900/13129  loss:  0.784917  lr:  0.000160  eta: 0:38:03
2026-01-06 06:44:09,032 - CDistNet - INFO - epoch: 5  iter: 11000/13129  loss:  0.789614  lr:  0.000160  eta: 0:36:21
2026-01-06 06:45:51,526 - CDistNet - INFO - epoch: 5  iter: 11100/13129  loss:  0.795751  lr:  0.000160  eta: 0:34:39
2026-01-06 06:47:34,021 - CDistNet - INFO - epoch: 5  iter: 11200/13129  loss:  0.792696  lr:  0.000159  eta: 0:32:56
2026-01-06 06:49:16,541 - CDistNet - INFO - epoch: 5  iter: 11300/13129  loss:  0.801550  lr:  0.000159  eta: 0:31:14
2026-01-06 06:50:59,200 - CDistNet - INFO - epoch: 5  iter: 11400/13129  loss:  0.795009  lr:  0.000159  eta: 0:29:31
2026-01-06 06:52:41,923 - CDistNet - INFO - epoch: 5  iter: 11500/13129  loss:  0.791034  lr:  0.000159  eta: 0:27:49
2026-01-06 06:54:24,274 - CDistNet - INFO - epoch: 5  iter: 11600/13129  loss:  0.804840  lr:  0.000159  eta: 0:26:06
2026-01-06 06:56:07,059 - CDistNet - INFO - epoch: 5  iter: 11700/13129  loss:  0.797792  lr:  0.000159  eta: 0:24:24
2026-01-06 06:57:49,687 - CDistNet - INFO - epoch: 5  iter: 11800/13129  loss:  0.795482  lr:  0.000159  eta: 0:22:41
2026-01-06 06:59:32,152 - CDistNet - INFO - epoch: 5  iter: 11900/13129  loss:  0.789048  lr:  0.000159  eta: 0:20:59
2026-01-06 07:01:14,526 - CDistNet - INFO - epoch: 5  iter: 12000/13129  loss:  0.792993  lr:  0.000159  eta: 0:19:16
2026-01-06 07:01:14,691 - CDistNet - INFO - eval_loss:1.5393,eval_acc:0.8444--------

2026-01-06 07:02:57,150 - CDistNet - INFO - epoch: 5  iter: 12100/13129  loss:  0.784444  lr:  0.000158  eta: 0:17:34
2026-01-06 07:04:39,252 - CDistNet - INFO - epoch: 5  iter: 12200/13129  loss:  0.783900  lr:  0.000158  eta: 0:15:51
2026-01-06 07:06:21,761 - CDistNet - INFO - epoch: 5  iter: 12300/13129  loss:  0.804824  lr:  0.000158  eta: 0:14:09
2026-01-06 07:08:04,390 - CDistNet - INFO - epoch: 5  iter: 12400/13129  loss:  0.789805  lr:  0.000158  eta: 0:12:27
2026-01-06 07:09:46,910 - CDistNet - INFO - epoch: 5  iter: 12500/13129  loss:  0.772754  lr:  0.000158  eta: 0:10:44
2026-01-06 07:11:29,241 - CDistNet - INFO - epoch: 5  iter: 12600/13129  loss:  0.778226  lr:  0.000158  eta: 0:09:02
2026-01-06 07:13:11,971 - CDistNet - INFO - epoch: 5  iter: 12700/13129  loss:  0.782747  lr:  0.000158  eta: 0:07:19
2026-01-06 07:14:54,107 - CDistNet - INFO - epoch: 5  iter: 12800/13129  loss:  0.784952  lr:  0.000158  eta: 0:05:37
2026-01-06 07:16:36,703 - CDistNet - INFO - epoch: 5  iter: 12900/13129  loss:  0.778758  lr:  0.000158  eta: 0:03:54
2026-01-06 07:18:18,918 - CDistNet - INFO - epoch: 5  iter: 13000/13129  loss:  0.783907  lr:  0.000158  eta: 0:02:12
2026-01-06 07:20:01,416 - CDistNet - INFO - epoch: 5  iter: 13100/13129  loss:  0.790563  lr:  0.000157  eta: 0:00:29
2026-01-06 07:20:29,756 - CDistNet - INFO - Now: best_acc in epoch:5,iteration:8000
2026-01-06 07:20:29,756 - CDistNet - INFO -   - (Training)   loss:  0.79307, accuracy: 99.215 %, time: 224.214 min
2026-01-06 07:20:30,834 - CDistNet - INFO - epoch: 6  iter: 0/13129  loss:  0.792191  lr:  0.000157  eta: 3:55:36
2026-01-06 07:20:30,997 - CDistNet - INFO - eval_loss:1.2948,eval_acc:0.8400--------

2026-01-06 07:20:30,998 - CDistNet - INFO - Saving model: best_acc in epoch:6,iteration:0
2026-01-06 07:20:31,314 - CDistNet - INFO - Saved!
2026-01-06 07:22:13,732 - CDistNet - INFO - epoch: 6  iter: 100/13129  loss:  0.788716  lr:  0.000157  eta: 3:43:32
2026-01-06 07:23:56,056 - CDistNet - INFO - epoch: 6  iter: 200/13129  loss:  0.786369  lr:  0.000157  eta: 3:41:09
2026-01-06 07:25:38,424 - CDistNet - INFO - epoch: 6  iter: 300/13129  loss:  0.787955  lr:  0.000157  eta: 3:39:15
2026-01-06 07:27:20,679 - CDistNet - INFO - epoch: 6  iter: 400/13129  loss:  0.790165  lr:  0.000157  eta: 3:37:23
2026-01-06 07:29:03,088 - CDistNet - INFO - epoch: 6  iter: 500/13129  loss:  0.789723  lr:  0.000157  eta: 3:35:39
2026-01-06 07:30:45,404 - CDistNet - INFO - epoch: 6  iter: 600/13129  loss:  0.799046  lr:  0.000157  eta: 3:33:54
2026-01-06 07:32:27,779 - CDistNet - INFO - epoch: 6  iter: 700/13129  loss:  0.793318  lr:  0.000157  eta: 3:32:10
2026-01-06 07:34:10,270 - CDistNet - INFO - epoch: 6  iter: 800/13129  loss:  0.794375  lr:  0.000157  eta: 3:30:29
2026-01-06 07:35:52,298 - CDistNet - INFO - epoch: 6  iter: 900/13129  loss:  0.784138  lr:  0.000157  eta: 3:28:41
2026-01-06 07:37:34,471 - CDistNet - INFO - epoch: 6  iter: 1000/13129  loss:  0.786995  lr:  0.000156  eta: 3:26:56
2026-01-06 07:39:16,833 - CDistNet - INFO - epoch: 6  iter: 1100/13129  loss:  0.812975  lr:  0.000156  eta: 3:25:13
2026-01-06 07:40:58,935 - CDistNet - INFO - epoch: 6  iter: 1200/13129  loss:  0.791088  lr:  0.000156  eta: 3:23:28
2026-01-06 07:42:41,355 - CDistNet - INFO - epoch: 6  iter: 1300/13129  loss:  0.794341  lr:  0.000156  eta: 3:21:47
2026-01-06 07:44:23,709 - CDistNet - INFO - epoch: 6  iter: 1400/13129  loss:  0.789934  lr:  0.000156  eta: 3:20:04
2026-01-06 07:46:06,040 - CDistNet - INFO - epoch: 6  iter: 1500/13129  loss:  0.787105  lr:  0.000156  eta: 3:18:22
2026-01-06 07:47:48,245 - CDistNet - INFO - epoch: 6  iter: 1600/13129  loss:  0.788930  lr:  0.000156  eta: 3:16:38
2026-01-06 07:49:30,671 - CDistNet - INFO - epoch: 6  iter: 1700/13129  loss:  0.786972  lr:  0.000156  eta: 3:14:57
2026-01-06 07:51:13,344 - CDistNet - INFO - epoch: 6  iter: 1800/13129  loss:  0.786055  lr:  0.000156  eta: 3:13:16
2026-01-06 07:52:55,717 - CDistNet - INFO - epoch: 6  iter: 1900/13129  loss:  0.784430  lr:  0.000156  eta: 3:11:34
2026-01-06 07:54:38,203 - CDistNet - INFO - epoch: 6  iter: 2000/13129  loss:  0.783886  lr:  0.000155  eta: 3:09:52
2026-01-06 07:56:20,555 - CDistNet - INFO - epoch: 6  iter: 2100/13129  loss:  0.787451  lr:  0.000155  eta: 3:08:10
2026-01-06 07:58:02,818 - CDistNet - INFO - epoch: 6  iter: 2200/13129  loss:  0.790591  lr:  0.000155  eta: 3:06:27
2026-01-06 07:59:45,025 - CDistNet - INFO - epoch: 6  iter: 2300/13129  loss:  0.791452  lr:  0.000155  eta: 3:04:44
2026-01-06 08:01:27,199 - CDistNet - INFO - epoch: 6  iter: 2400/13129  loss:  0.790443  lr:  0.000155  eta: 3:03:01
2026-01-06 08:03:09,268 - CDistNet - INFO - epoch: 6  iter: 2500/13129  loss:  0.789266  lr:  0.000155  eta: 3:01:17
2026-01-06 08:04:52,043 - CDistNet - INFO - epoch: 6  iter: 2600/13129  loss:  0.826824  lr:  0.000155  eta: 2:59:37
2026-01-06 08:06:34,579 - CDistNet - INFO - epoch: 6  iter: 2700/13129  loss:  0.804538  lr:  0.000155  eta: 2:57:55
2026-01-06 08:08:17,306 - CDistNet - INFO - epoch: 6  iter: 2800/13129  loss:  0.792617  lr:  0.000155  eta: 2:56:14
2026-01-06 08:09:59,955 - CDistNet - INFO - epoch: 6  iter: 2900/13129  loss:  0.798535  lr:  0.000155  eta: 2:54:32
2026-01-06 08:11:42,264 - CDistNet - INFO - epoch: 6  iter: 3000/13129  loss:  0.793088  lr:  0.000155  eta: 2:52:50
2026-01-06 08:13:24,821 - CDistNet - INFO - epoch: 6  iter: 3100/13129  loss:  0.787034  lr:  0.000154  eta: 2:51:08
2026-01-06 08:15:07,101 - CDistNet - INFO - epoch: 6  iter: 3200/13129  loss:  0.802249  lr:  0.000154  eta: 2:49:25
2026-01-06 08:16:49,586 - CDistNet - INFO - epoch: 6  iter: 3300/13129  loss:  0.798625  lr:  0.000154  eta: 2:47:43
2026-01-06 08:18:32,123 - CDistNet - INFO - epoch: 6  iter: 3400/13129  loss:  0.800337  lr:  0.000154  eta: 2:46:01
2026-01-06 08:20:14,676 - CDistNet - INFO - epoch: 6  iter: 3500/13129  loss:  0.787837  lr:  0.000154  eta: 2:44:19
2026-01-06 08:21:56,887 - CDistNet - INFO - epoch: 6  iter: 3600/13129  loss:  0.781703  lr:  0.000154  eta: 2:42:36
2026-01-06 08:23:39,281 - CDistNet - INFO - epoch: 6  iter: 3700/13129  loss:  0.805425  lr:  0.000154  eta: 2:40:54
2026-01-06 08:25:21,681 - CDistNet - INFO - epoch: 6  iter: 3800/13129  loss:  0.800250  lr:  0.000154  eta: 2:39:12
2026-01-06 08:27:04,035 - CDistNet - INFO - epoch: 6  iter: 3900/13129  loss:  0.785823  lr:  0.000154  eta: 2:37:29
2026-01-06 08:28:46,523 - CDistNet - INFO - epoch: 6  iter: 4000/13129  loss:  0.813511  lr:  0.000154  eta: 2:35:47
2026-01-06 08:28:46,687 - CDistNet - INFO - eval_loss:1.3851,eval_acc:0.8556--------

2026-01-06 08:28:46,687 - CDistNet - INFO - Saving model: best_acc in epoch:6,iteration:4000
2026-01-06 08:28:47,002 - CDistNet - INFO - Saved!
2026-01-06 08:30:29,300 - CDistNet - INFO - epoch: 6  iter: 4100/13129  loss:  0.797150  lr:  0.000154  eta: 2:34:05
2026-01-06 08:32:11,385 - CDistNet - INFO - epoch: 6  iter: 4200/13129  loss:  0.799643  lr:  0.000153  eta: 2:32:22
2026-01-06 08:33:53,499 - CDistNet - INFO - epoch: 6  iter: 4300/13129  loss:  0.793172  lr:  0.000153  eta: 2:30:39
2026-01-06 08:35:35,604 - CDistNet - INFO - epoch: 6  iter: 4400/13129  loss:  0.793611  lr:  0.000153  eta: 2:28:56
2026-01-06 08:37:17,985 - CDistNet - INFO - epoch: 6  iter: 4500/13129  loss:  0.785236  lr:  0.000153  eta: 2:27:14
2026-01-06 08:39:00,563 - CDistNet - INFO - epoch: 6  iter: 4600/13129  loss:  0.790983  lr:  0.000153  eta: 2:25:32
2026-01-06 08:40:43,002 - CDistNet - INFO - epoch: 6  iter: 4700/13129  loss:  0.791650  lr:  0.000153  eta: 2:23:50
2026-01-06 08:42:25,016 - CDistNet - INFO - epoch: 6  iter: 4800/13129  loss:  0.782049  lr:  0.000153  eta: 2:22:07
2026-01-06 08:44:07,704 - CDistNet - INFO - epoch: 6  iter: 4900/13129  loss:  0.800352  lr:  0.000153  eta: 2:20:25
2026-01-06 08:45:49,734 - CDistNet - INFO - epoch: 6  iter: 5000/13129  loss:  0.778094  lr:  0.000153  eta: 2:18:42
2026-01-06 08:47:32,103 - CDistNet - INFO - epoch: 6  iter: 5100/13129  loss:  0.798126  lr:  0.000153  eta: 2:16:59
2026-01-06 08:49:14,290 - CDistNet - INFO - epoch: 6  iter: 5200/13129  loss:  0.797800  lr:  0.000153  eta: 2:15:17
2026-01-06 08:50:56,705 - CDistNet - INFO - epoch: 6  iter: 5300/13129  loss:  0.789309  lr:  0.000152  eta: 2:13:35
2026-01-06 08:52:39,008 - CDistNet - INFO - epoch: 6  iter: 5400/13129  loss:  0.829373  lr:  0.000152  eta: 2:11:52
2026-01-06 08:54:21,174 - CDistNet - INFO - epoch: 6  iter: 5500/13129  loss:  0.806130  lr:  0.000152  eta: 2:10:09
2026-01-06 08:56:03,465 - CDistNet - INFO - epoch: 6  iter: 5600/13129  loss:  0.785413  lr:  0.000152  eta: 2:08:27
2026-01-06 08:57:45,937 - CDistNet - INFO - epoch: 6  iter: 5700/13129  loss:  0.785172  lr:  0.000152  eta: 2:06:45
2026-01-06 08:59:28,383 - CDistNet - INFO - epoch: 6  iter: 5800/13129  loss:  0.801053  lr:  0.000152  eta: 2:05:02
2026-01-06 09:01:10,829 - CDistNet - INFO - epoch: 6  iter: 5900/13129  loss:  0.799837  lr:  0.000152  eta: 2:03:20
2026-01-06 09:02:53,547 - CDistNet - INFO - epoch: 6  iter: 6000/13129  loss:  0.792782  lr:  0.000152  eta: 2:01:38
2026-01-06 09:04:36,161 - CDistNet - INFO - epoch: 6  iter: 6100/13129  loss:  0.807822  lr:  0.000152  eta: 1:59:56
2026-01-06 09:06:18,735 - CDistNet - INFO - epoch: 6  iter: 6200/13129  loss:  0.790273  lr:  0.000152  eta: 1:58:14
2026-01-06 09:08:00,794 - CDistNet - INFO - epoch: 6  iter: 6300/13129  loss:  0.788174  lr:  0.000152  eta: 1:56:31
2026-01-06 09:09:43,205 - CDistNet - INFO - epoch: 6  iter: 6400/13129  loss:  0.793982  lr:  0.000151  eta: 1:54:49
2026-01-06 09:11:25,583 - CDistNet - INFO - epoch: 6  iter: 6500/13129  loss:  0.788277  lr:  0.000151  eta: 1:53:06
2026-01-06 09:13:07,964 - CDistNet - INFO - epoch: 6  iter: 6600/13129  loss:  0.789112  lr:  0.000151  eta: 1:51:24
2026-01-06 09:14:50,361 - CDistNet - INFO - epoch: 6  iter: 6700/13129  loss:  0.797824  lr:  0.000151  eta: 1:49:42
2026-01-06 09:16:32,814 - CDistNet - INFO - epoch: 6  iter: 6800/13129  loss:  0.787882  lr:  0.000151  eta: 1:47:59
2026-01-06 09:18:15,091 - CDistNet - INFO - epoch: 6  iter: 6900/13129  loss:  0.798372  lr:  0.000151  eta: 1:46:17
2026-01-06 09:19:57,459 - CDistNet - INFO - epoch: 6  iter: 7000/13129  loss:  0.786468  lr:  0.000151  eta: 1:44:34
2026-01-06 09:21:39,823 - CDistNet - INFO - epoch: 6  iter: 7100/13129  loss:  0.773231  lr:  0.000151  eta: 1:42:52
2026-01-06 09:23:22,386 - CDistNet - INFO - epoch: 6  iter: 7200/13129  loss:  0.780093  lr:  0.000151  eta: 1:41:10
2026-01-06 09:25:04,873 - CDistNet - INFO - epoch: 6  iter: 7300/13129  loss:  0.794978  lr:  0.000151  eta: 1:39:28
2026-01-06 09:26:47,264 - CDistNet - INFO - epoch: 6  iter: 7400/13129  loss:  0.795140  lr:  0.000151  eta: 1:37:45
2026-01-06 09:28:29,871 - CDistNet - INFO - epoch: 6  iter: 7500/13129  loss:  0.787962  lr:  0.000150  eta: 1:36:03
2026-01-06 09:30:12,480 - CDistNet - INFO - epoch: 6  iter: 7600/13129  loss:  0.791753  lr:  0.000150  eta: 1:34:21
2026-01-06 09:31:54,719 - CDistNet - INFO - epoch: 6  iter: 7700/13129  loss:  0.790204  lr:  0.000150  eta: 1:32:38
2026-01-06 09:33:37,352 - CDistNet - INFO - epoch: 6  iter: 7800/13129  loss:  0.792564  lr:  0.000150  eta: 1:30:56
2026-01-06 09:35:19,686 - CDistNet - INFO - epoch: 6  iter: 7900/13129  loss:  0.784795  lr:  0.000150  eta: 1:29:14
2026-01-06 09:37:02,275 - CDistNet - INFO - epoch: 6  iter: 8000/13129  loss:  0.806314  lr:  0.000150  eta: 1:27:31
2026-01-06 09:37:02,439 - CDistNet - INFO - eval_loss:1.2974,eval_acc:0.8533--------

2026-01-06 09:38:44,962 - CDistNet - INFO - epoch: 6  iter: 8100/13129  loss:  0.794813  lr:  0.000150  eta: 1:25:49
2026-01-06 09:40:27,333 - CDistNet - INFO - epoch: 6  iter: 8200/13129  loss:  0.785617  lr:  0.000150  eta: 1:24:07
2026-01-06 09:42:09,713 - CDistNet - INFO - epoch: 6  iter: 8300/13129  loss:  0.780458  lr:  0.000150  eta: 1:22:24
2026-01-06 09:43:52,242 - CDistNet - INFO - epoch: 6  iter: 8400/13129  loss:  0.784358  lr:  0.000150  eta: 1:20:42
2026-01-06 09:45:34,721 - CDistNet - INFO - epoch: 6  iter: 8500/13129  loss:  0.800057  lr:  0.000150  eta: 1:19:00
2026-01-06 09:47:17,255 - CDistNet - INFO - epoch: 6  iter: 8600/13129  loss:  0.782462  lr:  0.000150  eta: 1:17:17
2026-01-06 09:48:59,830 - CDistNet - INFO - epoch: 6  iter: 8700/13129  loss:  0.777992  lr:  0.000149  eta: 1:15:35
2026-01-06 09:50:42,252 - CDistNet - INFO - epoch: 6  iter: 8800/13129  loss:  0.788919  lr:  0.000149  eta: 1:13:53
2026-01-06 09:52:24,728 - CDistNet - INFO - epoch: 6  iter: 8900/13129  loss:  0.789522  lr:  0.000149  eta: 1:12:10
2026-01-06 09:54:07,378 - CDistNet - INFO - epoch: 6  iter: 9000/13129  loss:  0.822428  lr:  0.000149  eta: 1:10:28
2026-01-06 09:55:49,920 - CDistNet - INFO - epoch: 6  iter: 9100/13129  loss:  0.786875  lr:  0.000149  eta: 1:08:46
2026-01-06 09:57:32,423 - CDistNet - INFO - epoch: 6  iter: 9200/13129  loss:  0.798594  lr:  0.000149  eta: 1:07:03
2026-01-06 09:59:15,147 - CDistNet - INFO - epoch: 6  iter: 9300/13129  loss:  0.795621  lr:  0.000149  eta: 1:05:21
2026-01-06 10:00:57,404 - CDistNet - INFO - epoch: 6  iter: 9400/13129  loss:  0.788032  lr:  0.000149  eta: 1:03:38
2026-01-06 10:02:39,833 - CDistNet - INFO - epoch: 6  iter: 9500/13129  loss:  0.785931  lr:  0.000149  eta: 1:01:56
2026-01-06 10:04:22,100 - CDistNet - INFO - epoch: 6  iter: 9600/13129  loss:  0.785263  lr:  0.000149  eta: 1:00:14
2026-01-06 10:06:04,707 - CDistNet - INFO - epoch: 6  iter: 9700/13129  loss:  0.795993  lr:  0.000149  eta: 0:58:31
2026-01-06 10:07:47,080 - CDistNet - INFO - epoch: 6  iter: 9800/13129  loss:  0.826039  lr:  0.000148  eta: 0:56:49
2026-01-06 10:09:29,408 - CDistNet - INFO - epoch: 6  iter: 9900/13129  loss:  0.782119  lr:  0.000148  eta: 0:55:06
2026-01-06 10:11:11,944 - CDistNet - INFO - epoch: 6  iter: 10000/13129  loss:  0.800275  lr:  0.000148  eta: 0:53:24
2026-01-06 10:12:54,113 - CDistNet - INFO - epoch: 6  iter: 10100/13129  loss:  0.786213  lr:  0.000148  eta: 0:51:41
2026-01-06 10:14:36,385 - CDistNet - INFO - epoch: 6  iter: 10200/13129  loss:  0.784882  lr:  0.000148  eta: 0:49:59
2026-01-06 10:16:18,784 - CDistNet - INFO - epoch: 6  iter: 10300/13129  loss:  0.801627  lr:  0.000148  eta: 0:48:17
2026-01-06 10:18:01,242 - CDistNet - INFO - epoch: 6  iter: 10400/13129  loss:  0.785241  lr:  0.000148  eta: 0:46:34
2026-01-06 10:19:43,761 - CDistNet - INFO - epoch: 6  iter: 10500/13129  loss:  0.791164  lr:  0.000148  eta: 0:44:52
2026-01-06 10:21:26,459 - CDistNet - INFO - epoch: 6  iter: 10600/13129  loss:  0.789464  lr:  0.000148  eta: 0:43:09
2026-01-06 10:23:08,770 - CDistNet - INFO - epoch: 6  iter: 10700/13129  loss:  0.793557  lr:  0.000148  eta: 0:41:27
2026-01-06 10:24:51,057 - CDistNet - INFO - epoch: 6  iter: 10800/13129  loss:  0.784027  lr:  0.000148  eta: 0:39:45
2026-01-06 10:26:33,407 - CDistNet - INFO - epoch: 6  iter: 10900/13129  loss:  0.786186  lr:  0.000148  eta: 0:38:02
2026-01-06 10:28:15,719 - CDistNet - INFO - epoch: 6  iter: 11000/13129  loss:  0.787546  lr:  0.000147  eta: 0:36:20
2026-01-06 10:29:58,007 - CDistNet - INFO - epoch: 6  iter: 11100/13129  loss:  0.788968  lr:  0.000147  eta: 0:34:37
2026-01-06 10:31:40,395 - CDistNet - INFO - epoch: 6  iter: 11200/13129  loss:  0.800734  lr:  0.000147  eta: 0:32:55
2026-01-06 10:33:23,006 - CDistNet - INFO - epoch: 6  iter: 11300/13129  loss:  0.788396  lr:  0.000147  eta: 0:31:13
2026-01-06 10:35:05,344 - CDistNet - INFO - epoch: 6  iter: 11400/13129  loss:  0.790901  lr:  0.000147  eta: 0:29:30
2026-01-06 10:36:48,221 - CDistNet - INFO - epoch: 6  iter: 11500/13129  loss:  0.798756  lr:  0.000147  eta: 0:27:48
2026-01-06 10:38:30,681 - CDistNet - INFO - epoch: 6  iter: 11600/13129  loss:  0.802696  lr:  0.000147  eta: 0:26:05
2026-01-06 10:40:13,243 - CDistNet - INFO - epoch: 6  iter: 11700/13129  loss:  0.799250  lr:  0.000147  eta: 0:24:23
2026-01-06 10:41:55,754 - CDistNet - INFO - epoch: 6  iter: 11800/13129  loss:  0.795145  lr:  0.000147  eta: 0:22:41
2026-01-06 10:43:38,102 - CDistNet - INFO - epoch: 6  iter: 11900/13129  loss:  0.801199  lr:  0.000147  eta: 0:20:58
2026-01-06 10:45:20,459 - CDistNet - INFO - epoch: 6  iter: 12000/13129  loss:  0.789377  lr:  0.000147  eta: 0:19:16
2026-01-06 10:45:20,623 - CDistNet - INFO - eval_loss:1.5303,eval_acc:0.8422--------

2026-01-06 10:47:03,090 - CDistNet - INFO - epoch: 6  iter: 12100/13129  loss:  0.785134  lr:  0.000147  eta: 0:17:33
2026-01-06 10:48:45,392 - CDistNet - INFO - epoch: 6  iter: 12200/13129  loss:  0.785301  lr:  0.000147  eta: 0:15:51
2026-01-06 10:50:27,801 - CDistNet - INFO - epoch: 6  iter: 12300/13129  loss:  0.783828  lr:  0.000146  eta: 0:14:09
2026-01-06 10:52:10,553 - CDistNet - INFO - epoch: 6  iter: 12400/13129  loss:  0.780397  lr:  0.000146  eta: 0:12:26
2026-01-06 10:53:52,861 - CDistNet - INFO - epoch: 6  iter: 12500/13129  loss:  0.801391  lr:  0.000146  eta: 0:10:44
2026-01-06 10:55:35,584 - CDistNet - INFO - epoch: 6  iter: 12600/13129  loss:  0.793012  lr:  0.000146  eta: 0:09:01
2026-01-06 10:57:17,857 - CDistNet - INFO - epoch: 6  iter: 12700/13129  loss:  0.788674  lr:  0.000146  eta: 0:07:19
2026-01-06 10:59:00,562 - CDistNet - INFO - epoch: 6  iter: 12800/13129  loss:  0.796499  lr:  0.000146  eta: 0:05:36
2026-01-06 11:00:43,447 - CDistNet - INFO - epoch: 6  iter: 12900/13129  loss:  0.799601  lr:  0.000146  eta: 0:03:54
2026-01-06 11:02:25,916 - CDistNet - INFO - epoch: 6  iter: 13000/13129  loss:  0.785449  lr:  0.000146  eta: 0:02:12
2026-01-06 11:04:08,467 - CDistNet - INFO - epoch: 6  iter: 13100/13129  loss:  0.792837  lr:  0.000146  eta: 0:00:29
2026-01-06 11:04:36,966 - CDistNet - INFO - Now: best_acc in epoch:6,iteration:4000
2026-01-06 11:04:36,967 - CDistNet - INFO -   - (Training)   loss:  0.79233, accuracy: 99.232 %, time: 224.120 min
2026-01-06 11:04:36,967 - CDistNet - INFO - Start eval ...
2026-01-06 11:04:37,131 - CDistNet - INFO -   - (Validation)   loss:  1.35625, accuracy: 86.667 %, time: 0.003 min
2026-01-06 11:04:37,131 - CDistNet - INFO - Saving model ...
2026-01-06 11:04:37,433 - CDistNet - INFO - Saved!
2026-01-06 11:04:38,513 - CDistNet - INFO - epoch: 7  iter: 0/13129  loss:  0.792466  lr:  0.000010  eta: 3:56:08
2026-01-06 11:04:38,678 - CDistNet - INFO - eval_loss:1.3529,eval_acc:0.8667--------

2026-01-06 11:04:38,678 - CDistNet - INFO - Saving model: best_acc in epoch:7,iteration:0
2026-01-06 11:04:38,991 - CDistNet - INFO - Saved!
2026-01-06 11:06:21,489 - CDistNet - INFO - epoch: 7  iter: 100/13129  loss:  0.779346  lr:  0.000010  eta: 3:43:43
2026-01-06 11:08:04,103 - CDistNet - INFO - epoch: 7  iter: 200/13129  loss:  0.798897  lr:  0.000010  eta: 3:41:33
2026-01-06 11:09:46,722 - CDistNet - INFO - epoch: 7  iter: 300/13129  loss:  0.793099  lr:  0.000010  eta: 3:39:42
2026-01-06 11:11:28,965 - CDistNet - INFO - epoch: 7  iter: 400/13129  loss:  0.791161  lr:  0.000010  eta: 3:37:43
2026-01-06 11:13:11,570 - CDistNet - INFO - epoch: 7  iter: 500/13129  loss:  0.790323  lr:  0.000010  eta: 3:36:00
2026-01-06 11:14:54,191 - CDistNet - INFO - epoch: 7  iter: 600/13129  loss:  0.794719  lr:  0.000010  eta: 3:34:17
2026-01-06 11:16:36,550 - CDistNet - INFO - epoch: 7  iter: 700/13129  loss:  0.777533  lr:  0.000010  eta: 3:32:30
2026-01-06 11:18:19,227 - CDistNet - INFO - epoch: 7  iter: 800/13129  loss:  0.796808  lr:  0.000010  eta: 3:30:49
2026-01-06 11:20:02,128 - CDistNet - INFO - epoch: 7  iter: 900/13129  loss:  0.787549  lr:  0.000010  eta: 3:29:10
2026-01-06 11:21:44,553 - CDistNet - INFO - epoch: 7  iter: 1000/13129  loss:  0.803054  lr:  0.000010  eta: 3:27:25
2026-01-06 11:23:27,116 - CDistNet - INFO - epoch: 7  iter: 1100/13129  loss:  0.785074  lr:  0.000010  eta: 3:25:42
2026-01-06 11:25:09,357 - CDistNet - INFO - epoch: 7  iter: 1200/13129  loss:  0.783263  lr:  0.000010  eta: 3:23:56
2026-01-06 11:26:51,693 - CDistNet - INFO - epoch: 7  iter: 1300/13129  loss:  0.789754  lr:  0.000010  eta: 3:22:11
2026-01-06 11:28:34,125 - CDistNet - INFO - epoch: 7  iter: 1400/13129  loss:  0.785220  lr:  0.000010  eta: 3:20:27
2026-01-06 11:30:16,975 - CDistNet - INFO - epoch: 7  iter: 1500/13129  loss:  0.804643  lr:  0.000010  eta: 3:18:47
2026-01-06 11:31:59,316 - CDistNet - INFO - epoch: 7  iter: 1600/13129  loss:  0.791116  lr:  0.000010  eta: 3:17:03
2026-01-06 11:33:41,759 - CDistNet - INFO - epoch: 7  iter: 1700/13129  loss:  0.794698  lr:  0.000010  eta: 3:15:20
2026-01-06 11:35:24,241 - CDistNet - INFO - epoch: 7  iter: 1800/13129  loss:  0.803390  lr:  0.000010  eta: 3:13:37
2026-01-06 11:37:06,961 - CDistNet - INFO - epoch: 7  iter: 1900/13129  loss:  0.794172  lr:  0.000010  eta: 3:11:55
2026-01-06 11:38:49,107 - CDistNet - INFO - epoch: 7  iter: 2000/13129  loss:  0.784970  lr:  0.000010  eta: 3:10:10
2026-01-06 11:40:31,642 - CDistNet - INFO - epoch: 7  iter: 2100/13129  loss:  0.792204  lr:  0.000010  eta: 3:08:28
2026-01-06 11:42:14,342 - CDistNet - INFO - epoch: 7  iter: 2200/13129  loss:  0.795809  lr:  0.000010  eta: 3:06:46
2026-01-06 11:43:56,553 - CDistNet - INFO - epoch: 7  iter: 2300/13129  loss:  0.795818  lr:  0.000010  eta: 3:05:02
2026-01-06 11:45:39,117 - CDistNet - INFO - epoch: 7  iter: 2400/13129  loss:  0.774752  lr:  0.000010  eta: 3:03:20
2026-01-06 11:47:21,860 - CDistNet - INFO - epoch: 7  iter: 2500/13129  loss:  0.799910  lr:  0.000010  eta: 3:01:38
2026-01-06 11:49:04,254 - CDistNet - INFO - epoch: 7  iter: 2600/13129  loss:  0.788327  lr:  0.000010  eta: 2:59:55
2026-01-06 11:50:46,822 - CDistNet - INFO - epoch: 7  iter: 2700/13129  loss:  0.807113  lr:  0.000010  eta: 2:58:13
2026-01-06 11:52:29,228 - CDistNet - INFO - epoch: 7  iter: 2800/13129  loss:  0.783631  lr:  0.000010  eta: 2:56:30
2026-01-06 11:54:11,962 - CDistNet - INFO - epoch: 7  iter: 2900/13129  loss:  0.779220  lr:  0.000010  eta: 2:54:48
2026-01-06 11:55:54,417 - CDistNet - INFO - epoch: 7  iter: 3000/13129  loss:  0.801153  lr:  0.000010  eta: 2:53:05
2026-01-06 11:57:37,103 - CDistNet - INFO - epoch: 7  iter: 3100/13129  loss:  0.795933  lr:  0.000010  eta: 2:51:23
2026-01-06 11:59:19,731 - CDistNet - INFO - epoch: 7  iter: 3200/13129  loss:  0.805417  lr:  0.000010  eta: 2:49:41
2026-01-06 12:01:02,147 - CDistNet - INFO - epoch: 7  iter: 3300/13129  loss:  0.788448  lr:  0.000010  eta: 2:47:58
2026-01-06 12:02:44,598 - CDistNet - INFO - epoch: 7  iter: 3400/13129  loss:  0.806864  lr:  0.000010  eta: 2:46:15
2026-01-06 12:04:27,002 - CDistNet - INFO - epoch: 7  iter: 3500/13129  loss:  0.796328  lr:  0.000010  eta: 2:44:32
2026-01-06 12:06:09,394 - CDistNet - INFO - epoch: 7  iter: 3600/13129  loss:  0.778043  lr:  0.000010  eta: 2:42:49
2026-01-06 12:07:51,916 - CDistNet - INFO - epoch: 7  iter: 3700/13129  loss:  0.805126  lr:  0.000010  eta: 2:41:07
2026-01-06 12:09:34,259 - CDistNet - INFO - epoch: 7  iter: 3800/13129  loss:  0.801067  lr:  0.000010  eta: 2:39:24
2026-01-06 12:11:17,036 - CDistNet - INFO - epoch: 7  iter: 3900/13129  loss:  0.813670  lr:  0.000010  eta: 2:37:42
2026-01-06 12:12:59,467 - CDistNet - INFO - epoch: 7  iter: 4000/13129  loss:  0.779788  lr:  0.000010  eta: 2:35:59
2026-01-06 12:12:59,632 - CDistNet - INFO - eval_loss:1.2756,eval_acc:0.8600--------

2026-01-06 12:14:41,897 - CDistNet - INFO - epoch: 7  iter: 4100/13129  loss:  0.794137  lr:  0.000010  eta: 2:34:16
2026-01-06 12:16:24,689 - CDistNet - INFO - epoch: 7  iter: 4200/13129  loss:  0.779286  lr:  0.000010  eta: 2:32:34
2026-01-06 12:18:07,147 - CDistNet - INFO - epoch: 7  iter: 4300/13129  loss:  0.791450  lr:  0.000010  eta: 2:30:52
2026-01-06 12:19:49,368 - CDistNet - INFO - epoch: 7  iter: 4400/13129  loss:  0.792993  lr:  0.000010  eta: 2:29:09
2026-01-06 12:21:32,037 - CDistNet - INFO - epoch: 7  iter: 4500/13129  loss:  0.791334  lr:  0.000010  eta: 2:27:26
2026-01-06 12:23:14,627 - CDistNet - INFO - epoch: 7  iter: 4600/13129  loss:  0.785342  lr:  0.000010  eta: 2:25:44
2026-01-06 12:24:57,192 - CDistNet - INFO - epoch: 7  iter: 4700/13129  loss:  0.788975  lr:  0.000010  eta: 2:24:01
2026-01-06 12:26:39,655 - CDistNet - INFO - epoch: 7  iter: 4800/13129  loss:  0.800217  lr:  0.000010  eta: 2:22:19
2026-01-06 12:28:22,121 - CDistNet - INFO - epoch: 7  iter: 4900/13129  loss:  0.786031  lr:  0.000010  eta: 2:20:36
2026-01-06 12:30:04,592 - CDistNet - INFO - epoch: 7  iter: 5000/13129  loss:  0.778608  lr:  0.000010  eta: 2:18:54
2026-01-06 12:31:46,966 - CDistNet - INFO - epoch: 7  iter: 5100/13129  loss:  0.774092  lr:  0.000010  eta: 2:17:11
2026-01-06 12:33:29,785 - CDistNet - INFO - epoch: 7  iter: 5200/13129  loss:  0.778237  lr:  0.000010  eta: 2:15:29
2026-01-06 12:35:12,325 - CDistNet - INFO - epoch: 7  iter: 5300/13129  loss:  0.795155  lr:  0.000010  eta: 2:13:46
2026-01-06 12:36:54,813 - CDistNet - INFO - epoch: 7  iter: 5400/13129  loss:  0.791387  lr:  0.000010  eta: 2:12:04
2026-01-06 12:38:37,270 - CDistNet - INFO - epoch: 7  iter: 5500/13129  loss:  0.776881  lr:  0.000010  eta: 2:10:21
2026-01-06 12:40:19,866 - CDistNet - INFO - epoch: 7  iter: 5600/13129  loss:  0.782491  lr:  0.000010  eta: 2:08:39
2026-01-06 12:42:02,042 - CDistNet - INFO - epoch: 7  iter: 5700/13129  loss:  0.789758  lr:  0.000010  eta: 2:06:56
2026-01-06 12:43:44,475 - CDistNet - INFO - epoch: 7  iter: 5800/13129  loss:  0.783595  lr:  0.000010  eta: 2:05:13
2026-01-06 12:45:26,513 - CDistNet - INFO - epoch: 7  iter: 5900/13129  loss:  0.782905  lr:  0.000010  eta: 2:03:30
2026-01-06 12:47:09,062 - CDistNet - INFO - epoch: 7  iter: 6000/13129  loss:  0.782051  lr:  0.000010  eta: 2:01:47
2026-01-06 12:48:51,597 - CDistNet - INFO - epoch: 7  iter: 6100/13129  loss:  0.789178  lr:  0.000010  eta: 2:00:05
2026-01-06 12:50:34,082 - CDistNet - INFO - epoch: 7  iter: 6200/13129  loss:  0.792004  lr:  0.000010  eta: 1:58:22
2026-01-06 12:52:16,402 - CDistNet - INFO - epoch: 7  iter: 6300/13129  loss:  0.785950  lr:  0.000010  eta: 1:56:40
2026-01-06 12:53:58,747 - CDistNet - INFO - epoch: 7  iter: 6400/13129  loss:  0.809063  lr:  0.000010  eta: 1:54:57
2026-01-06 12:55:41,387 - CDistNet - INFO - epoch: 7  iter: 6500/13129  loss:  0.787943  lr:  0.000010  eta: 1:53:15
2026-01-06 12:57:23,743 - CDistNet - INFO - epoch: 7  iter: 6600/13129  loss:  0.785292  lr:  0.000010  eta: 1:51:32
2026-01-06 12:59:05,830 - CDistNet - INFO - epoch: 7  iter: 6700/13129  loss:  0.785908  lr:  0.000010  eta: 1:49:49
2026-01-06 13:00:48,182 - CDistNet - INFO - epoch: 7  iter: 6800/13129  loss:  0.799023  lr:  0.000010  eta: 1:48:06
2026-01-06 13:02:30,663 - CDistNet - INFO - epoch: 7  iter: 6900/13129  loss:  0.787712  lr:  0.000010  eta: 1:46:24
2026-01-06 13:04:13,069 - CDistNet - INFO - epoch: 7  iter: 7000/13129  loss:  0.780100  lr:  0.000010  eta: 1:44:41
2026-01-06 13:05:55,342 - CDistNet - INFO - epoch: 7  iter: 7100/13129  loss:  0.782312  lr:  0.000010  eta: 1:42:59
2026-01-06 13:07:37,588 - CDistNet - INFO - epoch: 7  iter: 7200/13129  loss:  0.780729  lr:  0.000010  eta: 1:41:16
2026-01-06 13:09:20,202 - CDistNet - INFO - epoch: 7  iter: 7300/13129  loss:  0.791100  lr:  0.000010  eta: 1:39:34
2026-01-06 13:11:02,798 - CDistNet - INFO - epoch: 7  iter: 7400/13129  loss:  0.803028  lr:  0.000010  eta: 1:37:51
2026-01-06 13:12:45,378 - CDistNet - INFO - epoch: 7  iter: 7500/13129  loss:  0.782174  lr:  0.000010  eta: 1:36:09
2026-01-06 13:14:27,817 - CDistNet - INFO - epoch: 7  iter: 7600/13129  loss:  0.783699  lr:  0.000010  eta: 1:34:26
2026-01-06 13:16:10,653 - CDistNet - INFO - epoch: 7  iter: 7700/13129  loss:  0.791137  lr:  0.000010  eta: 1:32:44
2026-01-06 13:17:53,275 - CDistNet - INFO - epoch: 7  iter: 7800/13129  loss:  0.788291  lr:  0.000010  eta: 1:31:02
2026-01-06 13:19:35,717 - CDistNet - INFO - epoch: 7  iter: 7900/13129  loss:  0.775378  lr:  0.000010  eta: 1:29:19
2026-01-06 13:21:18,077 - CDistNet - INFO - epoch: 7  iter: 8000/13129  loss:  0.778383  lr:  0.000010  eta: 1:27:36
2026-01-06 13:21:18,241 - CDistNet - INFO - eval_loss:1.2917,eval_acc:0.8600--------

2026-01-06 13:23:00,996 - CDistNet - INFO - epoch: 7  iter: 8100/13129  loss:  0.783081  lr:  0.000010  eta: 1:25:54
2026-01-06 13:24:43,544 - CDistNet - INFO - epoch: 7  iter: 8200/13129  loss:  0.792944  lr:  0.000010  eta: 1:24:12
2026-01-06 13:26:25,865 - CDistNet - INFO - epoch: 7  iter: 8300/13129  loss:  0.786708  lr:  0.000010  eta: 1:22:29
2026-01-06 13:28:08,786 - CDistNet - INFO - epoch: 7  iter: 8400/13129  loss:  0.798763  lr:  0.000010  eta: 1:20:47
2026-01-06 13:29:51,114 - CDistNet - INFO - epoch: 7  iter: 8500/13129  loss:  0.790713  lr:  0.000010  eta: 1:19:04
2026-01-06 13:31:33,654 - CDistNet - INFO - epoch: 7  iter: 8600/13129  loss:  0.804126  lr:  0.000010  eta: 1:17:22
2026-01-06 13:33:16,147 - CDistNet - INFO - epoch: 7  iter: 8700/13129  loss:  0.793294  lr:  0.000010  eta: 1:15:39
2026-01-06 13:34:58,554 - CDistNet - INFO - epoch: 7  iter: 8800/13129  loss:  0.785065  lr:  0.000010  eta: 1:13:57
2026-01-06 13:36:41,060 - CDistNet - INFO - epoch: 7  iter: 8900/13129  loss:  0.799065  lr:  0.000010  eta: 1:12:14
2026-01-06 13:38:23,171 - CDistNet - INFO - epoch: 7  iter: 9000/13129  loss:  0.780196  lr:  0.000010  eta: 1:10:32
2026-01-06 13:40:05,941 - CDistNet - INFO - epoch: 7  iter: 9100/13129  loss:  0.799138  lr:  0.000010  eta: 1:08:49
2026-01-06 13:41:48,472 - CDistNet - INFO - epoch: 7  iter: 9200/13129  loss:  0.788941  lr:  0.000010  eta: 1:07:07
2026-01-06 13:43:30,687 - CDistNet - INFO - epoch: 7  iter: 9300/13129  loss:  0.778029  lr:  0.000010  eta: 1:05:24
2026-01-06 13:45:12,875 - CDistNet - INFO - epoch: 7  iter: 9400/13129  loss:  0.787834  lr:  0.000010  eta: 1:03:41
2026-01-06 13:46:55,061 - CDistNet - INFO - epoch: 7  iter: 9500/13129  loss:  0.796727  lr:  0.000010  eta: 1:01:59
2026-01-06 13:48:37,530 - CDistNet - INFO - epoch: 7  iter: 9600/13129  loss:  0.792145  lr:  0.000010  eta: 1:00:16
2026-01-06 13:50:19,930 - CDistNet - INFO - epoch: 7  iter: 9700/13129  loss:  0.786298  lr:  0.000010  eta: 0:58:34
2026-01-06 13:52:02,345 - CDistNet - INFO - epoch: 7  iter: 9800/13129  loss:  0.794481  lr:  0.000010  eta: 0:56:51
2026-01-06 13:53:45,227 - CDistNet - INFO - epoch: 7  iter: 9900/13129  loss:  0.784853  lr:  0.000010  eta: 0:55:09
2026-01-06 13:55:27,734 - CDistNet - INFO - epoch: 7  iter: 10000/13129  loss:  0.773642  lr:  0.000010  eta: 0:53:26
2026-01-06 13:57:09,902 - CDistNet - INFO - epoch: 7  iter: 10100/13129  loss:  0.784910  lr:  0.000010  eta: 0:51:44
2026-01-06 13:58:52,365 - CDistNet - INFO - epoch: 7  iter: 10200/13129  loss:  0.791040  lr:  0.000010  eta: 0:50:01
2026-01-06 14:00:34,937 - CDistNet - INFO - epoch: 7  iter: 10300/13129  loss:  0.777798  lr:  0.000010  eta: 0:48:19
2026-01-06 14:02:17,268 - CDistNet - INFO - epoch: 7  iter: 10400/13129  loss:  0.793424  lr:  0.000010  eta: 0:46:36
2026-01-06 14:03:59,824 - CDistNet - INFO - epoch: 7  iter: 10500/13129  loss:  0.783382  lr:  0.000010  eta: 0:44:54
2026-01-06 14:05:42,393 - CDistNet - INFO - epoch: 7  iter: 10600/13129  loss:  0.783266  lr:  0.000010  eta: 0:43:11
2026-01-06 14:07:24,804 - CDistNet - INFO - epoch: 7  iter: 10700/13129  loss:  0.784600  lr:  0.000010  eta: 0:41:29
2026-01-06 14:09:07,165 - CDistNet - INFO - epoch: 7  iter: 10800/13129  loss:  0.783284  lr:  0.000010  eta: 0:39:46
2026-01-06 14:10:49,450 - CDistNet - INFO - epoch: 7  iter: 10900/13129  loss:  0.787697  lr:  0.000010  eta: 0:38:04
2026-01-06 14:12:31,937 - CDistNet - INFO - epoch: 7  iter: 11000/13129  loss:  0.797065  lr:  0.000010  eta: 0:36:21
2026-01-06 14:14:14,360 - CDistNet - INFO - epoch: 7  iter: 11100/13129  loss:  0.790303  lr:  0.000010  eta: 0:34:39
2026-01-06 14:15:56,770 - CDistNet - INFO - epoch: 7  iter: 11200/13129  loss:  0.797016  lr:  0.000010  eta: 0:32:56
2026-01-06 14:17:39,228 - CDistNet - INFO - epoch: 7  iter: 11300/13129  loss:  0.813592  lr:  0.000010  eta: 0:31:14
2026-01-06 14:19:21,628 - CDistNet - INFO - epoch: 7  iter: 11400/13129  loss:  0.790357  lr:  0.000010  eta: 0:29:31
2026-01-06 14:21:04,148 - CDistNet - INFO - epoch: 7  iter: 11500/13129  loss:  0.777638  lr:  0.000010  eta: 0:27:49
2026-01-06 14:22:46,424 - CDistNet - INFO - epoch: 7  iter: 11600/13129  loss:  0.795968  lr:  0.000010  eta: 0:26:06
2026-01-06 14:24:28,959 - CDistNet - INFO - epoch: 7  iter: 11700/13129  loss:  0.792609  lr:  0.000010  eta: 0:24:24
2026-01-06 14:26:11,170 - CDistNet - INFO - epoch: 7  iter: 11800/13129  loss:  0.779015  lr:  0.000010  eta: 0:22:41
2026-01-06 14:27:53,665 - CDistNet - INFO - epoch: 7  iter: 11900/13129  loss:  0.793723  lr:  0.000010  eta: 0:20:59
2026-01-06 14:29:36,537 - CDistNet - INFO - epoch: 7  iter: 12000/13129  loss:  0.801541  lr:  0.000010  eta: 0:19:17
2026-01-06 14:29:36,702 - CDistNet - INFO - eval_loss:1.2969,eval_acc:0.8600--------

2026-01-06 14:31:19,843 - CDistNet - INFO - epoch: 7  iter: 12100/13129  loss:  0.782560  lr:  0.000010  eta: 0:17:34
2026-01-06 14:33:02,596 - CDistNet - INFO - epoch: 7  iter: 12200/13129  loss:  0.781189  lr:  0.000010  eta: 0:15:52
2026-01-06 14:34:45,485 - CDistNet - INFO - epoch: 7  iter: 12300/13129  loss:  0.784320  lr:  0.000010  eta: 0:14:09
2026-01-06 14:36:28,436 - CDistNet - INFO - epoch: 7  iter: 12400/13129  loss:  0.794787  lr:  0.000010  eta: 0:12:27
2026-01-06 14:38:10,929 - CDistNet - INFO - epoch: 7  iter: 12500/13129  loss:  0.781965  lr:  0.000010  eta: 0:10:44
2026-01-06 14:39:54,651 - CDistNet - INFO - epoch: 7  iter: 12600/13129  loss:  0.772901  lr:  0.000010  eta: 0:09:02
2026-01-06 14:41:38,668 - CDistNet - INFO - epoch: 7  iter: 12700/13129  loss:  0.787603  lr:  0.000010  eta: 0:07:19
2026-01-06 14:43:22,681 - CDistNet - INFO - epoch: 7  iter: 12800/13129  loss:  0.785414  lr:  0.000010  eta: 0:05:37
2026-01-06 14:45:06,294 - CDistNet - INFO - epoch: 7  iter: 12900/13129  loss:  0.778330  lr:  0.000010  eta: 0:03:54
2026-01-06 14:46:50,030 - CDistNet - INFO - epoch: 7  iter: 13000/13129  loss:  0.816053  lr:  0.000010  eta: 0:02:12
2026-01-06 14:48:33,540 - CDistNet - INFO - epoch: 7  iter: 13100/13129  loss:  0.795791  lr:  0.000010  eta: 0:00:29
2026-01-06 14:49:02,373 - CDistNet - INFO - Now: best_acc in epoch:7,iteration:0
2026-01-06 14:49:02,374 - CDistNet - INFO -   - (Training)   loss:  0.79021, accuracy: 99.280 %, time: 224.416 min
2026-01-06 14:49:02,374 - CDistNet - INFO - Start eval ...
2026-01-06 14:49:02,546 - CDistNet - INFO -   - (Validation)   loss:  1.29648, accuracy: 86.000 %, time: 0.003 min
2026-01-06 14:49:02,546 - CDistNet - INFO - Saving model ...
2026-01-06 14:49:02,808 - CDistNet - INFO - Saved!
2026-01-06 14:49:03,907 - CDistNet - INFO - epoch: 8  iter: 0/13129  loss:  0.798518  lr:  0.000010  eta: 4:00:10
2026-01-06 14:49:04,074 - CDistNet - INFO - eval_loss:1.2981,eval_acc:0.8600--------

2026-01-06 14:49:04,074 - CDistNet - INFO - Saving model: best_acc in epoch:8,iteration:0
2026-01-06 14:49:04,326 - CDistNet - INFO - Saved!
2026-01-06 14:50:47,904 - CDistNet - INFO - epoch: 8  iter: 100/13129  loss:  0.782486  lr:  0.000010  eta: 3:45:57
2026-01-06 14:52:31,644 - CDistNet - INFO - epoch: 8  iter: 200/13129  loss:  0.800876  lr:  0.000010  eta: 3:43:52
2026-01-06 14:54:15,672 - CDistNet - INFO - epoch: 8  iter: 300/13129  loss:  0.794461  lr:  0.000010  eta: 3:42:14
2026-01-06 14:55:59,599 - CDistNet - INFO - epoch: 8  iter: 400/13129  loss:  0.797956  lr:  0.000010  eta: 3:40:30
2026-01-06 14:57:43,548 - CDistNet - INFO - epoch: 8  iter: 500/13129  loss:  0.783245  lr:  0.000010  eta: 3:38:46
2026-01-06 14:59:27,530 - CDistNet - INFO - epoch: 8  iter: 600/13129  loss:  0.782995  lr:  0.000010  eta: 3:37:03
2026-01-06 15:01:12,159 - CDistNet - INFO - epoch: 8  iter: 700/13129  loss:  0.795604  lr:  0.000010  eta: 3:35:31
2026-01-06 15:02:56,464 - CDistNet - INFO - epoch: 8  iter: 800/13129  loss:  0.794291  lr:  0.000010  eta: 3:33:51
2026-01-06 15:04:40,434 - CDistNet - INFO - epoch: 8  iter: 900/13129  loss:  0.774206  lr:  0.000010  eta: 3:32:06
2026-01-06 22:22:23,088 - CDistNet - INFO - model parameter:-------
Trainable: 65.499528 M
2026-01-06 22:22:23,089 - CDistNet - INFO - model struct:-------
DataParallel(
  (module): CDistNet(
    (visual_branch): VIS_Pre(
      (transform): TPS_SpatialTransformerNetwork(
        (LocalizationNetwork): LocalizationNetwork(
          (conv): Sequential(
            (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU(inplace=True)
            (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
            (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (6): ReLU(inplace=True)
            (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
            (8): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (9): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (10): ReLU(inplace=True)
            (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
            (12): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (13): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (14): ReLU(inplace=True)
            (15): AdaptiveAvgPool2d(output_size=1)
          )
          (localization_fc1): Sequential(
            (0): Linear(in_features=512, out_features=256, bias=True)
            (1): ReLU(inplace=True)
          )
          (localization_fc2): Linear(in_features=256, out_features=40, bias=True)
        )
        (GridGenerator): GridGenerator()
      )
      (backbone): ABI_ResNet(
        (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (convbnrelu): ConvBnRelu(
          (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
          (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (layer1): Sequential(
          (0): BasicBlock(
            (conv1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (downsample): Sequential(
              (0): Conv2d(32, 32, kernel_size=(1, 1), stride=(2, 2), bias=False)
              (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (1): BasicBlock(
            (conv1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (2): BasicBlock(
            (conv1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (layer2): Sequential(
          (0): BasicBlock(
            (conv1): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (downsample): Sequential(
              (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (1): BasicBlock(
            (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (2): BasicBlock(
            (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (3): BasicBlock(
            (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (layer3): Sequential(
          (0): BasicBlock(
            (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (downsample): Sequential(
              (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
              (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (1): BasicBlock(
            (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (2): BasicBlock(
            (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (3): BasicBlock(
            (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (4): BasicBlock(
            (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (5): BasicBlock(
            (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (layer4): Sequential(
          (0): BasicBlock(
            (conv1): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (downsample): Sequential(
              (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (1): BasicBlock(
            (conv1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (2): BasicBlock(
            (conv1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (3): BasicBlock(
            (conv1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (4): BasicBlock(
            (conv1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (5): BasicBlock(
            (conv1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (layer5): Sequential(
          (0): BasicBlock(
            (conv1): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (downsample): Sequential(
              (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (1): BasicBlock(
            (conv1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (2): BasicBlock(
            (conv1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
      )
      (positional_encoding): PositionalEncoding(
        (dropout): Dropout(p=0.15, inplace=False)
      )
      (trans_encoder): TransformerEncoder(
        (layers): ModuleList(
          (0-2): 3 x TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): Linear(in_features=512, out_features=512, bias=True)
              (conv1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
              (conv2): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1))
              (conv3): Conv2d(512, 1536, kernel_size=(1, 1), stride=(1, 1))
            )
            (conv1): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1))
            (conv2): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1))
            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.15, inplace=False)
            (dropout2): Dropout(p=0.15, inplace=False)
          )
        )
        (pos_encoding): PositionalEncoding(
          (dropout): Dropout(p=0.0, inplace=False)
        )
      )
    )
    (semantic_branch): SEM_Pre(
      (embedding): Embeddings(
        (embedding): Embedding(81, 512, padding_idx=0)
      )
      (positional_encoding): PositionalEncoding(
        (dropout): Dropout(p=0.15, inplace=False)
      )
    )
    (positional_branch): POS_Pre(
      (pos_encoding): PositionalEncoding(
        (dropout): Dropout(p=0.15, inplace=False)
      )
      (linear1): Linear(in_features=512, out_features=512, bias=True)
      (linear2): Linear(in_features=512, out_features=512, bias=True)
      (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    )
    (mdcdp): MDCDP(
      (layers_pos): ModuleList(
        (0-2): 3 x CommonAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
            (conv1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
            (conv2): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1))
            (conv3): Conv2d(512, 1536, kernel_size=(1, 1), stride=(1, 1))
          )
          (linear1): Linear(in_features=512, out_features=1024, bias=True)
          (dropout): Dropout(p=0.05, inplace=False)
          (linear2): Linear(in_features=1024, out_features=512, bias=True)
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (dropout2): Dropout(p=0.15, inplace=False)
          (dropout3): Dropout(p=0.15, inplace=False)
        )
      )
      (layers2): ModuleList(
        (0-2): 3 x CommonAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
            (conv1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
            (conv2): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1))
            (conv3): Conv2d(512, 1536, kernel_size=(1, 1), stride=(1, 1))
          )
          (linear1): Linear(in_features=512, out_features=1024, bias=True)
          (dropout): Dropout(p=0.05, inplace=False)
          (linear2): Linear(in_features=1024, out_features=512, bias=True)
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (dropout2): Dropout(p=0.15, inplace=False)
          (dropout3): Dropout(p=0.15, inplace=False)
        )
      )
      (layers3): ModuleList(
        (0-2): 3 x CommonAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
            (conv1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
            (conv2): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1))
            (conv3): Conv2d(512, 1536, kernel_size=(1, 1), stride=(1, 1))
          )
          (linear1): Linear(in_features=512, out_features=1024, bias=True)
          (dropout): Dropout(p=0.05, inplace=False)
          (linear2): Linear(in_features=1024, out_features=512, bias=True)
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (dropout2): Dropout(p=0.15, inplace=False)
          (dropout3): Dropout(p=0.15, inplace=False)
        )
      )
      (dynamic_shared_fusion): DSF(
        (w_att): Linear(in_features=1024, out_features=512, bias=True)
      )
    )
    (tgt_word_prj): Linear(in_features=512, out_features=81, bias=False)
  )
)
2026-01-06 22:22:24,808 - CDistNet - INFO - epoch: 0  iter: 0/26258  loss:  4.834344  lr:  0.000000  eta: 12:31:24
2026-01-06 22:23:55,929 - CDistNet - INFO - epoch: 0  iter: 100/26258  loss:  4.207523  lr:  0.000001  eta: 6:40:44
2026-01-06 22:27:03,852 - CDistNet - INFO - model parameter:-------
Trainable: 65.499528 M
2026-01-06 22:27:03,854 - CDistNet - INFO - model struct:-------
DataParallel(
  (module): CDistNet(
    (visual_branch): VIS_Pre(
      (transform): TPS_SpatialTransformerNetwork(
        (LocalizationNetwork): LocalizationNetwork(
          (conv): Sequential(
            (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU(inplace=True)
            (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
            (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (6): ReLU(inplace=True)
            (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
            (8): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (9): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (10): ReLU(inplace=True)
            (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
            (12): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (13): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (14): ReLU(inplace=True)
            (15): AdaptiveAvgPool2d(output_size=1)
          )
          (localization_fc1): Sequential(
            (0): Linear(in_features=512, out_features=256, bias=True)
            (1): ReLU(inplace=True)
          )
          (localization_fc2): Linear(in_features=256, out_features=40, bias=True)
        )
        (GridGenerator): GridGenerator()
      )
      (backbone): ABI_ResNet(
        (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (convbnrelu): ConvBnRelu(
          (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
          (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (layer1): Sequential(
          (0): BasicBlock(
            (conv1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (downsample): Sequential(
              (0): Conv2d(32, 32, kernel_size=(1, 1), stride=(2, 2), bias=False)
              (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (1): BasicBlock(
            (conv1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (2): BasicBlock(
            (conv1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (layer2): Sequential(
          (0): BasicBlock(
            (conv1): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (downsample): Sequential(
              (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (1): BasicBlock(
            (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (2): BasicBlock(
            (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (3): BasicBlock(
            (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (layer3): Sequential(
          (0): BasicBlock(
            (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (downsample): Sequential(
              (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
              (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (1): BasicBlock(
            (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (2): BasicBlock(
            (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (3): BasicBlock(
            (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (4): BasicBlock(
            (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (5): BasicBlock(
            (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (layer4): Sequential(
          (0): BasicBlock(
            (conv1): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (downsample): Sequential(
              (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (1): BasicBlock(
            (conv1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (2): BasicBlock(
            (conv1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (3): BasicBlock(
            (conv1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (4): BasicBlock(
            (conv1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (5): BasicBlock(
            (conv1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (layer5): Sequential(
          (0): BasicBlock(
            (conv1): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (downsample): Sequential(
              (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (1): BasicBlock(
            (conv1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (2): BasicBlock(
            (conv1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
      )
      (positional_encoding): PositionalEncoding(
        (dropout): Dropout(p=0.15, inplace=False)
      )
      (trans_encoder): TransformerEncoder(
        (layers): ModuleList(
          (0-2): 3 x TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): Linear(in_features=512, out_features=512, bias=True)
              (conv1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
              (conv2): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1))
              (conv3): Conv2d(512, 1536, kernel_size=(1, 1), stride=(1, 1))
            )
            (conv1): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1))
            (conv2): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1))
            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.15, inplace=False)
            (dropout2): Dropout(p=0.15, inplace=False)
          )
        )
        (pos_encoding): PositionalEncoding(
          (dropout): Dropout(p=0.0, inplace=False)
        )
      )
    )
    (semantic_branch): SEM_Pre(
      (embedding): Embeddings(
        (embedding): Embedding(81, 512, padding_idx=0)
      )
      (positional_encoding): PositionalEncoding(
        (dropout): Dropout(p=0.15, inplace=False)
      )
    )
    (positional_branch): POS_Pre(
      (pos_encoding): PositionalEncoding(
        (dropout): Dropout(p=0.15, inplace=False)
      )
      (linear1): Linear(in_features=512, out_features=512, bias=True)
      (linear2): Linear(in_features=512, out_features=512, bias=True)
      (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    )
    (mdcdp): MDCDP(
      (layers_pos): ModuleList(
        (0-2): 3 x CommonAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
            (conv1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
            (conv2): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1))
            (conv3): Conv2d(512, 1536, kernel_size=(1, 1), stride=(1, 1))
          )
          (linear1): Linear(in_features=512, out_features=1024, bias=True)
          (dropout): Dropout(p=0.05, inplace=False)
          (linear2): Linear(in_features=1024, out_features=512, bias=True)
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (dropout2): Dropout(p=0.15, inplace=False)
          (dropout3): Dropout(p=0.15, inplace=False)
        )
      )
      (layers2): ModuleList(
        (0-2): 3 x CommonAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
            (conv1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
            (conv2): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1))
            (conv3): Conv2d(512, 1536, kernel_size=(1, 1), stride=(1, 1))
          )
          (linear1): Linear(in_features=512, out_features=1024, bias=True)
          (dropout): Dropout(p=0.05, inplace=False)
          (linear2): Linear(in_features=1024, out_features=512, bias=True)
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (dropout2): Dropout(p=0.15, inplace=False)
          (dropout3): Dropout(p=0.15, inplace=False)
        )
      )
      (layers3): ModuleList(
        (0-2): 3 x CommonAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
            (conv1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
            (conv2): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1))
            (conv3): Conv2d(512, 1536, kernel_size=(1, 1), stride=(1, 1))
          )
          (linear1): Linear(in_features=512, out_features=1024, bias=True)
          (dropout): Dropout(p=0.05, inplace=False)
          (linear2): Linear(in_features=1024, out_features=512, bias=True)
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (dropout2): Dropout(p=0.15, inplace=False)
          (dropout3): Dropout(p=0.15, inplace=False)
        )
      )
      (dynamic_shared_fusion): DSF(
        (w_att): Linear(in_features=1024, out_features=512, bias=True)
      )
    )
    (tgt_word_prj): Linear(in_features=512, out_features=81, bias=False)
  )
)
2026-01-06 22:27:05,442 - CDistNet - INFO - epoch: 0  iter: 0/26258  loss:  4.974135  lr:  0.000000  eta: 11:33:44
2026-01-06 22:28:45,248 - CDistNet - INFO - epoch: 0  iter: 100/26258  loss:  4.292060  lr:  0.000001  eta: 7:17:39
2026-01-06 22:30:28,754 - CDistNet - INFO - epoch: 0  iter: 200/26258  loss:  3.582763  lr:  0.000001  eta: 7:22:43
2026-01-06 22:32:12,306 - CDistNet - INFO - epoch: 0  iter: 300/26258  loss:  3.424547  lr:  0.000002  eta: 7:23:20
2026-01-06 22:33:55,917 - CDistNet - INFO - epoch: 0  iter: 400/26258  loss:  3.330750  lr:  0.000002  eta: 7:22:51
2026-01-06 22:35:39,172 - CDistNet - INFO - epoch: 0  iter: 500/26258  loss:  3.267761  lr:  0.000003  eta: 7:21:34
2026-01-06 22:37:22,198 - CDistNet - INFO - epoch: 0  iter: 600/26258  loss:  3.255970  lr:  0.000003  eta: 7:19:58
2026-01-06 22:39:05,387 - CDistNet - INFO - epoch: 0  iter: 700/26258  loss:  3.245966  lr:  0.000004  eta: 7:18:26
2026-01-06 22:40:48,481 - CDistNet - INFO - epoch: 0  iter: 800/26258  loss:  3.172719  lr:  0.000004  eta: 7:16:48
2026-01-06 22:42:31,617 - CDistNet - INFO - epoch: 0  iter: 900/26258  loss:  3.144342  lr:  0.000005  eta: 7:15:11
2026-01-06 22:44:14,610 - CDistNet - INFO - epoch: 0  iter: 1000/26258  loss:  3.163587  lr:  0.000006  eta: 7:13:28
2026-01-06 22:45:57,768 - CDistNet - INFO - epoch: 0  iter: 1100/26258  loss:  3.175573  lr:  0.000006  eta: 7:11:50
2026-01-06 22:47:40,665 - CDistNet - INFO - epoch: 0  iter: 1200/26258  loss:  3.099711  lr:  0.000007  eta: 7:10:05
2026-01-06 22:49:23,763 - CDistNet - INFO - epoch: 0  iter: 1300/26258  loss:  3.159245  lr:  0.000007  eta: 7:08:24
2026-01-06 22:51:06,796 - CDistNet - INFO - epoch: 0  iter: 1400/26258  loss:  3.109195  lr:  0.000008  eta: 7:06:42
2026-01-06 22:52:49,685 - CDistNet - INFO - epoch: 0  iter: 1500/26258  loss:  3.086048  lr:  0.000008  eta: 7:04:57
2026-01-06 22:54:32,521 - CDistNet - INFO - epoch: 0  iter: 1600/26258  loss:  3.054014  lr:  0.000009  eta: 7:03:12
2026-01-06 22:56:15,133 - CDistNet - INFO - epoch: 0  iter: 1700/26258  loss:  3.067907  lr:  0.000009  eta: 7:01:23
2026-01-06 22:57:57,864 - CDistNet - INFO - epoch: 0  iter: 1800/26258  loss:  3.048281  lr:  0.000010  eta: 6:59:37
2026-01-06 22:59:40,636 - CDistNet - INFO - epoch: 0  iter: 1900/26258  loss:  3.027460  lr:  0.000011  eta: 6:57:52
2026-01-06 23:01:23,495 - CDistNet - INFO - epoch: 0  iter: 2000/26258  loss:  3.024055  lr:  0.000011  eta: 6:56:08
2026-01-06 23:03:06,456 - CDistNet - INFO - epoch: 0  iter: 2100/26258  loss:  3.008098  lr:  0.000012  eta: 6:54:26
2026-01-06 23:04:49,198 - CDistNet - INFO - epoch: 0  iter: 2200/26258  loss:  2.979784  lr:  0.000012  eta: 6:52:41
2026-01-06 23:06:31,923 - CDistNet - INFO - epoch: 0  iter: 2300/26258  loss:  2.946988  lr:  0.000013  eta: 6:50:56
2026-01-06 23:08:14,871 - CDistNet - INFO - epoch: 0  iter: 2400/26258  loss:  2.890326  lr:  0.000013  eta: 6:49:13
2026-01-06 23:09:57,844 - CDistNet - INFO - epoch: 0  iter: 2500/26258  loss:  2.877595  lr:  0.000014  eta: 6:47:31
2026-01-06 23:11:40,940 - CDistNet - INFO - epoch: 0  iter: 2600/26258  loss:  2.866354  lr:  0.000014  eta: 6:45:50
2026-01-06 23:13:23,706 - CDistNet - INFO - epoch: 0  iter: 2700/26258  loss:  2.884333  lr:  0.000015  eta: 6:44:05
2026-01-06 23:15:06,522 - CDistNet - INFO - epoch: 0  iter: 2800/26258  loss:  2.814976  lr:  0.000015  eta: 6:42:21
2026-01-06 23:16:49,169 - CDistNet - INFO - epoch: 0  iter: 2900/26258  loss:  2.791245  lr:  0.000016  eta: 6:40:36
2026-01-06 23:18:32,063 - CDistNet - INFO - epoch: 0  iter: 3000/26258  loss:  2.768216  lr:  0.000017  eta: 6:38:53
2026-01-06 23:20:14,877 - CDistNet - INFO - epoch: 0  iter: 3100/26258  loss:  2.708428  lr:  0.000017  eta: 6:37:10
2026-01-06 23:21:57,988 - CDistNet - INFO - epoch: 0  iter: 3200/26258  loss:  2.672088  lr:  0.000018  eta: 6:35:28
2026-01-06 23:23:41,069 - CDistNet - INFO - epoch: 0  iter: 3300/26258  loss:  2.553628  lr:  0.000018  eta: 6:33:47
2026-01-06 23:25:23,877 - CDistNet - INFO - epoch: 0  iter: 3400/26258  loss:  2.570946  lr:  0.000019  eta: 6:32:03
2026-01-06 23:27:06,977 - CDistNet - INFO - epoch: 0  iter: 3500/26258  loss:  2.418837  lr:  0.000019  eta: 6:30:21
2026-01-06 23:28:49,715 - CDistNet - INFO - epoch: 0  iter: 3600/26258  loss:  2.422131  lr:  0.000020  eta: 6:28:37
2026-01-06 23:30:32,479 - CDistNet - INFO - epoch: 0  iter: 3700/26258  loss:  2.215528  lr:  0.000020  eta: 6:26:53
2026-01-06 23:32:15,107 - CDistNet - INFO - epoch: 0  iter: 3800/26258  loss:  2.118812  lr:  0.000021  eta: 6:25:09
2026-01-06 23:33:58,041 - CDistNet - INFO - epoch: 0  iter: 3900/26258  loss:  2.049322  lr:  0.000022  eta: 6:23:26
2026-01-06 23:35:40,849 - CDistNet - INFO - epoch: 0  iter: 4000/26258  loss:  1.889743  lr:  0.000022  eta: 6:21:43
2026-01-06 23:37:23,462 - CDistNet - INFO - epoch: 0  iter: 4100/26258  loss:  1.774110  lr:  0.000023  eta: 6:19:58
2026-01-06 23:39:06,214 - CDistNet - INFO - epoch: 0  iter: 4200/26258  loss:  1.785646  lr:  0.000023  eta: 6:18:15
2026-01-06 23:40:48,864 - CDistNet - INFO - epoch: 0  iter: 4300/26258  loss:  1.602022  lr:  0.000024  eta: 6:16:31
2026-01-06 23:42:31,468 - CDistNet - INFO - epoch: 0  iter: 4400/26258  loss:  1.610863  lr:  0.000024  eta: 6:14:46
2026-01-06 23:44:14,090 - CDistNet - INFO - epoch: 0  iter: 4500/26258  loss:  1.576636  lr:  0.000025  eta: 6:13:02
2026-01-06 23:45:57,081 - CDistNet - INFO - epoch: 0  iter: 4600/26258  loss:  1.465574  lr:  0.000025  eta: 6:11:20
2026-01-06 23:47:40,065 - CDistNet - INFO - epoch: 0  iter: 4700/26258  loss:  1.415247  lr:  0.000026  eta: 6:09:38
2026-01-06 23:49:22,634 - CDistNet - INFO - epoch: 0  iter: 4800/26258  loss:  1.353050  lr:  0.000027  eta: 6:07:53
2026-01-06 23:51:05,180 - CDistNet - INFO - epoch: 0  iter: 4900/26258  loss:  1.409008  lr:  0.000027  eta: 6:06:09
2026-01-06 23:52:47,857 - CDistNet - INFO - epoch: 0  iter: 5000/26258  loss:  1.314013  lr:  0.000028  eta: 6:04:25
2026-01-06 23:54:30,735 - CDistNet - INFO - epoch: 0  iter: 5100/26258  loss:  1.282369  lr:  0.000028  eta: 6:02:43
2026-01-06 23:56:13,199 - CDistNet - INFO - epoch: 0  iter: 5200/26258  loss:  1.193488  lr:  0.000029  eta: 6:00:58
2026-01-06 23:57:55,807 - CDistNet - INFO - epoch: 0  iter: 5300/26258  loss:  1.347207  lr:  0.000029  eta: 5:59:14
2026-01-06 23:59:38,281 - CDistNet - INFO - epoch: 0  iter: 5400/26258  loss:  1.159399  lr:  0.000030  eta: 5:57:30
2026-01-07 00:01:20,840 - CDistNet - INFO - epoch: 0  iter: 5500/26258  loss:  1.136108  lr:  0.000030  eta: 5:55:46
2026-01-07 00:03:03,783 - CDistNet - INFO - epoch: 0  iter: 5600/26258  loss:  1.207712  lr:  0.000031  eta: 5:54:04
2026-01-07 00:04:46,352 - CDistNet - INFO - epoch: 0  iter: 5700/26258  loss:  1.049194  lr:  0.000031  eta: 5:52:20
2026-01-07 00:06:29,006 - CDistNet - INFO - epoch: 0  iter: 5800/26258  loss:  1.136842  lr:  0.000032  eta: 5:50:36
2026-01-07 00:08:13,992 - CDistNet - INFO - epoch: 0  iter: 5900/26258  loss:  1.052429  lr:  0.000033  eta: 5:49:01
2026-01-07 00:09:58,566 - CDistNet - INFO - epoch: 0  iter: 6000/26258  loss:  0.989151  lr:  0.000033  eta: 5:47:24
2026-01-07 00:11:42,742 - CDistNet - INFO - epoch: 0  iter: 6100/26258  loss:  1.073665  lr:  0.000034  eta: 5:45:45
2026-01-07 00:13:27,208 - CDistNet - INFO - epoch: 0  iter: 6200/26258  loss:  0.975573  lr:  0.000034  eta: 5:44:07
2026-01-07 00:15:11,185 - CDistNet - INFO - epoch: 0  iter: 6300/26258  loss:  0.970268  lr:  0.000035  eta: 5:42:28
2026-01-07 00:16:54,903 - CDistNet - INFO - epoch: 0  iter: 6400/26258  loss:  0.963397  lr:  0.000035  eta: 5:40:47
2026-01-07 00:18:38,755 - CDistNet - INFO - epoch: 0  iter: 6500/26258  loss:  0.980654  lr:  0.000036  eta: 5:39:07
2026-01-07 00:20:22,649 - CDistNet - INFO - epoch: 0  iter: 6600/26258  loss:  0.908220  lr:  0.000036  eta: 5:37:27
2026-01-07 00:22:06,671 - CDistNet - INFO - epoch: 0  iter: 6700/26258  loss:  0.982755  lr:  0.000037  eta: 5:35:47
